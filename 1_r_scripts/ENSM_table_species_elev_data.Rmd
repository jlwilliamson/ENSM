---
title: "ENSM Table Elevation Calculations"
author: "Jessie Williamson"
date: "8/8/2019"
output: html_document
---

###

This script includes all code for downloading and calculating species upper and lower elevational range limits for Williamson & Witt, 'Elevational niche-shift migration', In revision. 

Please note that some GBIF download elements have changed since this code was originally written in Fall 2019 - several code chunks below describe these changes. The script has NOT been updated to implement these new download procedures. 

**Improvements that could be made to this script:** 
- Write a forloop to loop through all desired GBIF species downloads (taking care to pull unique download keys for each request) --> write out DOIs for each download to .csv
- Write a 'filtering' function to automate initial filering steps that quickly became repetitive in this code 
- Fiddle with using raster _alt layers to extract elevations vs. using geonames (which works well but is very cumbersome for species with >10,000 occurrence records)


###


Tutorial for getting elevation data from GBIF:
https://luisdva.github.io/rstats/Elevation-data-in-R-using-rgbif/

Tutorial for rgbif package: 
https://ropensci.org/tutorials/rgbif_tutorial/

FYI, if rgbif occ_download_import() function breaks again and repeatedly gives "Fatal error - R abort" message, see this link for helpful troubleshooting: https://github.com/ropensci/rgbif/issues/353


---

# Clear workspace and set WD 
```{R}
rm(list=ls(all=TRUE)) # clear workspace 
# setwd("~/Desktop/Rdirectory/ENSM") # remember you switched from Desktop to MSBbirds dropbox
setwd("/Users/Jessie/Dropbox (MSBbirds)/Rdirectory/ENSM")
```


# Load packages
```{R}
library(rgbif)
library(dplyr)
library(plyr)
library(XML)
library(httr)
library(maps)
library(ggplot2)
library(elevatr)
library(DescTools)
library(maptools)
```

# Subset criteria and functions:
```{r}
# subset criteria for making xxxx.sub datasets:
sc <- c("species"
        , "decimalLatitude" 
        , "decimalLongitude"
        , "coordinateUncertaintyInMeters"
        , "month"
        , "year"
        , "elevation"
        , "countryCode"
        , "locality"
        , "basisOfRecord"
        , "institutionCode"
        , "collectionCode"
        )

#subset criteria for Outlier Analysis (oa)
oa <- c("species"
        , "latitude" 
        , "longitude"
        , "month"
        , "year"
        , "final_elev"
        , "countryCode"
        )

himalayas <- c("IN" # India
              , "PK" # Pakistan
              , "BT" # Bhutan
              , "NP" # Nepal
              , "BD" # Bangladesh
              )
# For excluding all but largely Himalayan countries

# Jessie's function for finding outliers (good for normal distributions w/out a lot of skew)
FindOutliers <- function(data,r) {
  result <- vector("list",2) # make a list of 2
  Q1 <- quantile(data$final_elev, 0.25)
  Q3 <- quantile(data$final_elev, 0.75)
  IQR <- Q3-Q1 #Or use IQR(data)
  max.thresh <- Q3 + (IQR*r)   # r=outlier ID threshold; usually 1.5, but values of 3-4 for extreme outliers only
  min.thresh <- Q1 - (IQR*r)
  rownum <- which(data$final_elev > max.thresh | data$final_elev < min.thresh) # prints row ID of  outlier value 
  result[[1]] <- rownum
  result[[2]] <- data$final_elev[rownum]
  names(result) <- list("rownum", "elevation")
  result
} 
# hisp.b.out <- FindOutliers(hisp.b, r=1.5); hisp.b.out # sample of what running this looks like 
#hisp.b <- hisp.b[-hisp.b.out[[1]],] # remove outliers by indexing
#hisp.b <-hisp.b[-hisp.b.out$rownum,] # remove outliers by calling row number 
# hisp.b <- hisp.b[-hisp.b.out$rownum[1],] # remove just one outlier value

# Function to find breeding elevational range 
BreedingElevs <- function(data) { 
  LLH <- min(data$final_elev)
  ULH <- max(data$final_elev)
  breed.range <- cbind(LLH, ULH)
  as.data.frame(breed.range)
}

# Function to find non-breeding elevational range 
NonbreedingElevs <- function(data) { 
  LLL <- min(data$final_elev)
  ULL <- max(data$final_elev)
  nonbreed.range <- cbind(LLL, ULL)
  as.data.frame(nonbreed.range)
}
```


# Geonames note 
```{r}
# Download elevations with the FREE geonames service: http://www.geonames.org/
# Geonames uses srtm tiles to download elevation data for latitudes and longitudes 
# It works very well, but tends to be slow, and you can process maximum ~6,000-10,000 records with one download
# This is why I break some large datasets into several evenly-divided chunks
# I find ~6,000 max and a higher number downloads works better than 10,000 with fewer downloads 
# Regardless, after you exceed your free "credit" allotment (aka # elev downloads), you'll get timed out of the service 
# This process is somewhat clunky, but made more efficient by having >1 username to be able to use simultaneously 
# I like to toggle between ~5 usernames to get downloads I need, and it still involves a lot of waiting 

# It may be far more efficient to extract and download elevation records from rasters with the _alt layer 
```


# UDPATES TO GBIF DOWNLOAD PROCESS, FALL 2020 
I discovered for [another project](https://github.com/jlwilliamson/OLWA-BHCO/blob/main/r_script/OLWA-cowbird.Rmd) that the GBIF download process has chanced since I originally wrote this script in Fall 2019. I have NOT updated this script to reflect the new download process, but I provide this commented out example for downloading Olive Warbler records that provides the updated/correct current way to obtain GBIF records through R. 

Remember to set your GBIF password before beginning download! I've eliminated mine to protect account privacy. 
```{r}
# # Import data
# name_suggest(q="Peucedramus taeniatus", rank="species") # Taxon key: 2492276
# # For some reason $key[1] wasn't working; maybe GBIF changed data format? Regardless, key is first column 
# 
# # head(name_lookup(query = "Peucedramus taeniatus", rank="species", return = 'data'))
# 
# # rgbif formatting has changed since I last used it
# # In order to download records, now need to pass taxonkey through this pred function; see help files 
# olwa.pred <- pred("taxonKey", 2492276)
# 
# # pass olwa taxon key generated through pred function into occ_download
# # not exactly sure how to specify 'hascoordinates=TRUE', though seems this needs to happen in olwa.pred
# # (olwa.dl <- occ_download(olwa.pred, 
# #                          user="jwilliamson", 
# #                          pwd = "YOURPASSWORD", 
# #                          email = "williamson@unm.edu"))
# # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 
# 
# occ_download_meta(olwa.dl) # check download status 
# 
# # Once download is "succeeded", fetch data & pipe zip file into R as a data frame
# olwa <- occ_download_get("0033584-200613084148143", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# 
# olwa.cit <- occ_download_get("0033584-200613084148143", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
# olwa.cit$download # prints one-line output with DOI
# 
# write.csv(olwa, file = "olwa.csv")
# olwa <- read.csv("olwa.csv", header= TRUE)
```


---

# Download from GBIF in R, import data, and calculate upper and lower elevation limits

----

# PATAGONA GIGAS 
***OUT OF CURIOSITY: I want to download Patagona records, and georeference known elevations to plot them against each other. 
```{r}
# Import data
name_suggest(q="Patagona gigas", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form; taxonKey & hasCoordinates must be in character string
# (pgig.dl <- occ_download("taxonKey=2476964", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
      ## COMMENT THIS OUT ONCE DONE SO YOU DON'T RE-DOWNLOAD EVERY TIME

occ_download_meta(pgig.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
pgig <- occ_download_get("0001000-190813142620410", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

pgig.cit <- occ_download_get("0001000-190813142620410", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
pgig.cit$download # prints one-line output with DOI

write.csv(pgig, file = "pgig.csv")
#pgig <- read.csv("/Users/Jessie/Dropbox (MSBbirds)/Rdirectory/ENSM/pgig.csv", header= TRUE)
```

```{r}
# Clean data  
pgig.sub <- subset(pgig, select=sc) # subset data w/ criteria defined in sc
pgig.sub <- pgig.sub[which(pgig.sub$species == "Patagona gigas"),] # verify only desired species
pgig.sub <- pgig.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
pgig.sub <- pgig.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
pgig.sub <- pgig.sub[which(!pgig.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
pgig.sub <- pgig.sub[which(!pgig.sub$decimalLongitude == "0"), ] # Drop lon values of 0
pgig.sub <- pgig.sub[which(!pgig.sub$month == "NA"), ] # Drop NA months
pgig.sub <- pgig.sub[which(!pgig.sub$countryCode == "NA"), ] # Drop NA countries
colnames(pgig.sub)[colnames(pgig.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
pgig.sub <- pgig.sub[order(-pgig.sub$coord_uncert), ] # sort by coordinate uncertainty
pgig.sub <- subset(pgig.sub, pgig.sub$coord_uncert < 3000 | is.na(pgig.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]

# Species-specific region adjustments 
pgig.sub <- pgig.sub[which(!pgig.sub$countryCode == "US"), ] # Exclude US records (from zoos)
pgig.sub <- pgig.sub[which(!pgig.sub$countryCode == "CO"), ] # Exclude Colombia records (kinda weird/outliery)
#pgig.sub <- pgig.sub[which(!pgig.sub$countryCode == "NL"), ] # Exclude NL records (wtf are these)

# split into mini data frames to be able to run rgbif:
pgig.split <- split(pgig.sub, (seq(nrow(pgig.sub))-1) %/% 5000) # splits data into chunks of 5000 (10k too big)
# leye.split.unlist <- do.call(rbind.data.frame, leye.split) # unsplits and makes a data frame 

pgig0 <- as.data.frame(pgig.split$"0")
pgig1 <- as.data.frame(pgig.split$"1")
pgig2 <- as.data.frame(pgig.split$"2")

# get elevs from rgbif:
pgig.e0 <- elevation(pgig0, elevation_model="srtm3", username="jwilliamson0110")
pgig.e1 <- elevation(pgig1, elevation_model="srtm3", username="jwilliamson0110")
pgig.e2 <- elevation(pgig2, elevation_model="srtm3", username="cgadekgmail")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# write all to .csv
write.csv(pgig.e0, file = "pgig.e0.csv")
write.csv(pgig.e1, file = "pgig.e1.csv")
write.csv(pgig.e2, file = "pgig.e2.csv")

# rbind mini data frames together again
pgig.all <- rbind(pgig.e0, pgig.e1, pgig.e2) # good, same length as pgig.sub

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
pgig.qc <- pgig.all
pgig.qc$elev_diff <- (pgig.qc$elevation-pgig.qc$elevation_geonames) # Make elev_diff variable 
pgig.qc <- pgig.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
pgig.qc <- pgig.qc[order(-pgig.qc$elev_diff), ] # sort by elev_diff
pgig.qc <- subset(pgig.qc, pgig.qc$elev_diff < 300 | is.na(pgig.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
pgig.elevs <- pgig.qc %>% filter(!is.na(elevation)) # existing elev
pgig.noelev <- pgig.qc %>% filter(is.na(elevation)) # no original elevs
pgig.elevs$final_elev <- pgig.elevs$elevation # add final_elev, assign elevation values to it 
pgig.noelev$final_elev <- pgig.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
pgig.final <- rbind(pgig.elevs, pgig.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
pgig.final <- pgig.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
pgig.final <- pgig.final[order(-pgig.final$month, -pgig.final$final_elev), ] # sort by month
pgig.final <- pgig.final[which(!pgig.final$final_elev == "-32768"), ] # get rid of weird elevs
write.csv(pgig.final, file = "pgig.final.csv")
save(pgig.final, file="pgig.final.RData") # save as Rdata object so you don't have to do it every time
pgig.final <- read.csv("pgig.final.csv", header= TRUE)
load("pgig.final.RData") # to load .RData file

# Get a table of max elevs split by month: 
# pgig.max <- print(distinct(pgig.final %>% group_by(month) %>% top_n(1, final_elev)))
# pgig.min <- print(distinct(pgig.final %>% group_by(month) %>% top_n(-1, final_elev)))
  # note: some duplicate elevs correspond to distinct lat/lon coords and thus can't be removed

```

Map above added from this tutorial: https://rspatial.org/raster/sdm/2_sdm_occdata.html#data-cleaning

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

pgig.final <- pgig.final[ , !(colnames(pgig.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(pgig.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
pgig.final <- pgig.final[!dup, ] # drop duplicate records

# Plot points to verify no oddities in the data
data(wrld_simpl)
plot(wrld_simpl, axes=TRUE, col="white") # SOUTH AMERICA: xlim=c(-80,70), ylim=c(-60,10), axes=TRUE, 
# box() # restore the box around the map
points(pgig.final$lon, pgig.final$lat, col='orange', pch=20, cex=0.75) # add points
points(pgig.final$lon, pgig.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# --------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=pgig.final, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="pgig")
p <- p + theme_classic()
print(p)

# subset by country for data exploration and wrangling
pgig.cl <- pgig.final[which(pgig.final$countryCode == "CL"), ] # Chile only
pgig.ar <- pgig.final[which(pgig.final$countryCode == "AR"), ] # Argentina only
pgig.bo <- pgig.final[which(pgig.final$countryCode == "BO"), ] # Bolivia only
pgig.ec <- pgig.final[which(pgig.final$countryCode == "EC"), ] # Ecuador only
pgig.pe <- pgig.final[which(pgig.final$countryCode == "PE"), ] # Peru only


# Country-specific year-round elev distribution
p <- ggplot() # Chile
p <- p + geom_boxplot(data=pgig.cl, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Patagona gigas - Chile")
p <- p + theme_classic()
print(p)

p <- ggplot() # Argentina
p <- p + geom_boxplot(data=pgig.ar, aes(x=month, y=final_elev, group=pgig.ar$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Patagona gigas - Argentina")
p <- p + theme_classic()
print(p)

p <- ggplot() # Bolivia
p <- p + geom_boxplot(data=pgig.bo, aes(x=month, y=final_elev, group=pgig.bo$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Patagona gigas - Bolivia")
p <- p + theme_classic()
print(p)

p <- ggplot() # Ecuador
p <- p + geom_boxplot(data=pgig.ec, aes(x=month, y=final_elev, group=pgig.ec$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Patagona gigas - Ecudaor")
p <- p + theme_classic()
print(p)

p <- ggplot() # Peru
p <- p + geom_boxplot(data=pgig.pe, aes(x=month, y=final_elev, group=pgig.pe$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Patagona gigas - Peru")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
pgig.nona <- subset(pgig.final, select=oa) 
is.na(pgig.nona) # need no NAs to run outlier function 

pgig.nona.cl <- subset(pgig.cl, select=oa) # get no NA col subset of just Chile dataa (for breeding dist)
pgig.nandes <- rbind(pgig.pe, pgig.bo) # combine peru and bolivia datasets to calculate nonbreeding dist
pgig.nandes.nona <- subset(pgig.nandes, select=oa) # remove NA columns

# subset by breeding and non-breeding season 
pgig.b <- pgig.nona.cl[which(pgig.nona.cl$month==10 | pgig.nona.cl$month==11), ] # breeding Nov-Dec LOW 
  # I made breeding season just breeding records from CHILE 
pgig.nb <- pgig.nandes.nona[which(pgig.nandes.nona$month==6 | pgig.nandes.nona$month==7), ] # nb June-July HIGH

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=pgig.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: Patagona (Chile)")
p <- p + theme_classic()
print(p)

boxplot(pgig.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=pgig.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: Patagona (Bolivia & Peru")
p <- p + theme_classic()
print(p)

boxplot(pgig.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
pgig.b.out <- FindOutliers(pgig.b, r=1.5); pgig.b.out # Detect outliers
pgig.b <- pgig.b[-pgig.b.out$rownum,] # remove the outliers
  # I chose to remove ALL r=1.5 Patagona outliers. Either these represent breeding range extensions of upward 
  # limits, or they're sightings of P. gig at higher elevs during breeding season. 

pgig.nb.out <- FindOutliers(pgig.nb, r=1.5); pgig.nb.out # Detect outliers
pgig.nb <- pgig.nb[-pgig.nb.out$rownum,] 
    # I chose to remove ALL r=1.5 outliers where Patagona has been seen at really low elevations.
    # All are contradictory to what we know (e.g. Patagona at 254 m in La Molina, Lima is crazy)

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
pgig.nb.elevs <- BreedingElevs(pgig.nb); pgig.nb.elevs # passed the reverse df into functions to get low breed
pgig.b.elevs <- NonbreedingElevs(pgig.b); pgig.b.elevs # passed reverse df into funtion to get high nb
pgig.elev.range <- cbind(pgig.b.elevs, pgig.nb.elevs); pgig.elev.range
pgig.elev.range["species"] <- "Patagona_gigas_gigas"
pgig.elev.range <- pgig.elev.range[, c(5,1,2,3,4)]; pgig.elev.range  # reorder columns 
write.csv(pgig.elev.range, file = "pgig.elev.range.csv")

# High Range = nonbreeding (June-July)
# Low range = breeding (Oct-Nov) # this is peak breeding in Chile; note that breeding is later farther north
```


-----------


# WHITE-SIDED HILLSTAR
```{r}
# Import data
name_suggest(q="Oreotrochilus leucopleurus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(oreo.dl <- occ_download("taxonKey=2476680", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(oreo.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
oreo <- occ_download_get("0014795-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

oreo.cit <- occ_download_get("0014795-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
oreo.cit$download # prints one-line output with DOI

write.csv(oreo, file = "oreo.csv")
oreo <- read.csv("oreo.csv", header= TRUE)
```

```{r}
# Clean data  
oreo.sub <- subset(oreo, select=sc) # subset data w/ criteria defined in sc
oreo.sub <- oreo.sub[which(oreo.sub$species == "Oreotrochilus leucopleurus"),] # verify only desired species
oreo.sub <- oreo.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
oreo.sub <- oreo.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
oreo.sub <- oreo.sub[which(!oreo.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
oreo.sub <- oreo.sub[which(!oreo.sub$decimalLongitude == "0"), ] # Drop lon values of 0
oreo.sub <- oreo.sub[which(!oreo.sub$month == "NA"), ] # Drop NA months
oreo.sub <- oreo.sub[which(!oreo.sub$countryCode == "NA"), ] # Drop NA countries
colnames(oreo.sub)[colnames(oreo.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
oreo.sub <- oreo.sub[order(-oreo.sub$coord_uncert), ] # sort by coordinate uncertainty
oreo.sub <- subset(oreo.sub, oreo.sub$coord_uncert < 3000 | is.na(oreo.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert

# Species-specific region adjustments 
oreo.sub <- oreo.sub[which(!oreo.sub$institutionCode == "APN-AR"), ] # Exclude some weird records
oreo.sub <- oreo.sub[which(!oreo.sub$institutionCode == "SMF"), ] # Exclude more weird records
oreo.sub <- oreo.sub[which(!oreo.sub$basisOfRecord == "UNKNOWN"), ] # Exclude moreeee weird records
oreo.sub <- oreo.sub[which(oreo.sub$countryCode == "CL"), ] # Include Chile only
    # Note: I don't think I just want to include birds in Chile because we know O. leucopleurus is austral 
    # migrant; we just don't know to what degree. 

# Fetch elevations with elevation() from rgbif
oreo.getelev <- elevation(oreo.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
oreo.qc <- oreo.getelev
oreo.qc$elev_diff <- (oreo.qc$elevation-oreo.qc$elevation_geonames) # Make elev_diff variable 
oreo.qc <- oreo.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
oreo.qc <- oreo.qc[order(-oreo.qc$elev_diff), ] # sort by elev_diff
oreo.qc <- subset(oreo.qc, oreo.qc$elev_diff < 300 | is.na(oreo.qc$elev_diff)) 
oreo.qc <- subset(oreo.qc, oreo.qc$elev_diff > -300 | is.na(oreo.qc$elev_diff))  # drop negative values
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
oreo.elevs <- oreo.qc %>% filter(!is.na(elevation)) # existing elev
oreo.noelev <- oreo.qc %>% filter(is.na(elevation)) # no original elevs
oreo.elevs$final_elev <- oreo.elevs$elevation # add final_elev, assign elevation values to it 
oreo.noelev$final_elev <- oreo.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
oreo.final <- rbind(oreo.elevs, oreo.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
oreo.final <- oreo.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
oreo.final <- oreo.final[order(-oreo.final$month, -oreo.final$final_elev), ] # sort by month
oreo.final <- oreo.final[which(!oreo.final$final_elev == "-32768"), ] # get rid of weird elevs
write.csv(oreo.final, file = "oreo.final.csv")
oreo.final <- read.csv("oreo.final.csv", header= TRUE)
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE

oreo.final <- oreo.final[ , !(colnames(oreo.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(oreo.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
oreo.final <- oreo.final[!dup, ] # drop duplicate records

# Plot points to verify no oddities in the data
data(wrld_simpl)
plot(wrld_simpl, axes=TRUE, col="white") # SOUTH AMERICA: xlim=c(-80,70), ylim=c(-60,10), axes=TRUE, 
# box() # restore the box around the map
points(oreo.final$lon, oreo.final$lat, col='orange', pch=20, cex=0.75) # add points
points(oreo.final$lon, oreo.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# --------


# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=oreo.final, aes(x=month, y=final_elev, group=oreo.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="oreo")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
oreo.nona <- subset(oreo.final, select=oa) 
is.na(oreo.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
oreo.b <- oreo.nona[which(oreo.nona$month==11 | oreo.nona$month==12), ] # breeding Nov-Dec
oreo.nb <- oreo.nona[which(oreo.nona$month==5 | oreo.nona$month==6), ] # non-breeding April-May-June

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=oreo.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: oreo")
p <- p + theme_classic()
print(p)

boxplot(oreo.b$final_elev, range = 3, main="range = 3") # Breeding lumped; check outlier threshold 
    # Problem with this is that those 4409 m observations come from MANY years; top threshold is NOT outlier
    # Additionally, low threshold of 499 m is consistent with Jaramillo published records; also NOT outlier

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=oreo.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: oreo")
p <- p + theme_classic()
print(p)

boxplot(oreo.nb$final_elev, range = 1.5, main="range = 1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
oreo.b.out <- FindOutliers(oreo.b, r=3); oreo.b.out # Detect outliers
# Neither lower nor upper detected outliers are true outliers and should not be removed 

oreo.nb.out <- FindOutliers(oreo.nb, r=1.5); oreo.nb.out # Detect outliers
    # No outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
oreo.b.elevs <- BreedingElevs(oreo.b)
oreo.nb.elevs <- NonbreedingElevs(oreo.nb)
oreo.elev.range <- cbind(oreo.nb.elevs, oreo.b.elevs); oreo.elev.range
oreo.elev.range["species"] <- "Oreotrochilus_leucopleurus"
oreo.elev.range <- oreo.elev.range[, c(5,1,2,3,4)]; oreo.elev.range  # reorder columns 
write.csv(oreo.elev.range, file = "oreo.elev.range.csv")

# High Range = breeding 
# Low range = non-breeding  

# Whole distribution: 
# Low bound high = highest (.max) of May-June-July dates = 3664 m (high for July)
```




# SULPHUR-BELLIED WARBLER
```{r}
# Import data
name_suggest(q="Phylloscopus griseolus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
#(phgr.dl <- occ_download("taxonKey=2493062", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(phgr.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
phgr <- occ_download_get("0001509-190813142620410", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

phgr.cit <- occ_download_get("0001509-190813142620410", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
phgr.cit$download # prints one-line output with DOI

write.csv(phgr, file = "phgr.csv")
phgr <- read.csv("phgr.csv", header= TRUE)
```

```{r}
# Clean data  
phgr.sub <- subset(phgr, select=sc) # subset data w/ criteria defined in sc
phgr.sub <- phgr.sub[which(phgr.sub$species == "Phylloscopus griseolus"),] # verify only desired species
phgr.sub <- phgr.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
phgr.sub <- phgr.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
phgr.sub <- phgr.sub[which(!phgr.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
phgr.sub <- phgr.sub[which(!phgr.sub$decimalLongitude == "0"), ] # Drop lon values of 0
phgr.sub <- phgr.sub[which(!phgr.sub$month == "NA"), ] # Drop NA months
phgr.sub <- phgr.sub[which(!phgr.sub$countryCode == "NA"), ] # Drop NA countries
colnames(phgr.sub)[colnames(phgr.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
phgr.sub <- phgr.sub[order(-phgr.sub$coord_uncert), ] # sort by coordinate uncertainty
phgr.sub <- subset(phgr.sub, phgr.sub$coord_uncert < 3000 | is.na(phgr.sub$coord_uncert)) 
    # Drop coord_uncert values >5000 *and* keep NA values for coord_uncert

# Species-specific region adjustments 
phgr.sub <- phgr.sub[which(phgr.sub$countryCode == "IN"), ] # Keep only India records 

# Fetch elevations with elevation() from rgbif
phgr.getelev <- elevation(phgr.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
phgr.qc <- phgr.getelev
phgr.qc$elev_diff <- (phgr.qc$elevation-phgr.qc$elevation_geonames) # Make elev_diff variable 
phgr.qc <- phgr.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
phgr.qc <- phgr.qc[order(-phgr.qc$elev_diff), ] # sort by elev_diff
phgr.qc <- subset(phgr.qc, phgr.qc$elev_diff < 300 | is.na(phgr.qc$elev_diff)) 
phgr.qc <- subset(phgr.qc, phgr.qc$elev_diff > -300 | is.na(phgr.qc$elev_diff))  # drop negative values
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
phgr.elevs <- phgr.qc %>% filter(!is.na(elevation)) # existing elev
phgr.noelev <- phgr.qc %>% filter(is.na(elevation)) # no original elevs
phgr.elevs$final_elev <- phgr.elevs$elevation # add final_elev, assign elevation values to it 
phgr.noelev$final_elev <- phgr.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
phgr.final <- rbind(phgr.elevs, phgr.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
phgr.final <- phgr.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
phgr.final <- phgr.final[order(-phgr.final$month, -phgr.final$final_elev), ] # sort by month
phgr.final <- phgr.final[which(!phgr.final$final_elev == "-32768"), ] # get rid of weird elevs
write.csv(phgr.final, file = "phgr.final.csv")
phgr.final <- read.csv("phgr.final.csv", header= TRUE)
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

phgr.final <- phgr.final[ , !(colnames(phgr.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(phgr.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
phgr.final <- phgr.final[!dup, ] # drop duplicate records

# Plot points to verify no oddities in the data
data(wrld_simpl)
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(50,100), ylim=c(0,50)) 
# box() # restore the box around the map
points(phgr.final$lon, phgr.final$lat, col='orange', pch=20, cex=0.75) # add points
points(phgr.final$lon, phgr.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# filter map points that fall outside desired area:
phgr.final <- subset(phgr.final, phgr.final$longitude < 88) 
  # keep only breeding latitudes west of -88 

# --------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=phgr.final, aes(x=month, y=final_elev, group=phgr.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="phgr")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
phgr.nona <- subset(phgr.final, select=oa) 
is.na(phgr.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
phgr.b <- phgr.nona[which(phgr.nona$month==6 | phgr.nona$month==7), ] # Breeding = June-July
phgr.nb <- phgr.nona[which(phgr.nona$month==11 | phgr.nona$month==12), ] # Non-breeding = Dec-Jan

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phgr.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: phgr")
p <- p + theme_classic()
print(p)

boxplot(phgr.b$final_elev, range = 1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phgr.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: phgr")
p <- p + theme_classic()
print(p)

boxplot(phgr.nb$final_elev, range=3, main="range=3") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
phgr.b.out <- FindOutliers(phgr.b, r=1.5); phgr.b.out # Detect outliers
phgr.b <- phgr.b[-phgr.b.out$rownum,] # remove the outliers by calling row numbers they correspond to 

phgr.nb.out <- FindOutliers(phgr.nb, r=3); phgr.nb.out # Detect outliers
    # No outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
phgr.b.elevs <- BreedingElevs(phgr.b)
phgr.nb.elevs <- NonbreedingElevs(phgr.nb)
phgr.elev.range <- cbind(phgr.nb.elevs, phgr.b.elevs); phgr.elev.range
phgr.elev.range["species"] <- "Phylloscopus_griseolus"
phgr.elev.range <- phgr.elev.range[, c(5,1,2,3,4)]; phgr.elev.range  # reorder columns 
write.csv(phgr.elev.range, file = "phgr.elev.range.csv")

# High Range = breeding
# Low range = non-breeding 

# used LLL for table 
```




# COMMON REDSHANK
```{r}
# Import data
name_suggest(q="Tringa totanus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(core.dl <- occ_download("taxonKey=2481714", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(core.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
core <- occ_download_get("0015971-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

core.cit <- occ_download_get("0015971-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
core.cit$download # prints one-line output with DOI

write.csv(core, file = "core.csv")
core <- read.csv("core.csv", header= TRUE)
```

```{r}
# Clean data  
core.sub <- subset(core, select=sc) # subset data w/ criteria defined in sc
core.sub <- core.sub[which(core.sub$species == "Tringa totanus"),] # verify only desired species
core.sub <- core.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
core.sub <- core.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
core.sub <- core.sub[which(!core.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
core.sub <- core.sub[which(!core.sub$decimalLongitude == "0"), ] # Drop lon values of 0
core.sub <- core.sub[which(!core.sub$month == "NA"), ] # Drop NA months
core.sub <- core.sub[which(!core.sub$countryCode == "NA"), ] # Drop NA countries
colnames(core.sub)[colnames(core.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
core.sub <- core.sub[order(-core.sub$coord_uncert), ] # sort by coordinate uncertainty
core.sub <- subset(core.sub, core.sub$coord_uncert < 3000 | is.na(core.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]

# Species-specific region adjustments 
#core.sub <- core.sub[which(!core.sub$countryCode == "SE"), ] # Exclude SE
#core.sub <- core.sub[which(!core.sub$countryCode == "NO"), ] # Exclude NO
core.sub <- subset(core.sub, subset = core.sub$countryCode %in% c("PK", "IN", "NP", "BT")) # keep countries 


# Too big to run alone; need to split into a few chunks 

core.split <- split(core.sub, (seq(nrow(core.sub))-1) %/% 6000) # splits data into chunks of 6000 (10k too big)
# leye.split.unlist <- do.call(rbind.data.frame, leye.split) # unsplits and makes a data frame 

core0 <- as.data.frame(core.split$"0")
core1 <- as.data.frame(core.split$"1")
core2 <- as.data.frame(core.split$"2")

# Fetch elevations with elevation() from rgbif
core.e0 <- elevation(core0, elevation_model="srtm3", username="jwilliamson0110")
core.e1 <- elevation(core1, elevation_model="srtm3", username="jwilliamson0110")
core.e2 <- elevation(core2, elevation_model="srtm3", username="cgadekgmail")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# write all to .csv
write.csv(core.e0, file = "core.e0.csv")
write.csv(core.e1, file = "core.e1.csv")
write.csv(core.e2, file = "core.e2.csv")

core.all <- rbind(core.e0, core.e1, core.e2) # should be same length as core.sub

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
core.qc <- core.all
core.qc$elev_diff <- (core.qc$elevation-core.qc$elevation_geonames) # Make elev_diff variable 
core.qc <- core.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
core.qc <- core.qc[order(-core.qc$elev_diff), ] # sort by elev_diff
core.qc <- subset(core.qc, core.qc$elev_diff < 300 | is.na(core.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
core.elevs <- core.qc %>% filter(!is.na(elevation)) # existing elev
core.noelev <- core.qc %>% filter(is.na(elevation)) # no original elevs
core.elevs$final_elev <- core.elevs$elevation # add final_elev, assign elevation values to it 
core.noelev$final_elev <- core.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
core.final <- rbind(core.elevs, core.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
core.final <- core.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
core.final <- core.final[order(-core.final$month, -core.final$final_elev), ] # sort by month
core.final <- core.final[which(!core.final$final_elev == "-32768"), ] # drop ocean points
write.csv(core.final, file = "core.final.csv")
core.final <- read.csv("core.final.csv", header= TRUE)
save(core.final, file="core.final.RData") # save as Rdata object so you don't have to do it every time
# load("core.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

core.final <- core.final[ , !(colnames(core.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(core.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
core.final <- core.final[!dup, ] # drop duplicate records

# Plot points to verify no oddities in the data
data(wrld_simpl)
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(50,100), ylim=c(0,50)) 
# box() # restore the box around the map
points(core.final$lon, core.final$lat, col='orange', pch=20, cex=0.75) # add points
points(core.final$lon, core.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility
# Should be PK, IN, NP, BT

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=core.final, aes(x=month, y=final_elev, group=core.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="core")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
core.nona <- subset(core.final, select=oa) 
is.na(core.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
core.b <- core.nona[which(core.nona$month==5 | core.nona$month==6), ] # breeding May-June (high)
core.nb <- core.nona[which(core.nona$month==11 | core.nona$month==12), ] # non-breeding Nov-Dec (low)

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=core.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: core")
p <- p + theme_classic()
print(p)

boxplot(core.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=core.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: core")
p <- p + theme_classic()
print(p)

boxplot(core.nb$final_elev, range=4, main="range=4") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
core.b.out <- FindOutliers(core.b, r=1.5); core.b.out # Detect outliers
  # NOTE: I didn't remove outliers for breeding season because I'm using published Grimmet limits 
  # but important: Grimmet notes high elev breeding only; these records suggest breeding at coast
 

core.nb.out <- FindOutliers(core.nb, r=4); core.nb.out # Detect outliers
  # note very conservative threshold 
core.nb <- core.nb[c(-core.nb.out$rownum[1], -core.nb.out$rownum[2]),] # remove just two outlier value
  # Note: Grimmet et al. 1999 notes that CORE ULL is 915 m in Nepal, but records clearly show presence at 1281 m
  # across multiple years. I kept the outlier threshold conservative at r=4 and removed only 1 outlier value of     # ~2660 m, but left those at 1281 m.

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
core.b.elevs <- BreedingElevs(core.b)
core.nb.elevs <- NonbreedingElevs(core.nb)
core.elev.range <- cbind(core.nb.elevs, core.b.elevs); core.elev.range
core.elev.range["species"] <- "Tringa_totanus"
core.elev.range <- core.elev.range[, c(5,1,2,3,4)]; core.elev.range  # reorder columns 
write.csv(core.elev.range, file = "core.elev.range.csv")

# High Range = breeding (May-June)
# Low range = non-breeding (Nov-Dec)

## Only used LLL and ULL value in table
```


# WHITE-CAPPED WATER REDSTART - INDIA
```{r}
# Import data
name_suggest(q="Chaimarrornis leucocephalus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(wcwr.dl <- occ_download("taxonKey=2492482", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(wcwr.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
wcwr <- occ_download_get("0016041-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

wcwr.cit <- occ_download_get("0016041-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
wcwr.cit$download # prints one-line output with DOI

write.csv(wcwr, file = "wcwr.csv")
wcwr <- read.csv("wcwr.csv", header= TRUE)
```

```{r}
# Clean data  
wcwr.sub <- subset(wcwr, select=sc) # subset data w/ criteria defined in sc
wcwr.sub <- wcwr.sub[which(wcwr.sub$species == "Chaimarrornis leucocephalus"),] # verify only desired species
wcwr.sub <- wcwr.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
wcwr.sub <- wcwr.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
wcwr.sub <- wcwr.sub[which(!wcwr.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
wcwr.sub <- wcwr.sub[which(!wcwr.sub$decimalLongitude == "0"), ] # Drop lon values of 0
wcwr.sub <- wcwr.sub[which(!wcwr.sub$month == "NA"), ] # Drop NA months
wcwr.sub <- wcwr.sub[which(!wcwr.sub$countryCode == "NA"), ] # Drop NA countries
colnames(wcwr.sub)[colnames(wcwr.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
wcwr.sub <- wcwr.sub[order(-wcwr.sub$coord_uncert), ] # sort by coordinate uncertainty
wcwr.sub <- subset(wcwr.sub, wcwr.sub$coord_uncert < 3000 | is.na(wcwr.sub$coord_uncert)) 
    # Drop coord_uncert values >5000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 5000 | is.na(p$coord_uncert),]

# Species-specific region adjustments 
wcwr.sub <- wcwr.sub[which(wcwr.sub$countryCode == "IN"), ] # Keep only India

# Fetch elevations with elevation() from rgbif
wcwr.getelev <- elevation(wcwr.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
wcwr.qc <- wcwr.getelev
wcwr.qc$elev_diff <- (wcwr.qc$elevation-wcwr.qc$elevation_geonames) # Make elev_diff variable 
wcwr.qc <- wcwr.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
wcwr.qc <- wcwr.qc[order(-wcwr.qc$elev_diff), ] # sort by elev_diff
wcwr.qc <- subset(wcwr.qc, wcwr.qc$elev_diff < 300 | is.na(wcwr.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
wcwr.elevs <- wcwr.qc %>% filter(!is.na(elevation)) # existing elev
wcwr.noelev <- wcwr.qc %>% filter(is.na(elevation)) # no original elevs
wcwr.elevs$final_elev <- wcwr.elevs$elevation # add final_elev, assign elevation values to it 
wcwr.noelev$final_elev <- wcwr.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
wcwr.final <- rbind(wcwr.elevs, wcwr.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
wcwr.final <- wcwr.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
wcwr.final <- wcwr.final[order(-wcwr.final$month, -wcwr.final$final_elev), ] # sort by month
wcwr.final <- wcwr.final[which(!wcwr.final$final_elev == "-32768"), ] # drop ocean points
write.csv(wcwr.final, file = "wcwr.final.csv")
save(wcwr.final, file="wcwr.final.RData") # save as Rdata object so you don't have to do it every time
wcwr.final <- read.csv("wcwr.final.csv", header= TRUE)
# load("wcwr.final.RData") # to load .RData file

# Get a table of max elevs split by month: 
wcwr.max <- print(distinct(wcwr.final %>% group_by(month) %>% top_n(n=1, wt=final_elev)))
wcwr.min <- print(distinct(wcwr.final %>% group_by(month) %>% top_n(-1, final_elev)))
  # note: some duplicate elevs correspond to distinct lat/lon coords and thus can't be removed
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

wcwr.final <- wcwr.final[ , !(colnames(wcwr.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(wcwr.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
wcwr.final <- wcwr.final[!dup, ] # drop duplicate records
write.csv(wcwr.final, file = "wcwr.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(10,45)) 
points(wcwr.final$lon, wcwr.final$lat, col='orange', pch=20, cex=0.75) # add points
points(wcwr.final$lon, wcwr.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=wcwr.final, aes(x=month, y=final_elev, group=wcwr.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="wcwr")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
wcwr.nona <- subset(wcwr.final, select=oa) 
is.na(wcwr.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
wcwr.b <- wcwr.nona[which(wcwr.nona$month==6 | wcwr.nona$month==7), ] # breeding June-July (Range: May-Aug)
wcwr.nb <- wcwr.nona[which(wcwr.nona$month==12 | wcwr.nona$month==1), ] # nonbreeding Dec-Jan

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=wcwr.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: wcwr")
p <- p + theme_classic()
print(p)

boxplot(wcwr.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=wcwr.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: wcwr")
p <- p + theme_classic()
print(p)

boxplot(wcwr.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
wcwr.b.out <- FindOutliers(wcwr.b, r=1.5); wcwr.b.out # Detect outliers
wcwr.b <- wcwr.b[-wcwr.b.out$rownum,] # remove the outliers 
  # Note: I remove these outliers but am not using the breeding season limit from this rgbif analysis

wcwr.nb.out <- FindOutliers(wcwr.nb, r=1.5); wcwr.nb.out # Detect outliers
wcwr.nb <- wcwr.nb[-wcwr.nb.out$rownum,] # remove the outliers by calling row numbers they correspond to 
  

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
wcwr.b.elevs <- BreedingElevs(wcwr.b)
#wcwr.b.elevs <- RoundTo(wcwr.b.elevs, multiple=5, FUN=round); wcwr.b.elevs
wcwr.nb.elevs <- NonbreedingElevs(wcwr.nb)
#wcwr.nb.elevs <- RoundTo(wcwr.nb.elevs, multiple=5, FUN=round); wcwr.nb.elevs
wcwr.elev.range <- cbind(wcwr.nb.elevs, wcwr.b.elevs); wcwr.elev.range
wcwr.elev.range["species"] <- "Chaimarrornis_leucocephalus"
wcwr.elev.range <- wcwr.elev.range[, c(5,1,2,3,4)]; wcwr.elev.range  # reorder columns 
write.csv(wcwr.elev.range, file = "wcwr.elev.range.csv")

# High Range = breeding (May-June)
# Low range = non-breeding (Nov-Dec)
```



# DAURIAN REDSTART
```{r}
# Import data
name_suggest(q="Phoenicurus auroreus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(dare <- occ_download("taxonKey=5231223", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(dare) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
dare <- occ_download_get("0016099-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

dare.cit <- occ_download_get("0016099-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
dare.cit$download # prints one-line output with DOI

write.csv(dare, file = "dare.csv")
dare <- read.csv("dare.csv", header= TRUE)
```

```{r}
# Clean data  
dare.sub <- subset(dare, select=sc) # subset data w/ criteria defined in sc
dare.sub <- dare.sub[which(dare.sub$species == "Phoenicurus auroreus"),] # verify only desired species
dare.sub <- dare.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
dare.sub <- dare.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
dare.sub <- dare.sub[which(!dare.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
dare.sub <- dare.sub[which(!dare.sub$decimalLongitude == "0"), ] # Drop lon values of 0
dare.sub <- dare.sub[which(!dare.sub$month == "NA"), ] # Drop NA months
dare.sub <- dare.sub[which(!dare.sub$countryCode == "NA"), ] # Drop NA countries
colnames(dare.sub)[colnames(dare.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
dare.sub <- dare.sub[order(-dare.sub$coord_uncert), ] # sort by coordinate uncertainty
dare.sub <- subset(dare.sub, dare.sub$coord_uncert < 3000 | is.na(dare.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert >3000 | is.na(p$coord_uncert),]

# Species-specific region adjustments 
dare.sub <- subset(dare.sub, subset = dare.sub$countryCode %in% c("CN", "NP", "BT", "IN")) # keep these 

# Fetch elevations with elevation() from rgbif
dare.getelev <- elevation(dare.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
dare.qc <- dare.getelev
dare.qc$elev_diff <- (dare.qc$elevation-dare.qc$elevation_geonames) # Make elev_diff variable 
dare.qc <- dare.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
dare.qc <- dare.qc[order(-dare.qc$elev_diff), ] # sort by elev_diff
dare.qc <- subset(dare.qc, dare.qc$elev_diff < 300 | is.na(dare.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
dare.elevs <- dare.qc %>% filter(!is.na(elevation)) # existing elev
dare.noelev <- dare.qc %>% filter(is.na(elevation)) # no original elevs
dare.elevs$final_elev <- dare.elevs$elevation # add final_elev, assign elevation values to it 
dare.noelev$final_elev <- dare.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
dare.final <- rbind(dare.elevs, dare.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
dare.final <- dare.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
dare.final <- dare.final[order(-dare.final$month, -dare.final$final_elev), ] # sort by month
dare.final <- dare.final[which(!dare.final$final_elev == "-32768"), ] # drop ocean points
write.csv(dare.final, file = "dare.final.csv")
save(dare.final, file="dare.final.RData") # save as Rdata object so you don't have to do it every time
dare.final <- read.csv("dare.final.csv", header= TRUE)
# load("dare.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

dare.final <- dare.final[ , !(colnames(dare.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(dare.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
dare.final <- dare.final[!dup, ] # drop duplicate records

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,140), ylim=c(10,55)) # zoomed in
points(dare.final$lon, dare.final$lat, col='orange', pch=20, cex=0.75) # add points
points(dare.final$lon, dare.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility
# CH, NP, BT, IN

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=dare.final, aes(x=month, y=final_elev, group=dare.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="dare")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
dare.nona <- subset(dare.final, select=oa) 
is.na(dare.nona) # need no NAs to run outlier function 

#dare.in <- dare.final[which(dare.final$countryCode == "IN"), ] # India only
#dare.in.nona <- subset(dare.in, select=oa)

# subset by breeding and non-breeding season  
dare.b <- dare.nona[which(dare.nona$month==6 | dare.nona$month==7), ] # breeds May-August HIGh
dare.nb <- dare.nona[which(dare.nona$month==12 | dare.nona$month==1), ] # nonbreeding Dec-Jan LOW

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=dare.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: dare")
p <- p + theme_classic()
print(p)

boxplot(dare.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=dare.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: dare")
p <- p + theme_classic()
print(p)

boxplot(dare.nb$final_elev, range=5, main="range=5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
dare.b.out <- FindOutliers(dare.b, r=1.5); dare.b.out # Detect outliers
dare.b <- dare.b[-dare.b.out$rownum,] # remove the outliers
  # I removed all outliers 

dare.nb.out <- FindOutliers(dare.nb, r=5); dare.nb.out # Detect outliers with a SUPER conservative threshold
  # (not sure why so many points in what seem to be a continuous range show up as outliers...?)
dare.nb <- dare.nb[-dare.nb.out$rownum,] # remove the outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
dare.b.elevs <- BreedingElevs(dare.b)
dare.nb.elevs <- NonbreedingElevs(dare.nb)
dare.elev.range <- cbind(dare.nb.elevs, dare.b.elevs); dare.elev.range
dare.elev.range["species"] <- "Phoenicurus_auroreus"
dare.elev.range <- dare.elev.range[, c(5,1,2,3,4)]; dare.elev.range  # reorder columns 
write.csv(dare.elev.range, file = "dare.elev.range.csv")
```



# BLACK REDSTART
```{r}
# Import data
name_suggest(q="Phoenicurus ochruros", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(blre.dl <- occ_download("taxonKey=5739315", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))

#(blre.dl.in <- occ_download("taxonKey=5739315", "hasCoordinate=TRUE", "country=IN", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(blre.dl) # check download status 
#occ_download_meta(blre.dl.in) # check download status for India-only dataset

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
blre <- occ_download_get("0016121-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="")
#blre.india <- occ_download_get("0016126-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="")

blre.cit <- occ_download_get("0016121-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
blre.cit$download # prints one-line output with DOI
#blre.cit.india <- occ_download_get("0016126-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="")
#blre.cit.india$download  # get DOI for india-only dataset

write.csv(blre, file = "blre.csv")
blre <- read.csv("blre.csv", header= TRUE)
```

```{r}
# Clean data  
blre.sub <- subset(blre, select=sc) # subset data w/ criteria defined in sc
blre.sub <- blre.sub[which(blre.sub$species == "Phoenicurus ochruros"),] # verify only desired species
blre.sub <- blre.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
blre.sub <- blre.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
blre.sub <- blre.sub[which(!blre.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
blre.sub <- blre.sub[which(!blre.sub$decimalLongitude == "0"), ] # Drop lon values of 0
blre.sub <- blre.sub[which(!blre.sub$month == "NA"), ] # Drop NA months
blre.sub <- blre.sub[which(!blre.sub$countryCode == "NA"), ] # Drop NA countries
colnames(blre.sub)[colnames(blre.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
blre.sub <- blre.sub[order(-blre.sub$coord_uncert), ] # sort by coordinate uncertainty
blre.sub <- subset(blre.sub, blre.sub$coord_uncert < 3000 | is.na(blre.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]

# Species-specific region adjustments 
blre.sub <- blre.sub[which(blre.sub$countryCode == "IN"), ] # India only 

# Too big to get elevs at once; split into multiple data frames
blre.split <- split(blre.sub, (seq(nrow(blre.sub))-1) %/% 6000) # splits data into chunks of 6000 (10k too big)
# blre.split.unlist <- do.call(rbind.data.frame, blre.split) # unsplits and makes a data frame 

blre0 <- as.data.frame(blre.split$"0")
blre1 <- as.data.frame(blre.split$"1")
blre2 <- as.data.frame(blre.split$"2")

# get elevs from rgbif (omg worse code ever kill me)
blre.e0 <- elevation(blre0, elevation_model="srtm3", username="jwilliamson0110")
blre.e1 <- elevation(blre1, elevation_model="srtm3", username="selina1")
blre.e2 <- elevation(blre2, elevation_model="srtm3", username="jwilliamson0110")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# write all to .csv
write.csv(blre.e0, file = "blre.e0.csv")
write.csv(blre.e1, file = "blre.e1.csv")
write.csv(blre.e2, file = "blre.e2.csv")

# rbind mini data frames together again
blre.all <- rbind(blre.e0, blre.e1, blre.e2) # good, same length as blre.sub
  # for some reason this isn't the same number as blre.sub

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
blre.qc <- blre.all
blre.qc$elev_diff <- (blre.qc$elevation-blre.qc$elevation_geonames) # Make elev_diff variable 
blre.qc <- blre.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
blre.qc <- blre.qc[order(-blre.qc$elev_diff), ] # sort by elev_diff
blre.qc <- subset(blre.qc, blre.qc$elev_diff < 300 | is.na(blre.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
blre.elevs <- blre.qc %>% filter(!is.na(elevation)) # existing elev
blre.noelev <- blre.qc %>% filter(is.na(elevation)) # no original elevs
blre.elevs$final_elev <- blre.elevs$elevation # add final_elev, assign elevation values to it 
blre.noelev$final_elev <- blre.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
blre.final <- rbind(blre.elevs, blre.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
blre.final <- blre.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
blre.final <- blre.final[order(-blre.final$month, -blre.final$final_elev), ] # sort by month
blre.final <- blre.final[which(!blre.final$final_elev == "-32768"), ] # drop ocean points
write.csv(blre.final, file = "blre.final.csv")
save(blre.final, file="blre.final.RData") # save as Rdata object so you don't have to do it every time
blre.final <- read.csv("blre.final.csv", header= TRUE)
# load("blre.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

blre.final <- blre.final[ , !(colnames(blre.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(blre.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
blre.final <- blre.final[!dup, ] # drop duplicate records
write.csv(blre.final, file = "blre.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) 
points(blre.final$lon, blre.final$lat, col='orange', pch=20, cex=0.75) # add points
points(blre.final$lon, blre.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility
# Note that Borders of Kashmir are in dispute between India, Pakistan, and China

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=blre.final, aes(x=month, y=final_elev, group=blre.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="blre")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
blre.nona <- subset(blre.final, select=oa) 
is.na(blre.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
blre.b <- blre.nona[which(blre.nona$month==6 | blre.nona$month==7), ] # Breeding May-August HIGH
blre.nb <- blre.nona[which(blre.nona$month==12 | blre.nona$month==1), ] # nonbreeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=blre.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: blre")
p <- p + theme_classic()
print(p)

boxplot(blre.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=blre.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: blre")
p <- p + theme_classic()
print(p)

boxplot(blre.nb$final_elev, range=6.5, main="range=6.5") # Non-breeding lumped; check outlier threshold 
  # Extremely conservative threshold set based on where there appeared to be a semi-natural break in occurrence
  # Records for November and December when looking at ggplot2 version (ranges by month)

# OUTLIER ANALYSIS AND REMOVAL 
blre.b.out <- FindOutliers(blre.b, r=1.5); blre.b.out # Detect outliers
blre.b <- blre.b[-blre.b.out$rownum,] # remove the outliers by calling row numbers they correspond to 

blre.nb.out <- FindOutliers(blre.nb, r=6.5); blre.nb.out # Detect outliers
blre.nb <- blre.nb[-blre.nb.out$rownum,] # remove the outliers by calling row numbers they correspond to 


# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
blre.b.elevs <- BreedingElevs(blre.b)
blre.nb.elevs <- NonbreedingElevs(blre.nb)
blre.elev.range <- cbind(blre.nb.elevs, blre.b.elevs); blre.elev.range
blre.elev.range["species"] <- "Phoenicurus_ochruros"
blre.elev.range <- blre.elev.range[, c(5,1,2,3,4)]; blre.elev.range  # reorder columns 
write.csv(blre.elev.range, file = "blre.elev.range.csv")
 
```


# SMOKY WARBLER 
```{r}
# Import data
name_suggest(q="Phylloscopus fuligiventer", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(smwa.dl <- occ_download("taxonKey=2493079", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(smwa.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
smwa <- occ_download_get("0016133-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

smwa.cit <- occ_download_get("0016133-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
smwa.cit$download # prints one-line output with DOI

write.csv(smwa, file = "smwa.csv")
smwa <- read.csv("smwa.csv", header= TRUE)
```

```{r}
# Clean data  
smwa.sub <- subset(smwa, select=sc) # subset data w/ criteria defined in sc
smwa.sub <- smwa.sub[which(smwa.sub$species == "Phylloscopus fuligiventer"),] # verify only desired species
smwa.sub <- smwa.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
smwa.sub <- smwa.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
smwa.sub <- smwa.sub[which(!smwa.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
smwa.sub <- smwa.sub[which(!smwa.sub$decimalLongitude == "0"), ] # Drop lon values of 0
smwa.sub <- smwa.sub[which(!smwa.sub$month == "NA"), ] # Drop NA months
smwa.sub <- smwa.sub[which(!smwa.sub$countryCode == "NA"), ] # Drop NA countries
colnames(smwa.sub)[colnames(smwa.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
smwa.sub <- smwa.sub[order(-smwa.sub$coord_uncert), ] # sort by coordinate uncertainty
smwa.sub <- subset(smwa.sub, smwa.sub$coord_uncert < 3000 | is.na(smwa.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]

# Species-specific region adjustments 
smwa.sub <- smwa.sub[which(smwa.sub$countryCode == "NP"), ] # Keep Nepal only 

# Fetch elevations with elevation() from rgbif
smwa.getelev <- elevation(smwa.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
smwa.qc <- smwa.getelev
smwa.qc$elev_diff <- (smwa.qc$elevation-smwa.qc$elevation_geonames) # Make elev_diff variable 
smwa.qc <- smwa.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
smwa.qc <- smwa.qc[order(-smwa.qc$elev_diff), ] # sort by elev_diff
smwa.qc <- subset(smwa.qc, smwa.qc$elev_diff < 300 | is.na(smwa.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
smwa.elevs <- smwa.qc %>% filter(!is.na(elevation)) # existing elev
smwa.noelev <- smwa.qc %>% filter(is.na(elevation)) # no original elevs
smwa.elevs$final_elev <- smwa.elevs$elevation # add final_elev, assign elevation values to it 
smwa.noelev$final_elev <- smwa.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
smwa.final <- rbind(smwa.elevs, smwa.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
smwa.final <- smwa.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
smwa.final <- smwa.final[order(-smwa.final$month, -smwa.final$final_elev), ] # sort by month
smwa.final <- smwa.final[which(!smwa.final$final_elev == "-32768"), ] # drop ocean points
write.csv(smwa.final, file = "smwa.final.csv")
save(smwa.final, file="smwa.final.RData") # save as Rdata object so you don't have to do it every time
smwa.final <- read.csv("smwa.final.csv", header= TRUE)
# load("smwa.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

smwa.final <- smwa.final[ , !(colnames(smwa.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(smwa.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
smwa.final <- smwa.final[!dup, ] # drop duplicate records
write.csv(smwa.final, file = "smwa.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45))  
points(smwa.final$lon, smwa.final$lat, col='orange', pch=20, cex=0.75) # add points
points(smwa.final$lon, smwa.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=smwa.final, aes(x=month, y=final_elev, group=smwa.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="smwa")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
smwa.nona <- subset(smwa.final, select=oa) 
# is.na(smwa.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
smwa.b <- smwa.nona[which(smwa.nona$month==5 | smwa.nona$month==6 | smwa.nona$month==7 ), ] 
  # breeding estimated May-August; including as many months as possible because little data 
smwa.nb <- smwa.nona[which(smwa.nona$month==12 | smwa.nona$month==1), ]# nonbreeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=smwa.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: smwa")
p <- p + theme_classic()
print(p)

boxplot(smwa.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=smwa.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: smwa")
p <- p + theme_classic()
print(p)

boxplot(smwa.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
smwa.b.out <- FindOutliers(smwa.b, r=1.5); smwa.b.out # Detect outliers
# no outliers - plus, not including breeding data from rgbif

smwa.nb.out <- FindOutliers(smwa.nb, r=1.5); smwa.nb.out # Detect outliers
smwa.nb <- smwa.nb[-smwa.nb.out$rownum,] # remove the outliers


# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
smwa.b.elevs <- BreedingElevs(smwa.b)
smwa.nb.elevs <- NonbreedingElevs(smwa.nb)
smwa.elev.range <- cbind(smwa.nb.elevs, smwa.b.elevs); smwa.elev.range
smwa.elev.range["species"] <- "Phylloscopus_fuligiventer"
smwa.elev.range <- smwa.elev.range[, c(5,1,2,3,4)]; smwa.elev.range  # reorder columns 
write.csv(smwa.elev.range, file = "smwa.elev.range.csv")
 
```



# IBISBILL
```{r}
# Import data
name_suggest(q="Ibidorhyncha struthersii", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(ibis.dl <- occ_download("taxonKey=2480336", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(ibis.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
ibis <- occ_download_get("0016135-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

ibis.cit <- occ_download_get("0016135-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
ibis.cit$download # prints one-line output with DOI

write.csv(ibis, file = "ibis.csv")
ibis <- read.csv("ibis.csv", header= TRUE)
```

```{r}
# Clean data  
ibis.sub <- subset(ibis, select=sc) # subset data w/ criteria defined in sc
ibis.sub <- ibis.sub[which(ibis.sub$species == "Ibidorhyncha struthersii"),] # verify only desired species
ibis.sub <- ibis.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
ibis.sub <- ibis.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
ibis.sub <- ibis.sub[which(!ibis.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
ibis.sub <- ibis.sub[which(!ibis.sub$decimalLongitude == "0"), ] # Drop lon values of 0
ibis.sub <- ibis.sub[which(!ibis.sub$month == "NA"), ] # Drop NA months
ibis.sub <- ibis.sub[which(!ibis.sub$countryCode == "NA"), ] # Drop NA countries
colnames(ibis.sub)[colnames(ibis.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
ibis.sub <- ibis.sub[order(-ibis.sub$coord_uncert), ] # sort by coordinate uncertainty
ibis.sub <- subset(ibis.sub, ibis.sub$coord_uncert < 3000 | is.na(ibis.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]

# Species-specific region adjustments 
ibis.sub <- ibis.sub[which(ibis.sub$countryCode == "NP"), ] # Keep Nepal only

# Fetch elevations with elevation() from rgbif
ibis.getelev <- elevation(ibis.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
ibis.qc <- ibis.getelev
ibis.qc$elev_diff <- (ibis.qc$elevation-ibis.qc$elevation_geonames) # Make elev_diff variable 
ibis.qc <- ibis.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
ibis.qc <- ibis.qc[order(-ibis.qc$elev_diff), ] # sort by elev_diff
ibis.qc <- subset(ibis.qc, ibis.qc$elev_diff < 300 | is.na(ibis.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
ibis.elevs <- ibis.qc %>% filter(!is.na(elevation)) # existing elev
ibis.noelev <- ibis.qc %>% filter(is.na(elevation)) # no original elevs
ibis.elevs$final_elev <- ibis.elevs$elevation # add final_elev, assign elevation values to it 
ibis.noelev$final_elev <- ibis.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
ibis.final <- rbind(ibis.elevs, ibis.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
ibis.final <- ibis.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
ibis.final <- ibis.final[order(-ibis.final$month, -ibis.final$final_elev), ] # sort by month
ibis.final <- ibis.final[which(!ibis.final$final_elev == "-32768"), ] # drop ocean points
write.csv(ibis.final, file = "ibis.final.csv")
save(ibis.final, file="ibis.final.RData") # save as Rdata object so you don't have to do it every time
ibis.final <- read.csv("ibis.final.csv", header= TRUE)
# load("ibis.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

ibis.final <- ibis.final[ , !(colnames(ibis.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(ibis.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
ibis.final <- ibis.final[!dup, ] # drop duplicate records
write.csv(ibis.final, file = "ibis.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(ibis.final$lon, ibis.final$lat, col='orange', pch=20, cex=0.75) # add points
points(ibis.final$lon, ibis.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ---------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=ibis.final, aes(x=month, y=final_elev, group=ibis.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="ibis")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
ibis.nona <- subset(ibis.final, select=oa) 
is.na(ibis.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
ibis.b <- ibis.nona[which(ibis.nona$month==3 | ibis.nona$month==4 | ibis.nona$month==5), ] # Breeding March-May 
ibis.nb <- ibis.nona[which(ibis.nona$month==11 | ibis.nona$month==12), ] # nonbreeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=ibis.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: ibis")
p <- p + theme_classic()
print(p)

boxplot(ibis.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=ibis.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: ibis")
p <- p + theme_classic()
print(p)

boxplot(ibis.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 

# OUTLIER ANALYSIS AND REMOVAL 
ibis.b.out <- FindOutliers(ibis.b, r=1.5); ibis.b.out # Detect outliers
ibis.nb.out <- FindOutliers(ibis.nb, r=1.5); ibis.nb.out # Detect outliers
# no outliers for either period

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
ibis.b.elevs <- BreedingElevs(ibis.b)
ibis.nb.elevs <- NonbreedingElevs(ibis.nb)
ibis.elev.range <- cbind(ibis.nb.elevs, ibis.b.elevs); ibis.elev.range
ibis.elev.range["species"] <- "Ibidorhyncha_struthersii"
ibis.elev.range <- ibis.elev.range[, c(5,1,2,3,4)]; ibis.elev.range  # reorder columns 
write.csv(ibis.elev.range, file = "ibis.elev.range.csv")
 
```



# BROWN-HEADED GULL
```{r}
# Import data
name_suggest(q="Chroicocephalus brunnicephalus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(labr.dl <- occ_download("taxonKey=6065809", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(labr.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
labr <- occ_download_get("0016147-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

labr.cit <- occ_download_get("0016147-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
labr.cit$download # prints one-line output with DOI

write.csv(labr, file = "labr.csv")
labr <- read.csv("labr.csv", header= TRUE)
```

```{r}
# Clean data  
labr.sub <- subset(labr, select=sc) # subset data w/ criteria defined in sc
labr.sub <- labr.sub[which(labr.sub$species == "Chroicocephalus brunnicephalus"),] # verify only desired species
labr.sub <- labr.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
labr.sub <- labr.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
labr.sub <- labr.sub[which(!labr.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
labr.sub <- labr.sub[which(!labr.sub$decimalLongitude == "0"), ] # Drop lon values of 0
labr.sub <- labr.sub[which(!labr.sub$month == "NA"), ] # Drop NA months
labr.sub <- labr.sub[which(!labr.sub$countryCode == "NA"), ] # Drop NA countries
colnames(labr.sub)[colnames(labr.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
labr.sub <- labr.sub[order(-labr.sub$coord_uncert), ] # sort by coordinate uncertainty
labr.sub <- subset(labr.sub, labr.sub$coord_uncert < 3000 | is.na(labr.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]

# Species-specific region adjustments 
labr.sub <- labr.sub[which(labr.sub$countryCode == "IN"), ] # Keep India only 
  # India should give good representation of high breeding AND coastal winter descent

# Fetch elevations with elevation() from rgbif
labr.getelev <- elevation(labr.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
labr.qc <- labr.getelev
labr.qc$elev_diff <- (labr.qc$elevation-labr.qc$elevation_geonames) # Make elev_diff variable 
labr.qc <- labr.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
labr.qc <- labr.qc[order(-labr.qc$elev_diff), ] # sort by elev_diff
labr.qc <- subset(labr.qc, labr.qc$elev_diff < 300 | is.na(labr.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
labr.elevs <- labr.qc %>% filter(!is.na(elevation)) # existing elev
labr.noelev <- labr.qc %>% filter(is.na(elevation)) # no original elevs
labr.elevs$final_elev <- labr.elevs$elevation # add final_elev, assign elevation values to it 
labr.noelev$final_elev <- labr.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
labr.final <- rbind(labr.elevs, labr.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
labr.final <- labr.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
labr.final <- labr.final[order(-labr.final$month, -labr.final$final_elev), ] # sort by month
labr.final <- labr.final[which(!labr.final$final_elev == "-32768"), ] # drop ocean points
write.csv(labr.final, file = "labr.final.csv")
save(labr.final, file="labr.final.RData") # save as Rdata object so you don't have to do it every time
labr.final <- read.csv("labr.final.csv", header= TRUE)
# load("labr.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

labr.final <- labr.final[ , !(colnames(labr.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(labr.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
labr.final <- labr.final[!dup, ] # drop duplicate records
write.csv(labr.final, file = "labr.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(labr.final$lon, labr.final$lat, col='orange', pch=20, cex=0.75) # add points
points(labr.final$lon, labr.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility
# India only; note borders of Kashmir are in dispute

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=labr.final, aes(x=month, y=final_elev, group=labr.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="labr")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
labr.nona <- subset(labr.final, select=oa) 
# is.na(labr.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
labr.b <- labr.nona[which(labr.nona$month==6 | labr.nona$month==7), ] # breeding June and July HIGH
labr.nb <- labr.nona[which(labr.nona$month==1 | labr.nona$month==2), ] # nonbreeding 

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=labr.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: labr")
p <- p + theme_classic()
print(p)

boxplot(labr.b$final_elev, range=3, main="range=3") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=labr.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: labr")
p <- p + theme_classic()
print(p)

boxplot(labr.nb$final_elev, range=3, main="range=3") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
labr.b.out <- FindOutliers(labr.b, r=3); labr.b.out # Detect outliers
labr.b <- labr.b[-labr.b.out$rownum,] # remove outliers

labr.nb.out <- FindOutliers(labr.nb, r=3); labr.nb.out # Detect outliers
labr.nb <- labr.nb[-labr.nb.out$rownum,] # remove outliers


# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
labr.b.elevs <- BreedingElevs(labr.b)
labr.nb.elevs <- NonbreedingElevs(labr.nb)
labr.elev.range <- cbind(labr.nb.elevs, labr.b.elevs); labr.elev.range
labr.elev.range["species"] <- "Chroicocephalus_brunnicephalus"
labr.elev.range <- labr.elev.range[, c(5,1,2,3,4)]; labr.elev.range  # reorder columns 
write.csv(labr.elev.range, file = "labr.elev.range.csv")
 
```


# TICKELL'S LEAF WARBLER
```{r}
# Import data
name_suggest(q="Phylloscopus affinis", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
#(tick.dl <- occ_download("taxonKey=2493068", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(tick.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
tick <- occ_download_get("0001504-190813142620410", overwrite=TRUE) %>% occ_download_import() 

tick.cit <- occ_download_get("0001504-190813142620410", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
tick.cit$download # prints one-line output with DOI

write.csv(tick, file = "tick.csv")
tick <- read.csv("tick.csv", header= TRUE)
```

```{r}
# Clean data  
tick.sub <- subset(tick, select=sc) # subset data w/ criteria defined in sc
tick.sub <- tick.sub[which(tick.sub$species == "Phylloscopus affinis"),] # verify only desired species
tick.sub <- tick.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
tick.sub <- tick.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
tick.sub <- tick.sub[which(!tick.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
tick.sub <- tick.sub[which(!tick.sub$decimalLongitude == "0"), ] # Drop lon values of 0
tick.sub <- tick.sub[which(!tick.sub$month == "NA"), ] # Drop NA months
tick.sub <- tick.sub[which(!tick.sub$countryCode == "NA"), ] # Drop NA countries
colnames(tick.sub)[colnames(tick.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
tick.sub <- tick.sub[order(-tick.sub$coord_uncert), ] # sort by coordinate uncertainty
tick.sub <- subset(tick.sub, tick.sub$coord_uncert < 3000 | is.na(tick.sub$coord_uncert)) 
    # Drop coord_uncert values >5000 *and* keep NA values for coord_uncert

# Species-specific region adjustments 
tick.sub <- tick.sub[which(tick.sub$countryCode == "NP"), ] # Keep only Nepal records 

# Fetch elevations with elevation() from rgbif
tick.getelev <- elevation(tick.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
tick.qc <- tick.getelev
tick.qc$elev_diff <- (tick.qc$elevation-tick.qc$elevation_geonames) # Make elev_diff variable 
tick.qc <- tick.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
tick.qc <- tick.qc[order(-tick.qc$elev_diff), ] # sort by elev_diff
tick.qc <- subset(tick.qc, tick.qc$elev_diff < 300 | is.na(tick.qc$elev_diff)) 
tick.qc <- subset(tick.qc, tick.qc$elev_diff > -300 | is.na(tick.qc$elev_diff))  # drop negative values
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
tick.elevs <- tick.qc %>% filter(!is.na(elevation)) # existing elev
tick.noelev <- tick.qc %>% filter(is.na(elevation)) # no original elevs
tick.elevs$final_elev <- tick.elevs$elevation # add final_elev, assign elevation values to it 
tick.noelev$final_elev <- tick.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
tick.final <- rbind(tick.elevs, tick.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
tick.final <- tick.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
tick.final <- tick.final[order(-tick.final$month, -tick.final$final_elev), ] # sort by month
tick.final <- tick.final[which(!tick.final$final_elev == "-32768"), ] # get rid of weird elevs
write.csv(tick.final, file = "tick.final.csv")
save(tick.final, file="tick.final.RData") # save as Rdata object so you don't have to do it every time
tick.final <- read.csv("tick.final.csv", header= TRUE)
# load("tick.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

tick.final <- tick.final[ , !(colnames(tick.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(tick.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
tick.final <- tick.final[!dup, ] # drop duplicate records
write.csv(tick.final, file = "tick.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(tick.final$lon, tick.final$lat, col='orange', pch=20, cex=0.75) # add points
points(tick.final$lon, tick.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility
# Nepal only

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=tick.final, aes(x=month, y=final_elev, group=tick.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="tick")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
tick.nona <- subset(tick.final, select=oa) 
# is.na(tick.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
tick.b <- tick.nona[which(tick.nona$month==6 | tick.nona$month==7 | tick.nona$month==8), ] # Breeding May-August
tick.nb <- tick.nona[which(tick.nona$month==11 | tick.nona$month==12 | tick.nona$month==1), ] # Nonbreeding 

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=tick.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: tick")
p <- p + theme_classic()
print(p)

boxplot(tick.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=tick.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: tick")
p <- p + theme_classic()
print(p)

boxplot(tick.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
tick.b.out <- FindOutliers(tick.b, r=1.5); tick.b.out # Detect outliers
# no outliers (also not using breeding rgbif limits)
tick.nb.out <- FindOutliers(tick.nb, r=1.5); tick.nb.out # Detect outliers
tick.nb <- tick.nb[-tick.nb.out$rownum,] # remove outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
tick.b.elevs <- BreedingElevs(tick.b)
tick.nb.elevs <- NonbreedingElevs(tick.nb)
tick.elev.range <- cbind(tick.nb.elevs, tick.b.elevs); tick.elev.range
tick.elev.range["species"] <- "Phylloscopus_affinis"
tick.elev.range <- tick.elev.range[, c(5,1,2,3,4)]; tick.elev.range  # reorder columns 
write.csv(tick.elev.range, file = "tick.elev.range.csv")
 
```



# COMMON TERN (India population)
```{r}
# Import data
name_suggest(q="Sterna hirundo", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(cote.dl <- occ_download("taxonKey=9367409", "hasCoordinate=TRUE", "country=IN", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 
# NOTE: COTE dataset was HUGE, so I just downloaded GBIF records for India (what I want here)

occ_download_meta(cote.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
cote <- occ_download_get("0016436-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

cote.cit <- occ_download_get("0016436-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
cote.cit$download # prints one-line output with DOI

write.csv(cote, file = "cote.csv")
# cote <- read.csv("cote.csv", header= TRUE)
```

```{r}
# Clean data  
cote.sub <- subset(cote, select=sc) # subset data w/ criteria defined in sc
cote.sub <- cote.sub[which(cote.sub$species == "Sterna hirundo"),] # verify only desired species
cote.sub <- cote.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
cote.sub <- cote.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
cote.sub <- cote.sub[which(!cote.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
cote.sub <- cote.sub[which(!cote.sub$decimalLongitude == "0"), ] # Drop lon values of 0
cote.sub <- cote.sub[which(!cote.sub$month == "NA"), ] # Drop NA months
cote.sub <- cote.sub[which(!cote.sub$countryCode == "NA"), ] # Drop NA countries
colnames(cote.sub)[colnames(cote.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
cote.sub <- cote.sub[order(-cote.sub$coord_uncert), ] # sort by coordinate uncertainty
cote.sub <- subset(cote.sub, cote.sub$coord_uncert < 3000 | is.na(cote.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert

# Species-specific region adjustments 
cote.sub <- cote.sub[which(cote.sub$countryCode == "IN"), ] # Include India only; just make sure 

# Fetch elevations with elevation() from rgbif
cote.getelev <- elevation(cote.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
cote.qc <- cote.getelev
cote.qc$elev_diff <- (cote.qc$elevation-cote.qc$elevation_geonames) # Make elev_diff variable 
cote.qc <- cote.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
cote.qc <- cote.qc[order(-cote.qc$elev_diff), ] # sort by elev_diff
cote.qc <- subset(cote.qc, cote.qc$elev_diff < 300 | is.na(cote.qc$elev_diff)) 
cote.qc <- subset(cote.qc, cote.qc$elev_diff > -300 | is.na(cote.qc$elev_diff))  # drop negative values
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
cote.elevs <- cote.qc %>% filter(!is.na(elevation)) # existing elev
cote.noelev <- cote.qc %>% filter(is.na(elevation)) # no original elevs
cote.elevs$final_elev <- cote.elevs$elevation # add final_elev, assign elevation values to it 
cote.noelev$final_elev <- cote.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
cote.final <- rbind(cote.elevs, cote.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
cote.final <- cote.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
cote.final <- cote.final[order(-cote.final$month, -cote.final$final_elev), ] # sort by month
cote.final <- cote.final[which(!cote.final$final_elev == "-32768"), ] # get rid of weird elevs
write.csv(cote.final, file = "cote.final.csv")
save(cote.final, file="cote.final.RData") # save as Rdata object so you don't have to do it every time
cote.final <- read.csv("cote.final.csv", header= TRUE)
# load("cote.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

cote.final <- cote.final[ , !(colnames(cote.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(cote.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
cote.final <- cote.final[!dup, ] # drop duplicate records
write.csv(cote.final, file = "cote.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(cote.final$lon, cote.final$lat, col='orange', pch=20, cex=0.75) # add points
points(cote.final$lon, cote.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility
# India only

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=cote.final, aes(x=month, y=final_elev, group=cote.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="cote")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
cote.nona <- subset(cote.final, select=oa) 
# is.na(cote.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
cote.b <- cote.nona[which(cote.nona$month==6 | cote.nona$month==7), ] # Breeding June-July HIGH
cote.nb <- cote.nona[which(cote.nona$month==12 | cote.nona$month==11), ] # Nonbreeding 

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=cote.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: cote")
p <- p + theme_classic()
print(p)

boxplot(cote.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=cote.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: cote")
p <- p + theme_classic()
print(p)

boxplot(cote.nb$final_elev, range=15, main="range=15") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
cote.b.out <- FindOutliers(cote.b, r=1.5); cote.b.out # Detect outliers
 # no outliers

cote.nb.out <- FindOutliers(cote.nb, r=15); cote.nb.out # Detect outliers
cote.nb <- cote.nb[-cote.nb.out$rownum,] # remove outliers
  # kept the r=15 threshold VERY conservative and hit it at first natural break in points 
  # Because nearly all points are at sea level, Q3-Q1 won't be very large, meaning that large R won't impact 
  # estimate of threshold as much (hence, how high it is without hardly moving)

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
cote.b.elevs <- BreedingElevs(cote.b)
cote.nb.elevs <- NonbreedingElevs(cote.nb)
cote.elev.range <- cbind(cote.nb.elevs, cote.b.elevs); cote.elev.range
cote.elev.range["species"] <- "Sterna_hirundo"
cote.elev.range <- cote.elev.range[, c(5,1,2,3,4)]; cote.elev.range  # reorder columns 
write.csv(cote.elev.range, file = "cote.elev.range.csv")
 
```



# OLIVE-BACKED PIPIT
```{r}
# Import data
name_suggest(q="Anthus hodgsoni", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(anho.dl <- occ_download("taxonKey=2490244", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(anho.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
anho <- occ_download_get("0016439-191105090559680", overwrite=TRUE) %>% occ_download_import() 

anho.cit <- occ_download_get("0016439-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
anho.cit$download # prints one-line output with DOI

write.csv(anho, file = "anho.csv")
anho <- read.csv("//Users/Jessie/Desktop/RDirectory/ENSM/anho.csv", stringsAsFactors=FALSE)
```

```{r}
# Clean data  
anho.sub <- subset(anho, select=sc) # subset data w/ criteria defined in sc
anho.sub <- anho.sub[which(anho.sub$species == "Anthus hodgsoni"),] # verify only desired species
anho.sub <- anho.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
anho.sub <- anho.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
anho.sub <- anho.sub[which(!anho.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
anho.sub <- anho.sub[which(!anho.sub$decimalLongitude == "0"), ] # Drop lon values of 0
anho.sub <- anho.sub[which(!anho.sub$month == "NA"), ] # Drop NA months
anho.sub <- anho.sub[which(!anho.sub$countryCode == "NA"), ] # Drop NA countries
colnames(anho.sub)[colnames(anho.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
anho.sub <- anho.sub[order(-anho.sub$coord_uncert), ] # sort by coordinate uncertainty
anho.sub <- subset(anho.sub, anho.sub$coord_uncert < 3000 | is.na(anho.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert

# Species-specific region adjustments 
anho.sub <- anho.sub[which(anho.sub$countryCode == "IN"), ] # Keep only India records (~6,500)

# Fetch elevations with elevation() from rgbif
anho.getelev <- elevation(anho.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
anho.qc <- anho.getelev
anho.qc$elev_diff <- (anho.qc$elevation-anho.qc$elevation_geonames) # Make elev_diff variable 
anho.qc <- anho.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
anho.qc <- anho.qc[order(-anho.qc$elev_diff), ] # sort by elev_diff
anho.qc <- subset(anho.qc, anho.qc$elev_diff < 300 | is.na(anho.qc$elev_diff)) 
anho.qc <- subset(anho.qc, anho.qc$elev_diff > -300 | is.na(anho.qc$elev_diff))  # drop negative values
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
anho.elevs <- anho.qc %>% filter(!is.na(elevation)) # existing elev
anho.noelev <- anho.qc %>% filter(is.na(elevation)) # no original elevs
anho.elevs$final_elev <- anho.elevs$elevation # add final_elev, assign elevation values to it 
anho.noelev$final_elev <- anho.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
anho.final <- rbind(anho.elevs, anho.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
anho.final <- anho.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
anho.final <- anho.final[order(-anho.final$month, -anho.final$final_elev), ] # sort by month
anho.final <- anho.final[which(!anho.final$final_elev == "-32768"), ] # get rid of weird elevs
write.csv(anho.final, file = "anho.final.csv")
save(anho.final, file="anho.final.RData") # save as Rdata object so you don't have to do it every time
anho.final <- read.csv("anho.final.csv", header= TRUE)
an# load("anho.final.RData") # to load .RData file

# Get a table of max elevs split by month: 
anho.max <- print(distinct(anho.final %>% group_by(month) %>% top_n(1, final_elev)))
anho.min <- print(distinct(anho.final %>% group_by(month) %>% top_n(-1, final_elev)))
  # note: some duplicate elevs correspond to distinct lat/lon coords and thus can't be removed
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

anho.final <- anho.final[ , !(colnames(anho.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(anho.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
anho.final <- anho.final[!dup, ] # drop duplicate records
write.csv(anho.final, file = "anho.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(anho.final$lon, anho.final$lat, col='orange', pch=20, cex=0.75) # add points
points(anho.final$lon, anho.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility
# India only 

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=anho.final, aes(x=month, y=final_elev, group=anho.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="anho")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
anho.nona <- subset(anho.final, select=oa) 
# is.na(anho.nona) # need no NAs to run outlier function 

anho.b <- anho.nona[which(anho.nona$month==6 | anho.nona$month==7), ] # breeding March-July 
anho.nb <- anho.nona[which(anho.nona$month==12 | anho.nona$month==1), ] # non-breeding Nov-Dec

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=anho.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: anho")
p <- p + theme_classic()
print(p)

boxplot(anho.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=anho.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: anho")
p <- p + theme_classic()
print(p)

boxplot(anho.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
anho.b.out <- FindOutliers(anho.b, r=1.5); anho.b.out # Detect outliers
anho.b <- anho.b[-anho.b.out$rownum,] # remove outliers

anho.nb.out <- FindOutliers(anho.nb, r=1.5); anho.nb.out # Detect outliers
anho.nb <- anho.nb[-anho.nb.out$rownum,] # remove outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
anho.b.elevs <- BreedingElevs(anho.b)
anho.nb.elevs <- NonbreedingElevs(anho.nb)
anho.elev.range <- cbind(anho.nb.elevs, anho.b.elevs); anho.elev.range
anho.elev.range["species"] <- "Anthus_hodgsoni"
anho.elev.range <- anho.elev.range[, c(5,1,2,3,4)]; anho.elev.range  # reorder columns 
write.csv(anho.elev.range, file = "anho.elev.range.csv")

# Just need LLL from rgbif
 
```


# SCALY THRUSH
```{r}
# Import data
name_suggest(q="Zoothera dauma", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
#(zoda.dl <- occ_download("taxonKey=2490890", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(zoda.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
zoda <- occ_download_get("0003734-190813142620410", overwrite=TRUE) %>% occ_download_import() 

zoda.cit <- occ_download_get("0003734-190813142620410", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
zoda.cit$download # prints one-line output with DOI

write.csv(zoda, file = "zoda.csv")
zoda <- read.csv("zoda.csv", header= TRUE)
```

```{r}
# Clean data  
zoda.sub <- subset(zoda, select=sc) # subset data w/ criteria defined in sc
zoda.sub <- zoda.sub[which(zoda.sub$species == "Zoothera dauma"),] # verify only desired species
zoda.sub <- zoda.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
zoda.sub <- zoda.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
zoda.sub <- zoda.sub[which(!zoda.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
zoda.sub <- zoda.sub[which(!zoda.sub$decimalLongitude == "0"), ] # Drop lon values of 0
zoda.sub <- zoda.sub[which(!zoda.sub$month == "NA"), ] # Drop NA months
zoda.sub <- zoda.sub[which(!zoda.sub$countryCode == "NA"), ] # Drop NA countries
colnames(zoda.sub)[colnames(zoda.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
zoda.sub <- zoda.sub[order(-zoda.sub$coord_uncert), ] # sort by coordinate uncertainty
zoda.sub <- subset(zoda.sub, zoda.sub$coord_uncert < 3000 | is.na(zoda.sub$coord_uncert)) 
    # Drop coord_uncert values >5000 *and* keep NA values for coord_uncert

# Species-specific region adjustments 
zoda.sub <- zoda.sub[which(zoda.sub$countryCode == "IN"), ] # Keep only India records 

# Fetch elevations with elevation() from rgbif
zoda.getelev <- elevation(zoda.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
zoda.qc <- zoda.getelev
zoda.qc$elev_diff <- (zoda.qc$elevation-zoda.qc$elevation_geonames) # Make elev_diff variable 
zoda.qc <- zoda.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
zoda.qc <- zoda.qc[order(-zoda.qc$elev_diff), ] # sort by elev_diff
zoda.qc <- subset(zoda.qc, zoda.qc$elev_diff < 300 | is.na(zoda.qc$elev_diff)) 
zoda.qc <- subset(zoda.qc, zoda.qc$elev_diff > -300 | is.na(zoda.qc$elev_diff))  # drop negative values
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
zoda.elevs <- zoda.qc %>% filter(!is.na(elevation)) # existing elev
zoda.noelev <- zoda.qc %>% filter(is.na(elevation)) # no original elevs
zoda.elevs$final_elev <- zoda.elevs$elevation # add final_elev, assign elevation values to it 
zoda.noelev$final_elev <- zoda.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
zoda.final <- rbind(zoda.elevs, zoda.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
zoda.final <- zoda.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
zoda.final <- zoda.final[order(-zoda.final$month, -zoda.final$final_elev), ] # sort by month
zoda.final <- zoda.final[which(!zoda.final$final_elev == "-32768"), ] # get rid of weird elevs
write.csv(zoda.final, file = "zoda.final.csv")
save(zoda.final, file="zoda.final.RData") # save as Rdata object so you don't have to do it every time
zoda.final <- read.csv("zoda.final.csv", header= TRUE)
# load("zoda.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

zoda.final <- zoda.final[ , !(colnames(zoda.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(zoda.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
zoda.final <- zoda.final[!dup, ] # drop duplicate records
write.csv(zoda.final, file = "zoda.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(zoda.final$lon, zoda.final$lat, col='orange', pch=20, cex=0.75) # add points
points(zoda.final$lon, zoda.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=zoda.final, aes(x=month, y=final_elev, group=zoda.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="zoda")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
zoda.nona <- subset(zoda.final, select=oa) 
# is.na(zoda.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
zoda.b <- zoda.nona[which(zoda.nona$month==5 | zoda.nona$month==6), ] # Breeds March-October, "varying locally"
  # Breeding range from Grimmet; my previous rgbif notes say breeding April-June
zoda.nb <- zoda.nona[which(zoda.nona$month==11 | zoda.nona$month==12), ] # nonbreeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=zoda.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: zoda")
p <- p + theme_classic()
print(p)

boxplot(zoda.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=zoda.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: zoda")
p <- p + theme_classic()
print(p)

boxplot(zoda.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 

# OUTLIER ANALYSIS AND REMOVAL 
zoda.b.out <- FindOutliers(zoda.b, r=1.5); zoda.b.out # Detect outliers
zoda.b <- zoda.b[-zoda.b.out$rownum,] # remove outliers

zoda.nb.out <- FindOutliers(zoda.nb, r=1.5); zoda.nb.out # Detect outliers
# no outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
zoda.b.elevs <- BreedingElevs(zoda.b)
zoda.nb.elevs <- NonbreedingElevs(zoda.nb)
zoda.elev.range <- cbind(zoda.nb.elevs, zoda.b.elevs); zoda.elev.range
zoda.elev.range["species"] <- "Zoothera_dauma"
zoda.elev.range <- zoda.elev.range[, c(5,1,2,3,4)]; zoda.elev.range  # reorder columns 
write.csv(zoda.elev.range, file = "zoda.elev.range.csv")
 
# Need LLL
```



# CHESTNUT-CROWNED BUSH-WARBLER
```{r}
# Import data
name_suggest(q="Cettia major", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(cema.dl <- occ_download("taxonKey=2493003", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(cema.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
cema <- occ_download_get("0016640-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

cema.cit <- occ_download_get("0016640-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
cema.cit$download # prints one-line output with DOI

write.csv(cema, file = "cema.csv")
cema <- read.csv("cema.csv", header= TRUE)
```

```{r}
# Clean data  
cema.sub <- subset(cema, select=sc) # subset data w/ criteria defined in sc
cema.sub <- cema.sub[which(cema.sub$species == "Cettia major"),] # verify only desired species
cema.sub <- cema.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
cema.sub <- cema.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
cema.sub <- cema.sub[which(!cema.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
cema.sub <- cema.sub[which(!cema.sub$decimalLongitude == "0"), ] # Drop lon values of 0
cema.sub <- cema.sub[which(!cema.sub$month == "NA"), ] # Drop NA months
cema.sub <- cema.sub[which(!cema.sub$countryCode == "NA"), ] # Drop NA countries
colnames(cema.sub)[colnames(cema.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
cema.sub <- cema.sub[order(-cema.sub$coord_uncert), ] # sort by coordinate uncertainty
cema.sub <- subset(cema.sub, cema.sub$coord_uncert < 3000 | is.na(cema.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]

# Species-specific region adjustments 
cema.sub <- cema.sub[which(cema.sub$countryCode == "NP"), ] # Keep Nepal only 

# Fetch elevations with elevation() from rgbif
cema.getelev <- elevation(cema.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
cema.qc <- cema.getelev
cema.qc$elev_diff <- (cema.qc$elevation-cema.qc$elevation_geonames) # Make elev_diff variable 
cema.qc <- cema.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
cema.qc <- cema.qc[order(-cema.qc$elev_diff), ] # sort by elev_diff
cema.qc <- subset(cema.qc, cema.qc$elev_diff < 300 | is.na(cema.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
cema.elevs <- cema.qc %>% filter(!is.na(elevation)) # existing elev
cema.noelev <- cema.qc %>% filter(is.na(elevation)) # no original elevs
cema.elevs$final_elev <- cema.elevs$elevation # add final_elev, assign elevation values to it 
cema.noelev$final_elev <- cema.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
cema.final <- rbind(cema.elevs, cema.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
cema.final <- cema.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
cema.final <- cema.final[order(-cema.final$month, -cema.final$final_elev), ] # sort by month
cema.final <- cema.final[which(!cema.final$final_elev == "-32768"), ] # drop ocean points
write.csv(cema.final, file = "cema.final.csv")
save(cema.final, file="cema.final.RData") # save as Rdata object so you don't have to do it every time
cema.final <- read.csv("cema.final.csv", header= TRUE)
load("cema.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

cema.final <- cema.final[ , !(colnames(cema.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(cema.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
cema.final <- cema.final[!dup, ] # drop duplicate records
write.csv(cema.final, file = "cema.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Nepal only
points(cema.final$lon, cema.final$lat, col='orange', pch=20, cex=0.75) # add points
points(cema.final$lon, cema.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=cema.final, aes(x=month, y=final_elev, group=cema.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="cema")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
cema.nona <- subset(cema.final, select=oa) 
# is.na(cema.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
cema.b <- cema.nona[which(cema.nona$month==6), ] # Breeding June (likely July too)
cema.nb <- cema.nona[which(cema.nona$month==1 | cema.nona$month==2 | cema.nona$month==3), ] # nonbreeding
  # Note VERY few records for this species; even fewer when subsetted by breeding and non-breeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=cema.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: cema")
p <- p + theme_classic()
print(p)

boxplot(cema.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=cema.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: cema")
p <- p + theme_classic()
print(p)

boxplot(cema.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
cema.b.out <- FindOutliers(cema.b, r=1.5); cema.b.out # Detect outliers
# no outliers 
cema.nb.out <- FindOutliers(cema.nb, r=1.5); cema.nb.out # Detect outliers
cema.nb <- cema.nb[-cema.nb.out$rownum,] # remove outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
cema.b.elevs <- BreedingElevs(cema.b)
cema.nb.elevs <- NonbreedingElevs(cema.nb)
cema.elev.range <- cbind(cema.nb.elevs, cema.b.elevs); cema.elev.range
cema.elev.range["species"] <- "Cettia_major"
cema.elev.range <- cema.elev.range[, c(5,1,2,3,4)]; cema.elev.range  # reorder columns 
write.csv(cema.elev.range, file = "cema.elev.range.csv")
 
```



# ASIAN HOUSE MARTIN 
```{r}
# Import data
name_suggest(q="Delichon dasypus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
# (deda.dl <- occ_download("taxonKey=2489220", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(deda.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
deda <- occ_download_get("0001022-190813142620410", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

deda.cit <- occ_download_get("0001022-190813142620410", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
deda.cit$download # prints one-line output with DOI

write.csv(deda, file = "deda.csv")
deda <- read.csv("deda.csv", header= TRUE)
```

```{r}
# Clean data  
deda.sub <- subset(deda, select=sc) # subset data w/ criteria defined in sc
deda.sub <- deda.sub[which(deda.sub$species == "Delichon dasypus"),] # verify only desired species
deda.sub <- deda.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
deda.sub <- deda.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
deda.sub <- deda.sub[which(!deda.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
deda.sub <- deda.sub[which(!deda.sub$decimalLongitude == "0"), ] # Drop lon values of 0
deda.sub <- deda.sub[which(!deda.sub$month == "NA"), ] # Drop NA months
deda.sub <- deda.sub[which(!deda.sub$countryCode == "NA"), ] # Drop NA countries
colnames(deda.sub)[colnames(deda.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
deda.sub <- deda.sub[order(-deda.sub$coord_uncert), ] # sort by coordinate uncertainty
deda.sub <- subset(deda.sub, deda.sub$coord_uncert < 3000 | is.na(deda.sub$coord_uncert)) 
    # Drop coord_uncert values >5000 *and* keep NA values for coord_uncert

# Species-specific region adjustments 
deda.sub <- deda.sub[which(deda.sub$countryCode == "IN"), ] # Keep only India records

# Fetch elevations with elevation() from rgbif
deda.getelev <- elevation(deda.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
deda.qc <- deda.getelev
deda.qc$elev_diff <- (deda.qc$elevation-deda.qc$elevation_geonames) # Make elev_diff variable 
deda.qc <- deda.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
deda.qc <- deda.qc[order(-deda.qc$elev_diff), ] # sort by elev_diff
deda.qc <- subset(deda.qc, deda.qc$elev_diff < 300 | is.na(deda.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
deda.elevs <- deda.qc %>% filter(!is.na(elevation)) # existing elev
deda.noelev <- deda.qc %>% filter(is.na(elevation)) # no original elevs
deda.elevs$final_elev <- deda.elevs$elevation # add final_elev, assign elevation values to it 
deda.noelev$final_elev <- deda.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
deda.final <- rbind(deda.elevs, deda.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
deda.final <- deda.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
deda.final <- deda.final[order(-deda.final$month, -deda.final$final_elev), ] # sort by month
deda.final <- deda.final[which(!deda.final$final_elev == "-32768"), ] # get rid of weird elevs
write.csv(deda.final, file = "deda.final.csv")
save(deda.final, file="deda.final.RData") # save as Rdata object so you don't have to do it every time
deda.final <- read.csv("deda.final.csv", header= TRUE)
# load("deda.final.RData") # to load .RData file
```


```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

deda.final <- deda.final[ , !(colnames(deda.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(deda.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
deda.final <- deda.final[!dup, ] # drop duplicate records
write.csv(deda.final, file = "deda.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(deda.final$lon, deda.final$lat, col='orange', pch=20, cex=0.75) # add points
points(deda.final$lon, deda.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=deda.final, aes(x=month, y=final_elev, group=deda.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="deda")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
deda.nona <- subset(deda.final, select=oa) 
# is.na(deda.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
deda.b <- deda.nona[which(deda.nona$month==5 | deda.nona$month==6), ] # Breeding May-mid-July
deda.nb <- deda.nona[which(deda.nona$month==11 | deda.nona$month==12), ] # nonbreeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=deda.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: deda")
p <- p + theme_classic()
print(p)

boxplot(deda.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=deda.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: deda")
p <- p + theme_classic()
print(p)

boxplot(deda.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
deda.b.out <- FindOutliers(deda.b, r=1.5); deda.b.out # Detect outliers
# no outliers 

deda.nb.out <- FindOutliers(deda.nb, r=1.5); deda.nb.out # Detect outliers
deda.nb <- deda.nb[-deda.nb.out$rownum,] # remove outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
deda.b.elevs <- BreedingElevs(deda.b)
deda.nb.elevs <- NonbreedingElevs(deda.nb)
deda.elev.range <- cbind(deda.nb.elevs, deda.b.elevs); deda.elev.range
deda.elev.range["species"] <- "Delichon_dasypus"
deda.elev.range <- deda.elev.range[, c(5,1,2,3,4)]; deda.elev.range  # reorder columns 
write.csv(deda.elev.range, file = "deda.elev.range.csv")
```



# ROCK BUNTING
```{r}
# Import data
name_suggest(q="Emberiza cia", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
#(robu.dl <- occ_download("taxonKey=2491498", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(robu.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
robu <- occ_download_get("0001357-190813142620410", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

robu.cit <- occ_download_get("0001357-190813142620410", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
robu.cit$download # prints one-line output with DOI

write.csv(robu, file = "robu.csv")
robu <- read.csv("robu.csv", header= TRUE)
```

```{r}
# Clean data  
robu.sub <- subset(robu, select=sc) # subset data w/ criteria defined in sc
robu.sub <- robu.sub[which(robu.sub$species == "Emberiza cia"),] # verify only desired species
robu.sub <- robu.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
robu.sub <- robu.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
robu.sub <- robu.sub[which(!robu.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
robu.sub <- robu.sub[which(!robu.sub$decimalLongitude == "0"), ] # Drop lon values of 0
robu.sub <- robu.sub[which(!robu.sub$month == "NA"), ] # Drop NA months
robu.sub <- robu.sub[which(!robu.sub$countryCode == "NA"), ] # Drop NA countries
colnames(robu.sub)[colnames(robu.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
robu.sub <- robu.sub[order(-robu.sub$coord_uncert), ] # sort by coordinate uncertainty
robu.sub <- subset(robu.sub, robu.sub$coord_uncert < 3000 | is.na(robu.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert

# Species-specific region adjustments 
robu.sub <- robu.sub[which(robu.sub$countryCode == "IN"), ] # Keep only India records (~2700)

# Fetch elevations with elevation() from rgbif
robu.getelev <- elevation(robu.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
robu.qc <- robu.getelev
robu.qc$elev_diff <- (robu.qc$elevation-robu.qc$elevation_geonames) # Make elev_diff variable 
robu.qc <- robu.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
robu.qc <- robu.qc[order(-robu.qc$elev_diff), ] # sort by elev_diff
robu.qc <- subset(robu.qc, robu.qc$elev_diff < 300 | is.na(robu.qc$elev_diff)) 
robu.qc <- subset(robu.qc, robu.qc$elev_diff > -300 | is.na(robu.qc$elev_diff))  # drop negative values
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
robu.elevs <- robu.qc %>% filter(!is.na(elevation)) # existing elev
robu.noelev <- robu.qc %>% filter(is.na(elevation)) # no original elevs
robu.elevs$final_elev <- robu.elevs$elevation # add final_elev, assign elevation values to it 
robu.noelev$final_elev <- robu.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
robu.final <- rbind(robu.elevs, robu.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
robu.final <- robu.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
robu.final <- robu.final[order(-robu.final$month, -robu.final$final_elev), ] # sort by month
robu.final <- robu.final[which(!robu.final$final_elev == "-32768"), ] # get rid of weird elevs
write.csv(robu.final, file = "robu.final.csv")
save(robu.final, file="robu.final.RData") # save as Rdata object so you don't have to do it every time
robu.final <- read.csv("robu.final.csv", header= TRUE)
# load("robu.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

robu.final <- robu.final[ , !(colnames(robu.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(robu.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
robu.final <- robu.final[!dup, ] # drop duplicate records
write.csv(robu.final, file = "robu.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(robu.final$lon, robu.final$lat, col='orange', pch=20, cex=0.75) # add points
points(robu.final$lon, robu.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=robu.final, aes(x=month, y=final_elev, group=robu.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="robu")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
robu.nona <- subset(robu.final, select=oa) 
# is.na(robu.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
robu.b <- robu.nona[which(robu.nona$month==6 | robu.nona$month==7), ] # Breeding May-August
robu.nb <- robu.nona[which(robu.nona$month==12 | robu.nona$month==1), ] # nonbreeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=robu.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: robu")
p <- p + theme_classic()
print(p)

boxplot(robu.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=robu.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: robu")
p <- p + theme_classic()
print(p)

boxplot(robu.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
robu.b.out <- FindOutliers(robu.b, r=1.5); robu.b.out # Detect outliers
robu.b <- robu.b[-robu.b.out$rownum,] # remove outliers

robu.nb.out <- FindOutliers(robu.nb, r=1.5); robu.nb.out # Detect outliers
# no outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
robu.b.elevs <- BreedingElevs(robu.b)
robu.nb.elevs <- NonbreedingElevs(robu.nb)
robu.elev.range <- cbind(robu.nb.elevs, robu.b.elevs); robu.elev.range
robu.elev.range["species"] <- "Emberiza_cia"
robu.elev.range <- robu.elev.range[, c(5,1,2,3,4)]; robu.elev.range  # reorder columns 
write.csv(robu.elev.range, file = "robu.elev.range.csv")
```



# ULTRAMARINE FLYCATCHER
```{r}
# Import data
name_suggest(q="Ficedula superciliaris", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(ulfl.dl <- occ_download("taxonKey=5231283", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(ulfl.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
ulfl <- occ_download_get("0016658-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

ulfl.cit <- occ_download_get("0016658-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
ulfl.cit$download # prints one-line output with DOI

write.csv(ulfl, file = "ulfl.csv")
ulfl <- read.csv("ulfl.csv", header= TRUE)
```

```{r}
# Clean data  
ulfl.sub <- subset(ulfl, select=sc) # subset data w/ criteria defined in sc
ulfl.sub <- ulfl.sub[which(ulfl.sub$species == "Ficedula superciliaris"),] # verify only desired species
ulfl.sub <- ulfl.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
ulfl.sub <- ulfl.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
ulfl.sub <- ulfl.sub[which(!ulfl.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
ulfl.sub <- ulfl.sub[which(!ulfl.sub$decimalLongitude == "0"), ] # Drop lon values of 0
ulfl.sub <- ulfl.sub[which(!ulfl.sub$month == "NA"), ] # Drop NA months
ulfl.sub <- ulfl.sub[which(!ulfl.sub$countryCode == "NA"), ] # Drop NA countries
colnames(ulfl.sub)[colnames(ulfl.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
ulfl.sub <- ulfl.sub[order(-ulfl.sub$coord_uncert), ] # sort by coordinate uncertainty
ulfl.sub <- subset(ulfl.sub, ulfl.sub$coord_uncert < 3000 | is.na(ulfl.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]

# Species-specific region adjustments 
ulfl.sub <- ulfl.sub[which(ulfl.sub$countryCode == "IN"), ] # Keep India only

# Fetch elevations with elevation() from rgbif
ulfl.getelev <- elevation(ulfl.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
ulfl.qc <- ulfl.getelev
ulfl.qc$elev_diff <- (ulfl.qc$elevation-ulfl.qc$elevation_geonames) # Make elev_diff variable 
ulfl.qc <- ulfl.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
ulfl.qc <- ulfl.qc[order(-ulfl.qc$elev_diff), ] # sort by elev_diff
ulfl.qc <- subset(ulfl.qc, ulfl.qc$elev_diff < 300 | is.na(ulfl.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
ulfl.elevs <- ulfl.qc %>% filter(!is.na(elevation)) # existing elev
ulfl.noelev <- ulfl.qc %>% filter(is.na(elevation)) # no original elevs
ulfl.elevs$final_elev <- ulfl.elevs$elevation # add final_elev, assign elevation values to it 
ulfl.noelev$final_elev <- ulfl.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
ulfl.final <- rbind(ulfl.elevs, ulfl.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
ulfl.final <- ulfl.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
ulfl.final <- ulfl.final[order(-ulfl.final$month, -ulfl.final$final_elev), ] # sort by month
ulfl.final <- ulfl.final[which(!ulfl.final$final_elev == "-32768"), ] # drop ocean points
write.csv(ulfl.final, file = "ulfl.final.csv")
save(ulfl.final, file="ulfl.final.RData") # save as Rdata object so you don't have to do it every time
ulfl.final <- read.csv("ulfl.final.csv", header= TRUE)
# load("ulfl.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

ulfl.final <- ulfl.final[ , !(colnames(ulfl.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(ulfl.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
ulfl.final <- ulfl.final[!dup, ] # drop duplicate records
write.csv(ulfl.final, file = "ulfl.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(ulfl.final$lon, ulfl.final$lat, col='orange', pch=20, cex=0.75) # add points
points(ulfl.final$lon, ulfl.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=ulfl.final, aes(x=month, y=final_elev, group=ulfl.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="ulfl")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
ulfl.nona <- subset(ulfl.final, select=oa) 
# is.na(ulfl.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
ulfl.b <- ulfl.nona[which(ulfl.nona$month==5 | ulfl.nona$month==6), ] # breeding mid-April to early-July
ulfl.nb <- ulfl.nona[which(ulfl.nona$month==11 | ulfl.nona$month==12), ] # nonbreeding 

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=ulfl.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: ulfl")
p <- p + theme_classic()
print(p)

boxplot(ulfl.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=ulfl.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: ulfl")
p <- p + theme_classic()
print(p)

boxplot(ulfl.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
ulfl.b.out <- FindOutliers(ulfl.b, r=1.5); ulfl.b.out # Detect outliers
ulfl.b <- ulfl.b[-ulfl.b.out$rownum,] # remove outliers

ulfl.nb.out <- FindOutliers(ulfl.nb, r=1.5); ulfl.nb.out # Detect outliers
ulfl.nb <- ulfl.nb[-ulfl.nb.out$rownum,] # remove outliers


# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
ulfl.b.elevs <- BreedingElevs(ulfl.b)
ulfl.nb.elevs <- NonbreedingElevs(ulfl.nb)
ulfl.elev.range <- cbind(ulfl.nb.elevs, ulfl.b.elevs); ulfl.elev.range
ulfl.elev.range["species"] <- "Ficedula_superciliaris"
ulfl.elev.range <- ulfl.elev.range[, c(5,1,2,3,4)]; ulfl.elev.range  # reorder columns 
write.csv(ulfl.elev.range, file = "ulfl.elev.range.csv")
 
```



# WOOD SNIPE
```{r}
# Import data
name_suggest(q="Gallinago nemoricola", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(gane.dl <- occ_download("taxonKey=2481826", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(gane.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
gane <- occ_download_get("0016662-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

gane.cit <- occ_download_get("0016662-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
gane.cit$download # prints one-line output with DOI

write.csv(gane, file = "gane.csv")
gane <- read.csv("gane.csv", header= TRUE)
```

```{r}
# Clean data  
gane.sub <- subset(gane, select=sc) # subset data w/ criteria defined in sc
gane.sub <- gane.sub[which(gane.sub$species == "Gallinago nemoricola"),] # verify only desired species
gane.sub <- gane.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
gane.sub <- gane.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
gane.sub <- gane.sub[which(!gane.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
gane.sub <- gane.sub[which(!gane.sub$decimalLongitude == "0"), ] # Drop lon values of 0
gane.sub <- gane.sub[which(!gane.sub$month == "NA"), ] # Drop NA months
gane.sub <- gane.sub[which(!gane.sub$countryCode == "NA"), ] # Drop NA countries
colnames(gane.sub)[colnames(gane.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
gane.sub <- gane.sub[order(-gane.sub$coord_uncert), ] # sort by coordinate uncertainty
gane.sub <- subset(gane.sub, gane.sub$coord_uncert < 3000 | is.na(gane.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]

# Species-specific region adjustments 
# gane.sub <- gane.sub[which(gane.sub$countryCode == "IN"), ] # Keep India only
  # I decided to keep all observations because there are so few already 

# Fetch elevations with elevation() from rgbif
gane.getelev <- elevation(gane.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
gane.qc <- gane.getelev
gane.qc$elev_diff <- (gane.qc$elevation-gane.qc$elevation_geonames) # Make elev_diff variable 
gane.qc <- gane.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
gane.qc <- gane.qc[order(-gane.qc$elev_diff), ] # sort by elev_diff
gane.qc <- subset(gane.qc, gane.qc$elev_diff < 300 | is.na(gane.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
gane.elevs <- gane.qc %>% filter(!is.na(elevation)) # existing elev
gane.noelev <- gane.qc %>% filter(is.na(elevation)) # no original elevs
gane.elevs$final_elev <- gane.elevs$elevation # add final_elev, assign elevation values to it 
gane.noelev$final_elev <- gane.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
gane.final <- rbind(gane.elevs, gane.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
gane.final <- gane.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
gane.final <- gane.final[order(-gane.final$month, -gane.final$final_elev), ] # sort by month
gane.final <- gane.final[which(!gane.final$final_elev == "-32768"), ] # drop ocean points
write.csv(gane.final, file = "gane.final.csv")
save(gane.final, file="gane.final.RData") # save as Rdata object so you don't have to do it every time
gane.final <- read.csv("gane.final.csv", header= TRUE)
# load("gane.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

gane.final <- gane.final[ , !(colnames(gane.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(gane.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
gane.final <- gane.final[!dup, ] # drop duplicate records
write.csv(gane.final, file = "gane.final.nodups.csv")

# Running zoomed out version of map below revealed one record from west Africa; drop this and re-run
gane.final <- subset(gane.final, gane.final$longitude > 50) # keep only records EAST of 50 degrees longitude

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(gane.final$lon, gane.final$lat, col='orange', pch=20, cex=0.75) # add points
points(gane.final$lon, gane.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility
# Point that looks like it's in the middle of the ocean is maybe-first record for Narcondam island; on ebird w/ photos
# Other Thailand records appear verified: one IDed by guide in N; another w/ photos noted as 4th record for Thailand

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=gane.final, aes(x=month, y=final_elev, group=gane.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="gane")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
gane.nona <- subset(gane.final, select=oa) 
# is.na(gane.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
gane.b <- gane.nona[which(gane.nona$month==5 | gane.nona$month==6), ] # Breeding April-June 
  # From Khatiwada and Chaudhary 2008
gane.nb <- gane.nona[which(gane.nona$month==11 | gane.nona$month==12 | gane.nona$month==1 | gane.nona$month==2), ]
  # nonbreeding - including as many months as possible becuase so few records 

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=gane.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: gane")
p <- p + theme_classic()
print(p)

boxplot(gane.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=gane.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: gane")
p <- p + theme_classic()
print(p)

boxplot(gane.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
gane.b.out <- FindOutliers(gane.b, r=1.5); gane.b.out # Detect outliers
gane.b <- gane.b[-gane.b.out$rownum,] # remove outliers

gane.nb.out <- FindOutliers(gane.nb, r=1.5); gane.nb.out # Detect outliers
gane.nb <- gane.nb[-gane.nb.out$rownum,] # remove outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
gane.b.elevs <- BreedingElevs(gane.b)
gane.nb.elevs <- NonbreedingElevs(gane.nb)
gane.elev.range <- cbind(gane.nb.elevs, gane.b.elevs); gane.elev.range
gane.elev.range["species"] <- "Gallinago_nemoricola"
gane.elev.range <- gane.elev.range[, c(5,1,2,3,4)]; gane.elev.range  # reorder columns 
write.csv(gane.elev.range, file = "gane.elev.range.csv")
```



# GRAY-BACKED SHRIKE
```{r}
# Import data
name_suggest(q="Lanius tephronotus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(late.dl <- occ_download("taxonKey=2492849", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(late.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
late <- occ_download_get("0016676-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

late.cit <- occ_download_get("0016676-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
late.cit$download # prints one-line output with DOI

write.csv(late, file = "late.csv")
late <- read.csv("late.csv", header= TRUE)
```

```{r}
# Clean data  
late.sub <- subset(late, select=sc) # subset data w/ criteria defined in sc
late.sub <- late.sub[which(late.sub$species == "Lanius tephronotus"),] # verify only desired species
late.sub <- late.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
late.sub <- late.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
late.sub <- late.sub[which(!late.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
late.sub <- late.sub[which(!late.sub$decimalLongitude == "0"), ] # Drop lon values of 0
late.sub <- late.sub[which(!late.sub$month == "NA"), ] # Drop NA months
late.sub <- late.sub[which(!late.sub$countryCode == "NA"), ] # Drop NA countries
colnames(late.sub)[colnames(late.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
late.sub <- late.sub[order(-late.sub$coord_uncert), ] # sort by coordinate uncertainty
late.sub <- subset(late.sub, late.sub$coord_uncert < 3000 | is.na(late.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]

# Species-specific region adjustments 
late.sub <- late.sub[which(late.sub$countryCode == "IN"), ] # Keep India only

# Fetch elevations with elevation() from rgbif
late.getelev <- elevation(late.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
late.qc <- late.getelev
late.qc$elev_diff <- (late.qc$elevation-late.qc$elevation_geonames) # Make elev_diff variable 
late.qc <- late.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
late.qc <- late.qc[order(-late.qc$elev_diff), ] # sort by elev_diff
late.qc <- subset(late.qc, late.qc$elev_diff < 300 | is.na(late.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
late.elevs <- late.qc %>% filter(!is.na(elevation)) # existing elev
late.noelev <- late.qc %>% filter(is.na(elevation)) # no original elevs
late.elevs$final_elev <- late.elevs$elevation # add final_elev, assign elevation values to it 
late.noelev$final_elev <- late.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
late.final <- rbind(late.elevs, late.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
late.final <- late.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
late.final <- late.final[order(-late.final$month, -late.final$final_elev), ] # sort by month
late.final <- late.final[which(!late.final$final_elev == "-32768"), ] # drop ocean points
write.csv(late.final, file = "late.final.csv")
save(late.final, file="late.final.RData") # save as Rdata object so you don't have to do it every time
late.final <- read.csv("late.final.csv", header= TRUE)
# load("late.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

late.final <- late.final[ , !(colnames(late.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(late.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
late.final <- late.final[!dup, ] # drop duplicate records
write.csv(late.final, file = "late.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(late.final$lon, late.final$lat, col='orange', pch=20, cex=0.75) # add points
points(late.final$lon, late.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=late.final, aes(x=month, y=final_elev, group=late.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="late")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
late.nona <- subset(late.final, select=oa) 
# is.na(late.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
late.b <- late.nona[which(late.nona$month==6 | late.nona$month==7), ] # Breeding June-July
late.nb <- late.nona[which(late.nona$month==12 | late.nona$month==1), ] # nonbreeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=late.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: late")
p <- p + theme_classic()
print(p)

boxplot(late.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=late.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: late")
p <- p + theme_classic()
print(p)

boxplot(late.nb$final_elev, range=3, main="range=3") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
late.b.out <- FindOutliers(late.b, r=1.5); late.b.out # Detect outliers
# no outliers - a little wonky maybe? Not using this breeding data, however. 

late.nb.out <- FindOutliers(late.nb, r=3); late.nb.out # Detect outliers
late.nb <- late.nb[-late.nb.out$rownum,] # remove outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
late.b.elevs <- BreedingElevs(late.b)
late.nb.elevs <- NonbreedingElevs(late.nb)
late.elev.range <- cbind(late.nb.elevs, late.b.elevs); late.elev.range
late.elev.range["species"] <- "Lanius_tephronotus"
late.elev.range <- late.elev.range[, c(5,1,2,3,4)]; late.elev.range  # reorder columns 
write.csv(late.elev.range, file = "late.elev.range.csv")
 
```



# BRANDT'S MOUNTAIN FINCH
```{r}
# Import data
name_suggest(q="Leucosticte brandti", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(bmfi.dl <- occ_download("taxonKey=2494374", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(bmfi.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
bmfi <- occ_download_get("0016679-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

bmfi.cit <- occ_download_get("0016679-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
bmfi.cit$download # prints one-line output with DOI

write.csv(bmfi, file = "bmfi.csv")
bmfi <- read.csv("//Users/Jessie/Desktop/RDirectory/ENSM/BrandtMountainFinch.csv", stringsAsFactors=FALSE)
```

```{r}
# Clean data  
bmfi.sub <- subset(bmfi, select=sc) # subset data w/ criteria defined in sc
bmfi.sub <- bmfi.sub[which(bmfi.sub$species == "Leucosticte brandti"),] # verify only desired species
bmfi.sub <- bmfi.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
bmfi.sub <- bmfi.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
bmfi.sub <- bmfi.sub[which(!bmfi.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
bmfi.sub <- bmfi.sub[which(!bmfi.sub$decimalLongitude == "0"), ] # Drop lon values of 0
bmfi.sub <- bmfi.sub[which(!bmfi.sub$month == "NA"), ] # Drop NA months
bmfi.sub <- bmfi.sub[which(!bmfi.sub$countryCode == "NA"), ] # Drop NA countries
colnames(bmfi.sub)[colnames(bmfi.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
bmfi.sub <- bmfi.sub[order(-bmfi.sub$coord_uncert), ] # sort by coordinate uncertainty
bmfi.sub <- subset(bmfi.sub, bmfi.sub$coord_uncert < 3000 | is.na(bmfi.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
count(bmfi.sub$countryCode) # Lists all countries & number of observations per country


# Species-specific region adjustments 
bmfi.sub <- subset(bmfi.sub, subset = bmfi.sub$countryCode %in% c("IN", "NP"))
  # I ideally need Pakistan only, but no observations from PK, so going to Himalayas

# Fetch elevations with elevation() from rgbif
bmfi.getelev <- elevation(bmfi.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
bmfi.qc <- bmfi.getelev
bmfi.qc$elev_diff <- (bmfi.qc$elevation-bmfi.qc$elevation_geonames) # Make elev_diff variable 
bmfi.qc <- bmfi.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
bmfi.qc <- bmfi.qc[order(-bmfi.qc$elev_diff), ] # sort by elev_diff
bmfi.qc <- subset(bmfi.qc, bmfi.qc$elev_diff < 300 | is.na(bmfi.qc$elev_diff)) 
bmfi.qc <- subset(bmfi.qc, bmfi.qc$elev_diff > -300 | is.na(bmfi.qc$elev_diff))  # drop negative values
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
bmfi.elevs <- bmfi.qc %>% filter(!is.na(elevation)) # existing elev
bmfi.noelev <- bmfi.qc %>% filter(is.na(elevation)) # no original elevs
bmfi.elevs$final_elev <- bmfi.elevs$elevation # add final_elev, assign elevation values to it 
bmfi.noelev$final_elev <- bmfi.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
bmfi.final <- rbind(bmfi.elevs, bmfi.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
bmfi.final <- bmfi.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
bmfi.final <- bmfi.final[order(-bmfi.final$month, -bmfi.final$final_elev), ] # sort by month
bmfi.final <- bmfi.final[which(!bmfi.final$final_elev == "-32768"), ] # get rid of ocean elevs
write.csv(bmfi.final, file = "bmfi.final.csv")
save(bmfi.final, file="bmfi.final.RData") # save as Rdata object so you don't have to do it every time
bmfi.final <- read.csv("bmfi.final.csv", header= TRUE)
# load("bmfi.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

bmfi.final <- bmfi.final[ , !(colnames(bmfi.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(bmfi.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
bmfi.final <- bmfi.final[!dup, ] # drop duplicate records
write.csv(bmfi.final, file = "bmfi.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(bmfi.final$lon, bmfi.final$lat, col='orange', pch=20, cex=0.75) # add points
points(bmfi.final$lon, bmfi.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=bmfi.final, aes(x=month, y=final_elev, group=bmfi.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="bmfi")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
bmfi.nona <- subset(bmfi.final, select=oa) 
# is.na(bmfi.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
bmfi.b <- bmfi.nona[which(bmfi.nona$month==6 | bmfi.nona$month==7), ] # Breeding June-August
bmfi.nb <- bmfi.nona[which(bmfi.nona$month==12 | bmfi.nona$month==1), ] # nonbreeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=bmfi.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: bmfi")
p <- p + theme_classic()
print(p)

boxplot(bmfi.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=bmfi.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: bmfi")
p <- p + theme_classic()
print(p)

boxplot(bmfi.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
bmfi.b.out <- FindOutliers(bmfi.b, r=1.5); bmfi.b.out # Detect outliers
bmfi.b <- bmfi.b[-bmfi.b.out$rownum,] # remove outliers

bmfi.nb.out <- FindOutliers(bmfi.nb, r=1.5); bmfi.nb.out # Detect outliers
bmfi.nb <- bmfi.nb[-bmfi.nb.out$rownum,] # remove outliers


# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
bmfi.b.elevs <- BreedingElevs(bmfi.b)
bmfi.nb.elevs <- NonbreedingElevs(bmfi.nb)
bmfi.elev.range <- cbind(bmfi.nb.elevs, bmfi.b.elevs); bmfi.elev.range
bmfi.elev.range["species"] <- "Leucosticte_brandti"
bmfi.elev.range <- bmfi.elev.range[, c(5,1,2,3,4)]; bmfi.elev.range  # reorder columns 
write.csv(bmfi.elev.range, file = "bmfi.elev.range.csv")
```


# SPOTTED BUSH WARBLER
```{r}
# Import data
name_suggest(q="Locustella thoracica", rank="species")$key[1] # get taxonKey
  # I double-checked: GBIF records for Bradypterus thoracicus get rerouted to Locustella thoracica

# kick off a download (taxonKey MUST be numeric form)
(loth.dl <- occ_download("taxonKey=8234327", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(loth.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
loth <- occ_download_get("0016683-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

loth.cit <- occ_download_get("0016683-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
loth.cit$download # prints one-line output with DOI

write.csv(loth, file = "loth.csv")
loth <- read.csv("loth.csv", header= TRUE)
```

```{r}
# Clean data  
loth.sub <- subset(loth, select=sc) # subset data w/ criteria defined in sc
loth.sub <- loth.sub[which(loth.sub$species == "Locustella thoracica"),] # verify only desired species
loth.sub <- loth.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
loth.sub <- loth.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
loth.sub <- loth.sub[which(!loth.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
loth.sub <- loth.sub[which(!loth.sub$decimalLongitude == "0"), ] # Drop lon values of 0
loth.sub <- loth.sub[which(!loth.sub$month == "NA"), ] # Drop NA months
loth.sub <- loth.sub[which(!loth.sub$countryCode == "NA"), ] # Drop NA countries
colnames(loth.sub)[colnames(loth.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
loth.sub <- loth.sub[order(-loth.sub$coord_uncert), ] # sort by coordinate uncertainty
loth.sub <- subset(loth.sub, loth.sub$coord_uncert < 3000 | is.na(loth.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(loth.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
loth.sub <- subset(loth.sub, subset = loth.sub$countryCode %in% c("IN", "NP"))
  # I ideally want Nepal only, but NP has n=24 records, so going to include India too

# Fetch elevations with elevation() from rgbif
loth.getelev <- elevation(loth.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
loth.qc <- loth.getelev
loth.qc$elev_diff <- (loth.qc$elevation-loth.qc$elevation_geonames) # Make elev_diff variable 
loth.qc <- loth.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
loth.qc <- loth.qc[order(-loth.qc$elev_diff), ] # sort by elev_diff
loth.qc <- subset(loth.qc, loth.qc$elev_diff < 300 | is.na(loth.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
loth.elevs <- loth.qc %>% filter(!is.na(elevation)) # existing elev
loth.noelev <- loth.qc %>% filter(is.na(elevation)) # no original elevs
loth.elevs$final_elev <- loth.elevs$elevation # add final_elev, assign elevation values to it 
loth.noelev$final_elev <- loth.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
loth.final <- rbind(loth.elevs, loth.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
loth.final <- loth.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
loth.final <- loth.final[order(-loth.final$month, -loth.final$final_elev), ] # sort by month
loth.final <- loth.final[which(!loth.final$final_elev == "-32768"), ] # drop ocean points
write.csv(loth.final, file = "loth.final.csv")
save(loth.final, file="loth.final.RData") # save as Rdata object so you don't have to do it every time
loth.final <- read.csv("loth.final.csv", header= TRUE)
# load("loth.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

loth.final <- loth.final[ , !(colnames(loth.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(loth.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
loth.final <- loth.final[!dup, ] # drop duplicate records
write.csv(loth.final, file = "loth.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(loth.final$lon, loth.final$lat, col='orange', pch=20, cex=0.75) # add points
points(loth.final$lon, loth.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=loth.final, aes(x=month, y=final_elev, group=loth.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="loth")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
loth.india <- loth.final[which(loth.final$countryCode == "IN"), ] # Decided I want India only
loth.nona <- subset(loth.india, select=oa) 
# is.na(loth.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
loth.b <- loth.nona[which(loth.nona$month==6 | loth.nona$month==7), ] # Breeding May-August
loth.nb <- loth.nona[which(loth.nona$month==11 | loth.nona$month==12 | loth.nona$month==1 | loth.nona$month==2 | loth.nona$month==3 | loth.nona$month==4), ] 
  # Including as many nonbreeding records as possible because so few

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=loth.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: loth")
p <- p + theme_classic()
print(p)

boxplot(loth.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=loth.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: loth")
p <- p + theme_classic()
print(p)

boxplot(loth.nb$final_elev, range=3, main="range=3") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
loth.b.out <- FindOutliers(loth.b, r=1.5); loth.b.out # Detect outliers
# no outliers

loth.nb.out <- FindOutliers(loth.nb, r=3); loth.nb.out # Detect outliers
loth.nb <- loth.nb[-loth.nb.out$rownum,] # remove outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
loth.b.elevs <- BreedingElevs(loth.b)
loth.nb.elevs <- NonbreedingElevs(loth.nb)
loth.elev.range <- cbind(loth.nb.elevs, loth.b.elevs); loth.elev.range
loth.elev.range["species"] <- "Locustella thoracica"
loth.elev.range <- loth.elev.range[, c(5,1,2,3,4)]; loth.elev.range  # reorder columns 
write.csv(loth.elev.range, file = "loth.elev.range.csv")
```


# PYGMY BLUE FLYCATCHER 
```{r}
# Import data
name_suggest(q="Muscicapella hodgsoni", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(muho.dl <- occ_download("taxonKey=2492480", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(muho.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
muho <- occ_download_get("0016693-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

muho.cit <- occ_download_get("0016693-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
muho.cit$download # prints one-line output with DOI

write.csv(muho, file = "muho.csv")
muho <- read.csv("muho.csv", header= TRUE)
```

```{r}
# Clean data  
muho.sub <- subset(muho, select=sc) # subset data w/ criteria defined in sc
muho.sub <- muho.sub[which(muho.sub$species == "Muscicapella hodgsoni"),] # verify only desired species
muho.sub <- muho.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
muho.sub <- muho.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
muho.sub <- muho.sub[which(!muho.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
muho.sub <- muho.sub[which(!muho.sub$decimalLongitude == "0"), ] # Drop lon values of 0
muho.sub <- muho.sub[which(!muho.sub$month == "NA"), ] # Drop NA months
muho.sub <- muho.sub[which(!muho.sub$countryCode == "NA"), ] # Drop NA countries
colnames(muho.sub)[colnames(muho.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
muho.sub <- muho.sub[order(-muho.sub$coord_uncert), ] # sort by coordinate uncertainty
muho.sub <- subset(muho.sub, muho.sub$coord_uncert < 3000 | is.na(muho.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(muho.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
muho.sub <- subset(muho.sub, subset = muho.sub$countryCode %in% c("NP", "IN"))

# Fetch elevations with elevation() from rgbif
muho.getelev <- elevation(muho.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
muho.qc <- muho.getelev
muho.qc$elev_diff <- (muho.qc$elevation-muho.qc$elevation_geonames) # Make elev_diff variable 
muho.qc <- muho.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
muho.qc <- muho.qc[order(-muho.qc$elev_diff), ] # sort by elev_diff
muho.qc <- subset(muho.qc, muho.qc$elev_diff < 300 | is.na(muho.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
muho.elevs <- muho.qc %>% filter(!is.na(elevation)) # existing elev
muho.noelev <- muho.qc %>% filter(is.na(elevation)) # no original elevs
muho.elevs$final_elev <- muho.elevs$elevation # add final_elev, assign elevation values to it 
muho.noelev$final_elev <- muho.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
muho.final <- rbind(muho.elevs, muho.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
muho.final <- muho.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
muho.final <- muho.final[order(-muho.final$month, -muho.final$final_elev), ] # sort by month
muho.final <- muho.final[which(!muho.final$final_elev == "-32768"), ] # drop ocean points
write.csv(muho.final, file = "muho.final.csv")
save(muho.final, file="muho.final.RData") # save as Rdata object so you don't have to do it every time
muho.final <- read.csv("muho.final.csv", header= TRUE)
# load("muho.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

muho.final <- muho.final[ , !(colnames(muho.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(muho.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
muho.final <- muho.final[!dup, ] # drop duplicate records
write.csv(muho.final, file = "muho.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(muho.final$lon, muho.final$lat, col='orange', pch=20, cex=0.75) # add points
points(muho.final$lon, muho.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=muho.final, aes(x=month, y=final_elev, group=muho.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="muho")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
muho.np <- muho.final[which(muho.final$countryCode == "NP"), ] # Just Nepal
muho.in <- muho.final[which(muho.final$countryCode == "IN"), ] # Just India

muho.np.nona <- subset(muho.np, select=oa) 
muho.in.nona <- subset(muho.in, select=oa)
# is.na(muho.nona) # need no NAs to run outlier function 

# HBW says breeding mid-March to July; Grimmet says July (other months unknown)
# subset by breeding and non-breeding season - NEPAL  
muho.b.np <- muho.np.nona[which(muho.np.nona$month==6 | muho.np.nona$month==7), ] # Breeding  
muho.nb.np <- muho.np.nona[which(muho.np.nona$month==12 | muho.np.nona$month==1), ]

# subset by breeding and non-breeding season - INDIA  
muho.b.in <- muho.in.nona[which(muho.in.nona$month==6 | muho.in.nona$month==7), ] # Breeding  
muho.nb.in <- muho.in.nona[which(muho.in.nona$month==12 | muho.in.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=muho.b.in, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: muho")
p <- p + theme_classic()
print(p)

boxplot(muho.b.in$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=muho.nb.in, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: muho")
p <- p + theme_classic()
print(p)

boxplot(muho.nb.np$final_elev, range=3, main="range =3") # Non-breeding lumped; check outlier threshold 
boxplot(muho.nb.in$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
muho.b.np.out <- FindOutliers(muho.b.np, r=1.5); muho.b.np.out # Detect outliers
# no outliers

muho.nb.np.out <- FindOutliers(muho.nb.np, r=3); muho.nb.np.out # Detect outliers
muho.nb.np <- muho.nb.np[-muho.nb.np.out$rownum,] # remove outliers

muho.b.in.out <- FindOutliers(muho.b.in, r=1.5); muho.b.in.out # Detect outliers
# no outliers

muho.nb.in.out <- FindOutliers(muho.nb.in, r=1.5); muho.nb.in.out # Detect outliers
muho.nb.in <- muho.nb.in[-muho.nb.in.out$rownum,] # remove outliers


# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
# Nepal
muho.b.np.elevs <- BreedingElevs(muho.b.np)
muho.nb.np.elevs <- NonbreedingElevs(muho.nb.np)
muho.np.elev.range <- cbind(muho.nb.np.elevs, muho.b.np.elevs); muho.np.elev.range
muho.np.elev.range["species"] <- "Muscicapella_hodgsoni_Nepal"
muho.np.elev.range <- muho.np.elev.range[, c(5,1,2,3,4)]; muho.np.elev.range  # reorder columns 
write.csv(muho.np.elev.range, file = "muho.np.elev.range.csv")

# India
muho.b.in.elevs <- BreedingElevs(muho.b.in)
muho.nb.in.elevs <- NonbreedingElevs(muho.nb.in)
muho.in.elev.range <- cbind(muho.nb.in.elevs, muho.b.in.elevs); muho.np.elev.range
muho.in.elev.range["species"] <- "Muscicapella_hodgsoni_India"
muho.in.elev.range <- muho.in.elev.range[, c(5,1,2,3,4)]; muho.in.elev.range  # reorder columns 
write.csv(muho.in.elev.range, file = "muho.in.elev.range.csv")
```



# BLYTH'S LEAF WARBLER
```{r}
# Import data
name_suggest(q="Phylloscopus reguloides", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(phre.dl <- occ_download("taxonKey=2493092", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(phre.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
phre <- occ_download_get("0016701-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

phre.cit <- occ_download_get("0016701-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
phre.cit$download # prints one-line output with DOI

write.csv(phre, file = "phre.csv")
phre <- read.csv("phre.csv", header= TRUE)
```

```{r}
# Clean data  
phre.sub <- subset(phre, select=sc) # subset data w/ criteria defined in sc
phre.sub <- phre.sub[which(phre.sub$species == "Phylloscopus reguloides"),] # verify only desired species
phre.sub <- phre.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
phre.sub <- phre.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
phre.sub <- phre.sub[which(!phre.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
phre.sub <- phre.sub[which(!phre.sub$decimalLongitude == "0"), ] # Drop lon values of 0
phre.sub <- phre.sub[which(!phre.sub$month == "NA"), ] # Drop NA months
phre.sub <- phre.sub[which(!phre.sub$countryCode == "NA"), ] # Drop NA countries
colnames(phre.sub)[colnames(phre.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
phre.sub <- phre.sub[order(-phre.sub$coord_uncert), ] # sort by coordinate uncertainty
phre.sub <- subset(phre.sub, phre.sub$coord_uncert < 3000 | is.na(phre.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(phre.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
phre.sub <- phre.sub[which(phre.sub$countryCode == "IN"), ] # India only

# Fetch elevations with elevation() from rgbif
phre.getelev <- elevation(phre.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
phre.qc <- phre.getelev
phre.qc$elev_diff <- (phre.qc$elevation-phre.qc$elevation_geonames) # Make elev_diff variable 
phre.qc <- phre.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
phre.qc <- phre.qc[order(-phre.qc$elev_diff), ] # sort by elev_diff
phre.qc <- subset(phre.qc, phre.qc$elev_diff < 300 | is.na(phre.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
phre.elevs <- phre.qc %>% filter(!is.na(elevation)) # existing elev
phre.noelev <- phre.qc %>% filter(is.na(elevation)) # no original elevs
phre.elevs$final_elev <- phre.elevs$elevation # add final_elev, assign elevation values to it 
phre.noelev$final_elev <- phre.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
phre.final <- rbind(phre.elevs, phre.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
phre.final <- phre.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
phre.final <- phre.final[order(-phre.final$month, -phre.final$final_elev), ] # sort by month
phre.final <- phre.final[which(!phre.final$final_elev == "-32768"), ] # drop ocean points
write.csv(phre.final, file = "phre.final.csv")
save(phre.final, file="phre.final.RData") # save as Rdata object so you don't have to do it every time
phre.final <- read.csv("phre.final.csv", header= TRUE)
# load("phre.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

phre.final <- phre.final[ , !(colnames(phre.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(phre.final[, c("species", 'longitude', 'latitude', "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
phre.final <- phre.final[!dup, ] # drop duplicate records
write.csv(phre.final, file = "phre.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(phre.final$lon, phre.final$lat, col='orange', pch=20, cex=0.75) # add points
points(phre.final$lon, phre.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=phre.final, aes(x=month, y=final_elev, group=phre.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="phre")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
phre.nona <- subset(phre.final, select=oa) 
# is.na(phre.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
phre.b <- phre.nona[which(phre.nona$month==6 | phre.nona$month==7), ] # Breeding April to August
phre.nb <- phre.nona[which(phre.nona$month==12 | phre.nona$month==1), ] # Nonbreeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phre.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: phre")
p <- p + theme_classic()
print(p)

boxplot(phre.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phre.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: phre")
p <- p + theme_classic()
print(p)

boxplot(phre.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
phre.b.out <- FindOutliers(phre.b, r=1.5); phre.b.out # Detect outliers
phre.b <- phre.b[-phre.b.out$rownum,] # remove outliers

phre.nb.out <- FindOutliers(phre.nb, r=1.5); phre.nb.out # Detect outliers
phre.nb <- phre.nb[-phre.nb.out$rownum,] # remove outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
phre.b.elevs <- BreedingElevs(phre.b)
phre.nb.elevs <- NonbreedingElevs(phre.nb)
phre.elev.range <- cbind(phre.nb.elevs, phre.b.elevs); phre.elev.range
phre.elev.range["species"] <- "Phylloscopus_reguloides"
phre.elev.range <- phre.elev.range[, c(5,1,2,3,4)]; phre.elev.range  # reorder columns 
write.csv(phre.elev.range, file = "phre.elev.range.csv")
```



# RUFOUS-BREASTED ACCENTOR
```{r}
# Import data
name_suggest(q="Prunella strophiata", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(rbac.dl <- occ_download("taxonKey=5231765", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(rbac.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
rbac <- occ_download_get("0016703-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

rbac.cit <- occ_download_get("0016703-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
rbac.cit$download # prints one-line output with DOI

write.csv(rbac, file = "rbac.csv")
rbac <- read.csv("//Users/Jessie/Desktop/RDirectory/ENSM/Rufous-breastedAccentor.csv", stringsAsFactors=FALSE)
```

```{r}
# Clean data  
rbac.sub <- subset(rbac, select=sc) # subset data w/ criteria defined in sc
rbac.sub <- rbac.sub[which(rbac.sub$species == "Prunella strophiata"),] # verify only desired species
rbac.sub <- rbac.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
rbac.sub <- rbac.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
rbac.sub <- rbac.sub[which(!rbac.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
rbac.sub <- rbac.sub[which(!rbac.sub$decimalLongitude == "0"), ] # Drop lon values of 0
rbac.sub <- rbac.sub[which(!rbac.sub$month == "NA"), ] # Drop NA months
rbac.sub <- rbac.sub[which(!rbac.sub$countryCode == "NA"), ] # Drop NA countries
colnames(rbac.sub)[colnames(rbac.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
rbac.sub <- rbac.sub[order(-rbac.sub$coord_uncert), ] # sort by coordinate uncertainty
rbac.sub <- subset(rbac.sub, rbac.sub$coord_uncert < 3000 | is.na(rbac.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
count(rbac.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
rbac.sub <- rbac.sub[which(rbac.sub$countryCode == "IN"), ] # Include India only

# Fetch elevations with elevation() from rgbif
rbac.getelev <- elevation(rbac.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
rbac.qc <- rbac.getelev
rbac.qc$elev_diff <- (rbac.qc$elevation-rbac.qc$elevation_geonames) # Make elev_diff variable 
rbac.qc <- rbac.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
rbac.qc <- rbac.qc[order(-rbac.qc$elev_diff), ] # sort by elev_diff
rbac.qc <- subset(rbac.qc, rbac.qc$elev_diff < 300 | is.na(rbac.qc$elev_diff)) 
rbac.qc <- subset(rbac.qc, rbac.qc$elev_diff > -300 | is.na(rbac.qc$elev_diff))  # drop negative values
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
rbac.elevs <- rbac.qc %>% filter(!is.na(elevation)) # existing elev
rbac.noelev <- rbac.qc %>% filter(is.na(elevation)) # no original elevs
rbac.elevs$final_elev <- rbac.elevs$elevation # add final_elev, assign elevation values to it 
rbac.noelev$final_elev <- rbac.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
rbac.final <- rbind(rbac.elevs, rbac.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
rbac.final <- rbac.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
rbac.final <- rbac.final[order(-rbac.final$month, -rbac.final$final_elev), ] # sort by month
rbac.final <- rbac.final[which(!rbac.final$final_elev == "-32768"), ] # get rid of ocean points
write.csv(rbac.final, file = "rbac.final.csv")
save(rbac.final, file="rbac.final.RData") # save as Rdata object so you don't have to do it every time
rbac.final <- read.csv("rbac.final.csv", header= TRUE)
# load("rbac.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

rbac.final <- rbac.final[ , !(colnames(rbac.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(rbac.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
rbac.final <- rbac.final[!dup, ] # drop duplicate records
write.csv(rbac.final, file = "rbac.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(rbac.final$lon, rbac.final$lat, col='orange', pch=20, cex=0.75) # add points
points(rbac.final$lon, rbac.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=rbac.final, aes(x=month, y=final_elev, group=rbac.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="rbac")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
rbac.nona <- subset(rbac.final, select=oa) 
# is.na(rbac.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
rbac.b <- rbac.nona[which(rbac.nona$month==6 | rbac.nona$month==7), ] # Breeding May-August
rbac.nb <- rbac.nona[which(rbac.nona$month==12 | rbac.nona$month==1), ] # nonbreeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=rbac.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: rbac")
p <- p + theme_classic()
print(p)

boxplot(rbac.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=rbac.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: rbac")
p <- p + theme_classic()
print(p)

boxplot(rbac.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
rbac.b.out <- FindOutliers(rbac.b, r=1.5); rbac.b.out # Detect outliers
rbac.b <- rbac.b[-rbac.b.out$rownum,] # remove outliers

rbac.nb.out <- FindOutliers(rbac.nb, r=1.5); rbac.nb.out # Detect outliers
rbac.nb <- rbac.nb[-rbac.nb.out$rownum,] # remove outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
rbac.b.elevs <- BreedingElevs(rbac.b)
rbac.nb.elevs <- NonbreedingElevs(rbac.nb)
rbac.elev.range <- cbind(rbac.nb.elevs, rbac.b.elevs); rbac.elev.range
rbac.elev.range["species"] <- "Prunella_strophiata"
rbac.elev.range <- rbac.elev.range[, c(5,1,2,3,4)]; rbac.elev.range  # reorder columns 
write.csv(rbac.elev.range, file = "rbac.elev.range.csv")
```


# EURASIAN CRAG MARTIN
```{r}
# Import data
name_suggest(q="Ptyonoprogne rupestris", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(ptru.dl <- occ_download("taxonKey=4408796", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(ptru.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
ptru <- occ_download_get("0016708-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

ptru.cit <- occ_download_get("0016708-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
ptru.cit$download # prints one-line output with DOI

write.csv(ptru, file = "ptru.csv")
ptru <- read.csv("ptru.csv", header= TRUE)
```

```{r}
# Clean data  
ptru.sub <- subset(ptru, select=sc) # subset data w/ criteria defined in sc
ptru.sub <- ptru.sub[which(ptru.sub$species == "Ptyonoprogne rupestris"),] # verify only desired species
ptru.sub <- ptru.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
ptru.sub <- ptru.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
ptru.sub <- ptru.sub[which(!ptru.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
ptru.sub <- ptru.sub[which(!ptru.sub$decimalLongitude == "0"), ] # Drop lon values of 0
ptru.sub <- ptru.sub[which(!ptru.sub$month == "NA"), ] # Drop NA months
ptru.sub <- ptru.sub[which(!ptru.sub$countryCode == "NA"), ] # Drop NA countries
colnames(ptru.sub)[colnames(ptru.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
ptru.sub <- ptru.sub[order(-ptru.sub$coord_uncert), ] # sort by coordinate uncertainty
ptru.sub <- subset(ptru.sub, ptru.sub$coord_uncert < 3000 | is.na(ptru.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(ptru.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
ptru.sub <- ptru.sub[which(ptru.sub$countryCode == "IN"), ] # India only

# Fetch elevations with elevation() from rgbif
ptru.getelev <- elevation(ptru.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
ptru.qc <- ptru.getelev
ptru.qc$elev_diff <- (ptru.qc$elevation-ptru.qc$elevation_geonames) # Make elev_diff variable 
ptru.qc <- ptru.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
ptru.qc <- ptru.qc[order(-ptru.qc$elev_diff), ] # sort by elev_diff
ptru.qc <- subset(ptru.qc, ptru.qc$elev_diff < 300 | is.na(ptru.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
ptru.elevs <- ptru.qc %>% filter(!is.na(elevation)) # existing elev
ptru.noelev <- ptru.qc %>% filter(is.na(elevation)) # no original elevs
ptru.elevs$final_elev <- ptru.elevs$elevation # add final_elev, assign elevation values to it 
ptru.noelev$final_elev <- ptru.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
ptru.final <- rbind(ptru.elevs, ptru.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
ptru.final <- ptru.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
ptru.final <- ptru.final[order(-ptru.final$month, -ptru.final$final_elev), ] # sort by month
ptru.final <- ptru.final[which(!ptru.final$final_elev == "-32768"), ] # drop ocean points
write.csv(ptru.final, file = "ptru.final.csv")
save(ptru.final, file="ptru.final.RData") # save as Rdata object so you don't have to do it every time
ptru.final <- read.csv("ptru.final.csv", header= TRUE)
# load("ptru.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

ptru.final <- ptru.final[ , !(colnames(ptru.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(ptru.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
ptru.final <- ptru.final[!dup, ] # drop duplicate records
write.csv(ptru.final, file = "ptru.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India
points(ptru.final$lon, ptru.final$lat, col='orange', pch=20, cex=0.75) # add points
points(ptru.final$lon, ptru.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=ptru.final, aes(x=month, y=final_elev, group=ptru.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="ptru")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
ptru.nona <- subset(ptru.final, select=oa) 
# is.na(ptru.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
ptru.b <- ptru.nona[which(ptru.nona$month==6 | ptru.nona$month==7), ] # Breeding April-July
ptru.nb <- ptru.nona[which(ptru.nona$month==12 | ptru.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=ptru.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: ptru")
p <- p + theme_classic()
print(p)

boxplot(ptru.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=ptru.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: ptru")
p <- p + theme_classic()
print(p)

boxplot(ptru.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
ptru.b.out <- FindOutliers(ptru.b, r=1.5); ptru.b.out # Detect outliers
ptru.b <- ptru.b[-ptru.b.out$rownum,] # remove outliers

ptru.nb.out <- FindOutliers(ptru.nb, r=1.5); ptru.nb.out # Detect outliers
ptru.nb <- ptru.nb[-ptru.nb.out$rownum,] # remove outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
ptru.b.elevs <- BreedingElevs(ptru.b)
ptru.nb.elevs <- NonbreedingElevs(ptru.nb)
ptru.elev.range <- cbind(ptru.nb.elevs, ptru.b.elevs); ptru.elev.range
ptru.elev.range["species"] <- "Ptyonoprogne rupestris"
ptru.elev.range <- ptru.elev.range[, c(5,1,2,3,4)]; ptru.elev.range  # reorder columns 
write.csv(ptru.elev.range, file = "ptru.elev.range.csv")
```



# LESSER YELLOWLEGS
*Note: Full LEYE dataset is HUGE (205.54 MB download)...so don't download unless you're willing to wait. 
```{r}
# Import data
name_suggest(q="Tringa flavipes", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
#(leye.dl <- occ_download("taxonKey=2481721", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

#occ_download_meta(leye.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
#leye.all.records <- occ_download_get("0016759-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

#leye.cit.allrecords <- occ_download_get("0016759-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
#leye.cit.allrecords$download # prints one-line output with DOI

#write.csv(leye.all.records, file = "leye.all.records.csv")
#leye.all.records <- read.csv("leye.all.records.csv", header= TRUE)
```

```{r}
# read in data
leye <- read.csv("//Users/Jessie/Desktop/RDirectory/ENSM/LesserYellowlegs.csv", stringsAsFactors=FALSE)
  # leye records are HUGE, so I downloaded US and Canada only for May-June-July 

# Clean data  
leye.sub <- subset(leye, select=sc) # subset data w/ criteria defined in sc
leye.sub <- leye.sub[which(leye.sub$species == "Tringa flavipes"),] # verify only desired species
leye.sub <- leye.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
leye.sub <- leye.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
leye.sub <- leye.sub[which(!leye.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
leye.sub <- leye.sub[which(!leye.sub$decimalLongitude == "0"), ] # Drop lon values of 0
leye.sub <- leye.sub[which(!leye.sub$month == "NA"), ] # Drop NA months
leye.sub <- leye.sub[which(!leye.sub$countryCode == "NA"), ] # Drop NA countries
colnames(leye.sub)[colnames(leye.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
leye.sub <- leye.sub[order(-leye.sub$coord_uncert), ] # sort by coordinate uncertainty
leye.sub <- subset(leye.sub, leye.sub$coord_uncert < 3000 | is.na(leye.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
    #NOTE: THERE IS SO MUCH DATA THAT I INCREASED THRESHOLD FOR COORDINATE UNCERTAINTY 

leye.split <- split(leye.sub, (seq(nrow(leye.sub))-1) %/% 5000) # splits data into chunks of 9000 (10k too big)
# leye.split.unlist <- do.call(rbind.data.frame, leye.split) # unsplits and makes a data frame 

leye0 <- as.data.frame(leye.split$"0")
leye1 <- as.data.frame(leye.split$"1")
leye2 <- as.data.frame(leye.split$"2")
leye3 <- as.data.frame(leye.split$"3")
leye4 <- as.data.frame(leye.split$"4")
leye5 <- as.data.frame(leye.split$"5")
leye6 <- as.data.frame(leye.split$"6")
leye7 <- as.data.frame(leye.split$"7")
leye8 <- as.data.frame(leye.split$"8")
leye9 <- as.data.frame(leye.split$"9")
leye10 <- as.data.frame(leye.split$"10")
leye11 <- as.data.frame(leye.split$"11")
leye12 <- as.data.frame(leye.split$"12")
leye13 <- as.data.frame(leye.split$"13")
leye14 <- as.data.frame(leye.split$"14")
leye15 <- as.data.frame(leye.split$"15")
leye16 <- as.data.frame(leye.split$"16")
leye17 <- as.data.frame(leye.split$"17")
leye18 <- as.data.frame(leye.split$"18")
leye19 <- as.data.frame(leye.split$"19")
leye20 <- as.data.frame(leye.split$"20")
leye21 <- as.data.frame(leye.split$"21")
leye22 <- as.data.frame(leye.split$"22")
leye23 <- as.data.frame(leye.split$"23")
leye24 <- as.data.frame(leye.split$"24")
leye25 <- as.data.frame(leye.split$"25")
leye26 <- as.data.frame(leye.split$"26")
leye27 <- as.data.frame(leye.split$"27")
leye28 <- as.data.frame(leye.split$"28")
leye29 <- as.data.frame(leye.split$"29")
leye30 <- as.data.frame(leye.split$"30")
leye31 <- as.data.frame(leye.split$"31")
leye32 <- as.data.frame(leye.split$"32")
leye33 <- as.data.frame(leye.split$"33")
leye34 <- as.data.frame(leye.split$"34")
leye35 <- as.data.frame(leye.split$"35")
leye36 <- as.data.frame(leye.split$"36")
leye37 <- as.data.frame(leye.split$"37")
leye38 <- as.data.frame(leye.split$"38")
leye39 <- as.data.frame(leye.split$"39")
leye40 <- as.data.frame(leye.split$"40")
leye41 <- as.data.frame(leye.split$"41")
leye42 <- as.data.frame(leye.split$"42")
leye43 <- as.data.frame(leye.split$"43")
leye44 <- as.data.frame(leye.split$"44")
leye45 <- as.data.frame(leye.split$"45")
leye46 <- as.data.frame(leye.split$"46")

# get elevs from rgbif (omg worse code ever kill me)
leye.e0 <- elevation(leye0, elevation_model="srtm3", username="jwilliamson0110")
leye.e1 <- elevation(leye1, elevation_model="srtm3", username="jwilliamson0110")
leye.e10 <- elevation(leye10, elevation_model="srtm3", username="cgadekgmail")
leye.e15 <- elevation(leye16, elevation_model="srtm3", username="selina2")
leye.e18 <- elevation(leye17, elevation_model="srtm3", username="selina2")
leye.e6 <- elevation(leye6, elevation_model="srtm3", username="jessiefulbright")

leye.e2 <- elevation(leye2, elevation_model="srtm3", username="jwilliamson")
leye.e3 <- elevation(leye3, elevation_model="srtm3", username="jwilliamson0110")
leye.e4 <- elevation(leye4, elevation_model="srtm3", username="jessiewgym") 
leye.e7 <- elevation(leye7, elevation_model="srtm3", username="cgadekunm") 
leye.e8 <- elevation(leye8, elevation_model="srtm3", username="cgadekgmail") 
leye.e9 <- elevation(leye9, elevation_model="srtm3", username="willford1") 
leye.e11 <- elevation(leye11, elevation_model="srtm3", username="selina1")
leye.e13 <- elevation(leye13, elevation_model="srtm3", username="jwilliamson")
leye.e17 <- elevation(leye15, elevation_model="srtm3", username="jessiewgym")
leye.e23 <- elevation(leye22, elevation_model="srtm3", username="selina1")
leye.e5 <- elevation(leye5, elevation_model="srtm3", username="jessiefulbright") 
leye.e12 <- elevation(leye12, elevation_model="srtm3", username="selina2")
leye.e14 <- elevation(leye14, elevation_model="srtm3", username="jwilliamson0110") 
leye.e20 <- elevation(leye18, elevation_model="srtm3", username="jwilliamson")
leye.e16 <- elevation(leye19, elevation_model="srtm3", username="cgadekunm")  
leye.e19 <- elevation(leye20, elevation_model="srtm3", username="cgadekgmail")
leye.e22 <- elevation(leye21, elevation_model="srtm3", username="willford1")
leye.e21 <- elevation(leye23, elevation_model="srtm3", username="selina1") 
leye.e24 <- elevation(leye24, elevation_model="srtm3", username="jessiewgym")
leye.e25 <- elevation(leye25, elevation_model="srtm3", username="jwilliamson0110")
leye.e28 <- elevation(leye28, elevation_model="srtm3", username="jessiefulbright")
leye.e29 <- elevation(leye29, elevation_model="srtm3", username="selina1") 
leye.e33 <- elevation(leye33, elevation_model="srtm3", username="willford1") # done 
leye.e26 <- elevation(leye26, elevation_model="srtm3", username="jwilliamson")  
leye.e27 <- elevation(leye27, elevation_model="srtm3", username="jessiewgym")  
leye.e30 <- elevation(leye30, elevation_model="srtm3", username="jwilliamson0110")
leye.e31 <- elevation(leye31, elevation_model="srtm3", username="jessiefulbright")
leye.e32 <- elevation(leye32, elevation_model="srtm3", username="cgadekunm")
leye.e34 <- elevation(leye34, elevation_model="srtm3", username="cgadekgmail")
leye.e35 <- elevation(leye35, elevation_model="srtm3", username="willford1")
leye.e36 <- elevation(leye36, elevation_model="srtm3", username="selina1")
leye.e37 <- elevation(leye37, elevation_model="srtm3", username="selina2")
leye.e38 <- elevation(leye38, elevation_model="srtm3", username="jwilliamson")
leye.e39 <- elevation(leye39, elevation_model="srtm3", username="jessiewgym")
leye.e42 <- elevation(leye42, elevation_model="srtm3", username="cgadekunm")
leye.e43 <- elevation(leye43, elevation_model="srtm3", username="cgadekgmail")
leye.e44 <- elevation(leye44, elevation_model="srtm3", username="willford1")
leye.e45 <- elevation(leye45, elevation_model="srtm3", username="selina1")
leye.e46 <- elevation(leye46, elevation_model="srtm3", username="selina2")
leye.e40 <- elevation(leye40, elevation_model="srtm3", username="jessiewgym")
leye.e41 <- elevation(leye41, elevation_model="srtm3", username="jwilliamson")

# write all to .csv
write.csv(leye.e0, file = "leye.e0.csv")
write.csv(leye.e1, file = "leye.e1.csv")
write.csv(leye.e10, file = "leye.e10.csv")
write.csv(leye.e15, file = "leye.e15.csv")
write.csv(leye.e18, file = "leye.e18.csv")
write.csv(leye.e6, file = "leye.e6.csv")
write.csv(leye.e2, file = "leye.e2.csv")
write.csv(leye.e3, file = "leye.e3.csv")
write.csv(leye.e4, file = "leye.e4.csv")
write.csv(leye.e7, file = "leye.e7.csv")
write.csv(leye.e8, file = "leye.e8.csv")
write.csv(leye.e9, file = "leye.e9.csv") 
write.csv(leye.e11, file = "leye.e11.csv")
write.csv(leye.e13, file = "leye.e13.csv")
write.csv(leye.e23, file = "leye.e23.csv")
write.csv(leye.e17, file = "leye.e17.csv") 
write.csv(leye.e5, file = "leye.e5.csv")
write.csv(leye.e12, file = "leye.e12.csv")  
write.csv(leye.e14, file = "leye.e14.csv")
write.csv(leye.e20, file = "leye.e20.csv")
write.csv(leye.e16, file = "leye.e16.csv")
write.csv(leye.e19, file = "leye.e19.csv")
write.csv(leye.e22, file = "leye.e22.csv")
write.csv(leye.e21, file = "leye.e21.csv")
write.csv(leye.e24, file = "leye.e24.csv")
write.csv(leye.e25, file = "leye.e25.csv")
write.csv(leye.e28, file = "leye.e28.csv")
write.csv(leye.e29, file = "leye.e29.csv")
write.csv(leye.e33, file = "leye.e33.csv") 
write.csv(leye.e26, file = "leye.e26.csv")
write.csv(leye.e27, file = "leye.e27.csv")
write.csv(leye.e30, file = "leye.e30.csv")
write.csv(leye.e31, file = "leye.e31.csv")
write.csv(leye.e32, file = "leye.e32.csv")
write.csv(leye.e34, file = "leye.e34.csv")
write.csv(leye.e35, file = "leye.e35.csv")
write.csv(leye.e36, file = "leye.e36.csv")
write.csv(leye.e37, file = "leye.e37.csv")
write.csv(leye.e38, file = "leye.e38.csv")
write.csv(leye.e39, file = "leye.e39.csv") 
write.csv(leye.e42, file = "leye.e42.csv")
write.csv(leye.e43, file = "leye.e43.csv")
write.csv(leye.e44, file = "leye.e44.csv")
write.csv(leye.e45, file = "leye.e45.csv")
write.csv(leye.e46, file = "leye.e46.csv")
write.csv(leye.e40, file = "leye.e40.csv")
write.csv(leye.e41, file = "leye.e41.csv")

# rbind mini data frames together again
leye.all <- rbind(leye.e0, leye.e1, leye.e2, leye.e3, leye.e4, leye.e5, leye.e6, leye.e7, leye.e8, leye.e9, leye.e10, leye.e11, leye.e12, leye.e13, leye.e14, leye.e15, leye.e16, leye.e17, leye.e18, leye.e19, leye.e20, leye.e21, leye.e22, leye.e23, leye.e24, leye.e25, leye.e26, leye.e27, leye.e28, leye.e29, leye.e30, leye.e31, leye.e32, leye.e33, leye.e34, leye.e35, leye.e36, leye.e37, leye.e38, leye.e39, leye.e40, leye.e41, leye.e42, leye.e43, leye.e44, leye.e45, leye.e46) # good, same length as leye.sub
  # for some reason this isn't the same number as leye.sub

# save(leye.all, file="leye.all.RData") # save as Rdata object so you don't have to do it every time
#load("leye.all.RData") # to load .RData file

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
leye.qc <- leye.all
leye.qc$elev_diff <- (leye.qc$elevation-leye.qc$elevation_geonames) # Make elev_diff variable 
leye.qc <- leye.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
leye.qc <- leye.qc[order(-leye.qc$elev_diff), ] # sort by elev_diff
leye.qc <- subset(leye.qc, leye.qc$elev_diff < 300 | is.na(leye.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
leye.elevs <- leye.qc %>% filter(!is.na(elevation)) # existing elev
leye.noelev <- leye.qc %>% filter(is.na(elevation)) # no original elevs
leye.elevs$final_elev <- leye.elevs$elevation # add final_elev, assign elevation values to it 
leye.noelev$final_elev <- leye.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
leye.final <- rbind(leye.elevs, leye.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
leye.final <- leye.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
leye.final <- leye.final[order(-leye.final$month, -leye.final$final_elev), ] # sort by month
leye.final <- leye.final[which(!leye.final$final_elev == "-32768"), ] # get rid of weird elevs

write.csv(leye.final, file = "leye.final.csv")
save(leye.final, file="leye.final.RData") # save as Rdata object so you don't have to do it every time
leye.final <- read.csv("leye.final.csv", header= TRUE)
# load("leye.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE

leye.final <- leye.final[ , !(colnames(leye.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(leye.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
leye.final <- leye.final[!dup, ] # drop duplicate records
write.csv(leye.final, file = "leye.final.nodups.csv")

# Remove records from Hawaii
leye.final <- subset(leye.final, leye.final$latitude > 24) # Keep only latitudes north of 24 degrees

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(-160,-60), ylim=c(0,80))
points(leye.final$lon, leye.final$lat, col='orange', pch=20, cex=0.75) # add points
points(leye.final$lon, leye.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=leye.final, aes(x=month, y=final_elev, group=leye.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="leye")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
leye.nona <- subset(leye.final, select=oa) 
leye.nona <- subset(leye.nona, leye.nona$latitude > 50) # keep only breeding latitudes >49 degrees
  # Becasue LEYE don't breed in the lower 48
# is.na(leye.nona) # need no NAs to run outlier function 

# subset by breeding season (because you don't have nonbreeding data)
leye.b <- leye.nona[which(leye.nona$month==5 | leye.nona$month==6), ]
  # July too late - a lot of birds already migrating by then

# Plot of breeding season to identify outliers 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=leye.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: Tringa flavipes")
p <- p + theme_classic()
print(p)

boxplot(leye.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold  

# OUTLIER ANALYSIS AND REMOVAL 
leye.b.out <- FindOutliers(leye.b, r=1.5); leye.b.out # Detect outliers
leye.b <- leye.b[-leye.b.out$rownum,] # remove outliers


# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
leye.b.elevs <- BreedingElevs(leye.b); leye.b.elevs
#leye.nb.elevs <- NonbreedingElevs(leye.nb)
leye.elev.range <- leye.b.elevs
leye.elev.range["species"] <- "Tringa_flavipes"
leye.elev.range <- leye.elev.range[, c(3,1,2)]; leye.elev.range  # reorder columns 
write.csv(leye.elev.range, file = "leye.elev.range.csv") 
```



# GREATER YELLOWLEGS
```{r}
# read in data
grye <- read.csv("//Users/Jessie/Desktop/RDirectory/ENSM/GreaterYellowlegs.csv", stringsAsFactors=FALSE)
  # grye records are HUGE, so I downloaded US and CAN records from May-June-July only 

# Clean data  
grye.sub <- subset(grye, select=sc) # subset data w/ criteria defined in sc
grye.sub <- grye.sub[which(grye.sub$species == "Tringa melanoleuca"),] # verify only desired species
grye.sub <- grye.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
grye.sub <- grye.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
grye.sub <- grye.sub[which(!grye.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
grye.sub <- grye.sub[which(!grye.sub$decimalLongitude == "0"), ] # Drop lon values of 0
grye.sub <- grye.sub[which(!grye.sub$month == "NA"), ] # Drop NA months
grye.sub <- grye.sub[which(!grye.sub$countryCode == "NA"), ] # Drop NA countries
colnames(grye.sub)[colnames(grye.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
grye.sub <- grye.sub[order(-grye.sub$coord_uncert), ] # sort by coordinate uncertainty
grye.sub <- subset(grye.sub, grye.sub$coord_uncert < 3000 | is.na(grye.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
    #NOTE: THERE IS SO MUCH DATA THAT I INCREASED THRESHOLD FOR COORDINATE UNCERTAINTY 

grye.split <- split(grye.sub, (seq(nrow(grye.sub))-1) %/% 9000) # splits data into chunks of 9000 (10k too big)
# grye.split.unlist <- do.call(rbind.data.frame, grye.split) # unsplits and makes a data frame 

grye0 <- as.data.frame(grye.split$"0")
grye1 <- as.data.frame(grye.split$"1")
grye2 <- as.data.frame(grye.split$"2")
grye3 <- as.data.frame(grye.split$"3")
grye4 <- as.data.frame(grye.split$"4")
grye5 <- as.data.frame(grye.split$"5")
grye6 <- as.data.frame(grye.split$"6")
grye7 <- as.data.frame(grye.split$"7")
grye8 <- as.data.frame(grye.split$"8")
grye9 <- as.data.frame(grye.split$"9")
grye10 <- as.data.frame(grye.split$"10")
grye11 <- as.data.frame(grye.split$"11")
grye12 <- as.data.frame(grye.split$"12")
grye13 <- as.data.frame(grye.split$"13")
grye14 <- as.data.frame(grye.split$"14")
grye15 <- as.data.frame(grye.split$"15")
grye16 <- as.data.frame(grye.split$"16")
grye17 <- as.data.frame(grye.split$"17")
grye18 <- as.data.frame(grye.split$"18")
grye19 <- as.data.frame(grye.split$"19")
grye20 <- as.data.frame(grye.split$"20")
grye21 <- as.data.frame(grye.split$"21")
grye22 <- as.data.frame(grye.split$"22")
grye23 <- as.data.frame(grye.split$"23")
grye24 <- as.data.frame(grye.split$"24")
grye25 <- as.data.frame(grye.split$"25")
grye26 <- as.data.frame(grye.split$"26")
grye27 <- as.data.frame(grye.split$"27")

# get elevs from rgbif (omg worst code ever kill me)
grye.e0 <- elevation(grye0, elevation_model="srtm3", username="jwilliamson")
grye.e1 <- elevation(grye1, elevation_model="srtm3", username="jwilliamson0110")
grye.e2 <- elevation(grye2, elevation_model="srtm3", username="jessiewgym")
grye.e3 <- elevation(grye3, elevation_model="srtm3", username="cgadekunm")
grye.e4 <- elevation(grye4, elevation_model="srtm3", username="jwilliamson") 
grye.e5 <- elevation(grye5, elevation_model="srtm3", username="willford1")
grye.e6 <- elevation(grye6, elevation_model="srtm3", username="jwilliamson")
grye.e7 <- elevation(grye7, elevation_model="srtm3", username="jwilliamson")
grye.e8 <- elevation(grye8, elevation_model="srtm3", username="jwilliamson0110")
grye.e9 <- elevation(grye9, elevation_model="srtm3", username="jwilliamson0110") 
grye.e10 <- elevation(grye10, elevation_model="srtm3", username="cgadekunm")
grye.e11 <- elevation(grye11, elevation_model="srtm3", username="cgadekgmail") # done 
grye.e12 <- elevation(grye12, elevation_model="srtm3", username="jessiewgym") 
grye.e13 <- elevation(grye13, elevation_model="srtm3", username="cgadekunm")  
grye.e14 <- elevation(grye14, elevation_model="srtm3", username="cgadekgmail")
grye.e17 <- elevation(grye17, elevation_model="srtm3", username="jwilliamson0110")
grye.e18 <- elevation(grye18, elevation_model="srtm3", username="selina1")
grye.e19 <- elevation(grye19, elevation_model="srtm3", username="selina1")
grye.e20 <- elevation(grye20, elevation_model="srtm3", username="willford1")
grye.e21 <- elevation(grye21, elevation_model="srtm3", username="willford1")
grye.e23 <- elevation(grye23, elevation_model="srtm3", username="cgadekunm") 
grye.e15 <- elevation(grye15, elevation_model="srtm3", username="jwilliamson") 
grye.e22 <- elevation(grye22, elevation_model="srtm3", username="jessiewgym")
grye.e24 <- elevation(grye24, elevation_model="srtm3", username="selina1")
grye.e25 <- elevation(grye25, elevation_model="srtm3", username="jwilliamson0110")
grye.e16 <- elevation(grye16, elevation_model="srtm3", username="willford1") 
grye.e26 <- elevation(grye26, elevation_model="srtm3", username="willford1") 
grye.e27 <- elevation(grye27, elevation_model="srtm3", username="jwilliamson0110") 

##### temporary ##### until you can get grye.e27 to run 
# rbind mini data frames together again
grye.allbut.e27 <- rbind(grye.e0, grye.e1, grye.e2, grye.e3, grye.e4, grye.e5, grye.e6, grye.e7, grye.e8, grye.e9, grye.e10, grye.e11, grye.e12, grye.e13, grye.e14, grye.e15, grye.e16, grye.e17, grye.e18, grye.e19, grye.e20, grye.e21, grye.e22, grye.e23, grye.e24, grye.e25, grye.e26) 
write.csv(grye.allbut.e27, file = "grye.allbut.e27.csv") # ALL elevation records 
save(grye.allbut.e27, file="grye.allbut.e27.RData") # save as Rdata object so you don't have to do it every time
load("grye.allbut.e27.RData") # to load .RData file 

# because I deleted all other files, you'll need to rbind grye.allbut.e27 with grye.e27 to make grye.all
# then write that to a csv and save

# write all to .csv
write.csv(grye.e0, file = "grye.e0.csv")
write.csv(grye.e1, file = "grye.e1.csv")
write.csv(grye.e2, file = "grye.e2.csv")
write.csv(grye.e3, file = "grye.e3.csv")
write.csv(grye.e4, file = "grye.e4.csv")
write.csv(grye.e5, file = "grye.e5.csv")
write.csv(grye.e6, file = "grye.e6.csv")
write.csv(grye.e7, file = "grye.e7.csv")
write.csv(grye.e8, file = "grye.e8.csv")
write.csv(grye.e9, file = "grye.e9.csv")
write.csv(grye.e10, file = "grye.e10.csv")
write.csv(grye.e11, file = "grye.e11.csv")
write.csv(grye.e12, file = "grye.e12.csv")
write.csv(grye.e13, file = "grye.e13.csv")
write.csv(grye.e14, file = "grye.e14.csv")
write.csv(grye.e15, file = "grye.e15.csv")
write.csv(grye.e26, file = "grye.e26.csv")
write.csv(grye.e17, file = "grye.e17.csv")
write.csv(grye.e18, file = "grye.e18.csv")
write.csv(grye.e19, file = "grye.e19.csv")
write.csv(grye.e20, file = "grye.e20.csv")
write.csv(grye.e21, file = "grye.e21.csv")
write.csv(grye.e23, file = "grye.e23.csv")
write.csv(grye.e22, file = "grye.e22.csv")
write.csv(grye.e24, file = "grye.e24.csv")
write.csv(grye.e25, file = "grye.e25.csv")
write.csv(grye.e16, file = "grye.e16.csv")
write.csv(grye.e27, file = "grye.e27.csv")

# rbind mini data frames together again
 grye.all <- rbind(grye.allbut.e27, grye.e27) # matches grye.sub in length 

# grye.all <- rbind(grye.e0, grye.e1, grye.e2, grye.e3, grye.e4, grye.e5, grye.e6, grye.e7, grye.e8, grye.e9, grye.e10, grye.e11, grye.e12, grye.e13, grye.e14, grye.e15, grye.e16, grye.e17, grye.e18, grye.e19, grye.e20, grye.e21, grye.e22, grye.e23, grye.e24, grye.e25) 
#write.csv(grye.all, file = "grye.all.csv") # ALL elevation records 
#save(grye.all, file="grye.all.RData") # save as Rdata object so you don't have to do it every time
grye.all <- read.csv("grye.all.csv", header= TRUE)
load("grye.all.RData") # to load .RData file 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
grye.qc <- grye.all
grye.qc$elev_diff <- (grye.qc$elevation-grye.qc$elevation_geonames) # Make elev_diff variable 
grye.qc <- grye.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
grye.qc <- grye.qc[order(-grye.qc$elev_diff), ] # sort by elev_diff
grye.qc <- subset(grye.qc, grye.qc$elev_diff < 300 | is.na(grye.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
grye.elevs <- grye.qc %>% filter(!is.na(elevation)) # existing elev
grye.noelev <- grye.qc %>% filter(is.na(elevation)) # no original elevs
grye.elevs$final_elev <- grye.elevs$elevation # add final_elev, assign elevation values to it 
grye.noelev$final_elev <- grye.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
grye.final <- rbind(grye.elevs, grye.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
grye.final <- grye.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
grye.final <- grye.final[order(-grye.final$month, -grye.final$final_elev), ] # sort by month
grye.final <- grye.final[which(!grye.final$final_elev == "-32768"), ] # get rid of unrealistic ocean values
write.csv(grye.final, file = "grye.final.csv")
save(grye.final, file="grye.final.RData") # save as Rdata object so you don't have to do it every time
grye.final <- read.csv("grye.final.csv", header= TRUE)
load("grye.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE

grye.final <- grye.final[ , !(colnames(grye.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(grye.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
grye.final <- grye.final[!dup, ] # drop duplicate records
write.csv(grye.final, file = "grye.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(-160,-60), ylim=c(0,80))
points(grye.final$lon, grye.final$lat, col='orange', pch=20, cex=0.75) # add points
points(grye.final$lon, grye.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=grye.final, aes(x=month, y=final_elev, group=grye.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="grye")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
grye.nona <- subset(grye.final, select=oa) 
grye.nona <- subset(grye.nona, grye.nona$latitude > 50) # keep only breeding latitudes >50 degrees
  # Becasue grye don't breed in the lower 48
# is.na(grye.nona) # need no NAs to run outlier function 

# subset by breeding season (because you don't have nonbreeding data)
grye.b <- grye.nona[which(grye.nona$month==5 | grye.nona$month==6), ]
  # July too late - a lot of birds already migrating by then

# Plot of breeding season to identify outliers 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=grye.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: grye")
p <- p + theme_classic()
print(p)

boxplot(grye.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold  

# OUTLIER ANALYSIS AND REMOVAL 
grye.b.out <- FindOutliers(grye.b, r=1.5); grye.b.out # Detect outliers
grye.b <- grye.b[-grye.b.out$rownum,] # remove outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
grye.b.elevs <- BreedingElevs(grye.b); grye.b.elevs
#grye.nb.elevs <- NonbreedingElevs(grye.nb)
grye.elev.range <- grye.b.elevs
grye.elev.range["species"] <- "Tringa_flavipes"
grye.elev.range <- grye.elev.range[, c(3,1,2)]; grye.elev.range  # reorder columns 
write.csv(grye.elev.range, file = "grye.elev.range.csv") 
```



# ANDEAN GULL 
```{r}
# Import data
name_suggest(q="Chroicocephalus serranus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(angu.dl <- occ_download("taxonKey=6065825", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(angu.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
angu <- occ_download_get("0016817-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

angu.cit <- occ_download_get("0016817-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
angu.cit$download # prints one-line output with DOI

write.csv(angu, file = "angu.csv")
angu <- read.csv("angu.csv", header= TRUE)
```

```{r}
# Clean data  
angu.sub <- subset(angu, select=sc) # subset data w/ criteria defined in sc
angu.sub <- angu.sub[which(angu.sub$species == "Chroicocephalus serranus"),] # verify only desired species
angu.sub <- angu.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
angu.sub <- angu.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
angu.sub <- angu.sub[which(!angu.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
angu.sub <- angu.sub[which(!angu.sub$decimalLongitude == "0"), ] # Drop lon values of 0
angu.sub <- angu.sub[which(!angu.sub$month == "NA"), ] # Drop NA months
angu.sub <- angu.sub[which(!angu.sub$countryCode == "NA"), ] # Drop NA countries
colnames(angu.sub)[colnames(angu.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
angu.sub <- angu.sub[order(-angu.sub$coord_uncert), ] # sort by coordinate uncertainty
angu.sub <- subset(angu.sub, angu.sub$coord_uncert < 3000 | is.na(angu.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(angu.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
angu.sub <- angu.sub[which(!angu.sub$countryCode == "EC"), ] # Remove Ecuador 
angu.sub <- angu.sub[which(!angu.sub$countryCode == "NG"), ] # Remove NG 
angu.sub <- angu.sub[which(!angu.sub$countryCode == "CO"), ] # Remove Colombia 

# Too big, so splitting into 3: 
angu.split <- split(angu.sub, (seq(nrow(angu.sub))-1) %/% 4776) # splits data into chunks of 9000 (10k too big)
# angu.split.unlist <- do.call(rbind.data.frame, angu.split) # unsplits and makes a data frame 

angu0 <- as.data.frame(angu.split$"0")
angu1 <- as.data.frame(angu.split$"1")
angu2 <- as.data.frame(angu.split$"2")

# get elevs from rgbif (omg worse code ever kill me)
angu.e0 <- elevation(angu0, elevation_model="srtm3", username="jwilliamson0110")
angu.e1 <- elevation(angu1, elevation_model="srtm3", username="jessiewgym")
angu.e2 <- elevation(angu2, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# rbind mini data frames together again
angu.all <- rbind(angu.e0, angu.e1, angu.e2) # good, same length as angu.sub
write.csv(angu.all, file = "angu.all.csv")

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
angu.qc <- angu.all
angu.qc$elev_diff <- (angu.qc$elevation-angu.qc$elevation_geonames) # Make elev_diff variable 
angu.qc <- angu.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
angu.qc <- angu.qc[order(-angu.qc$elev_diff), ] # sort by elev_diff
angu.qc <- subset(angu.qc, angu.qc$elev_diff < 300 | is.na(angu.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
angu.elevs <- angu.qc %>% filter(!is.na(elevation)) # existing elev
angu.noelev <- angu.qc %>% filter(is.na(elevation)) # no original elevs
angu.elevs$final_elev <- angu.elevs$elevation # add final_elev, assign elevation values to it 
angu.noelev$final_elev <- angu.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
angu.final <- rbind(angu.elevs, angu.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
angu.final <- angu.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
angu.final <- angu.final[order(-angu.final$month, -angu.final$final_elev), ] # sort by month
angu.final <- angu.final[which(!angu.final$final_elev == "-32768"), ] # drop ocean points
write.csv(angu.final, file = "angu.final.csv")
save(angu.final, file="angu.final.RData") # save as Rdata object so you don't have to do it every time
angu.final <- read.csv("angu.final.csv", header= TRUE)
# load("angu.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

angu.final <- angu.final[ , !(colnames(angu.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(angu.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
angu.final <- angu.final[!dup, ] # drop duplicate records
write.csv(angu.final, file = "angu.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(-80,70), ylim=c(-60,10))
points(angu.final$lon, angu.final$lat, col='orange', pch=20, cex=0.75) # add points
points(angu.final$lon, angu.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=angu.final, aes(x=month, y=final_elev, group=angu.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="angu")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
#angu.cl <- angu.final[which(angu.final$countryCode == "CL"), ] # Chile only
#angu.pe <- angu.final[which(angu.final$countryCode == "PE"), ] # Peru only
angu.nona <- subset(angu.final, select=oa) 
# is.na(angu.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
angu.b <- angu.nona[which(angu.nona$month==10 | angu.nona$month==11), ] # breeding?
  # HBW says breeding is "mainly July-August"
  # Fjeldsa & Krabbe say "eggs Sept-Jan, fledglings Aug (Ecu)"
  # I'm guessing this has A LOT to do with latitude...
angu.nb <- angu.nona[which(angu.nona$month==5 | angu.nona$month==6), ] # nonbreeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=angu.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: angu")
p <- p + theme_classic()
print(p)

boxplot(angu.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=angu.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: angu")
p <- p + theme_classic()
print(p)

boxplot(angu.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
angu.b.out <- FindOutliers(angu.b, r=1.5); angu.b.out # Detect outliers
angu.nb.out <- FindOutliers(angu.nb, r=1.5); angu.nb.out # Detect outliers
# no outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
angu.b.elevs <- BreedingElevs(angu.b)
angu.nb.elevs <- NonbreedingElevs(angu.nb)
angu.elev.range <- cbind(angu.nb.elevs, angu.b.elevs); angu.elev.range
angu.elev.range["species"] <- "Chroicocephalus_serranus"
angu.elev.range <- angu.elev.range[, c(5,1,2,3,4)]; angu.elev.range  # reorder columns 
write.csv(angu.elev.range, file = "angu.elev.range.csv")
```



# TAWNY-THROATED DOTTEREL
```{r}
# Import data
name_suggest(q="Oreopholus ruficollis", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(ttdo.dl <- occ_download("taxonKey=2480254", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(ttdo.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
ttdo <- occ_download_get("0016165-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

ttdo.cit <- occ_download_get("0016165-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
ttdo.cit$download # prints one-line output with DOI

write.csv(ttdo, file = "ttdo.csv")
ttdo <- read.csv("ttdo.csv", header= TRUE)
```

```{r}
# Clean data  
ttdo.sub <- subset(ttdo, select=sc) # subset data w/ criteria defined in sc
ttdo.sub <- ttdo.sub[which(ttdo.sub$species == "Oreopholus ruficollis"),] # verify only desired species
ttdo.sub <- ttdo.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
ttdo.sub <- ttdo.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
ttdo.sub <- ttdo.sub[which(!ttdo.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
ttdo.sub <- ttdo.sub[which(!ttdo.sub$decimalLongitude == "0"), ] # Drop lon values of 0
ttdo.sub <- ttdo.sub[which(!ttdo.sub$month == "NA"), ] # Drop NA months
ttdo.sub <- ttdo.sub[which(!ttdo.sub$countryCode == "NA"), ] # Drop NA countries
colnames(ttdo.sub)[colnames(ttdo.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
ttdo.sub <- ttdo.sub[order(-ttdo.sub$coord_uncert), ] # sort by coordinate uncertainty
ttdo.sub <- subset(ttdo.sub, ttdo.sub$coord_uncert < 3000 | is.na(ttdo.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert

# Species-specific region adjustments 
ttdo.sub <- ttdo.sub[which(!ttdo.sub$countryCode == "FK"), ] # Exclude Falkland Islands records 

# Fetch elevations with elevation() from rgbif
ttdo.getelev <- elevation(ttdo.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
ttdo.qc <- ttdo.getelev
ttdo.qc$elev_diff <- (ttdo.qc$elevation-ttdo.qc$elevation_geonames) # Make elev_diff variable 
ttdo.qc <- ttdo.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
ttdo.qc <- ttdo.qc[order(-ttdo.qc$elev_diff), ] # sort by elev_diff
ttdo.qc <- subset(ttdo.qc, ttdo.qc$elev_diff < 300 | is.na(ttdo.qc$elev_diff)) 
ttdo.qc <- subset(ttdo.qc, ttdo.qc$elev_diff > -300 | is.na(ttdo.qc$elev_diff))  # drop negative values
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
ttdo.elevs <- ttdo.qc %>% filter(!is.na(elevation)) # existing elev
ttdo.noelev <- ttdo.qc %>% filter(is.na(elevation)) # no original elevs
ttdo.elevs$final_elev <- ttdo.elevs$elevation # add final_elev, assign elevation values to it 
ttdo.noelev$final_elev <- ttdo.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
ttdo.final <- rbind(ttdo.elevs, ttdo.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
ttdo.final <- ttdo.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
ttdo.final <- ttdo.final[order(-ttdo.final$month, -ttdo.final$final_elev), ] # sort by month
ttdo.final <- ttdo.final[which(!ttdo.final$final_elev == "-32768"), ] # get rid of weird elevs
write.csv(ttdo.final, file = "ttdo.final.csv")
save(ttdo.final, file="ttdo.final.RData") # save as Rdata object so you don't have to do it every time
ttdo.final <- read.csv("ttdo.final.csv", header= TRUE)
load("ttdo.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

ttdo.final <- ttdo.final[ , !(colnames(ttdo.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(ttdo.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
ttdo.final <- ttdo.final[!dup, ] # drop duplicate records
write.csv(ttdo.final, file = "ttdo.final.nodups.csv")

# delete galapagos record & weird Africa record
ttdo.final <- subset(ttdo.final, ttdo.final$longitude > -82 & ttdo.final$longitude < -50) 
# Keep only records East of -82 and West of -50

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(-100,50), ylim=c(-60,10))
points(ttdo.final$lon, ttdo.final$lat, col='orange', pch=20, cex=0.75) # add points
points(ttdo.final$lon, ttdo.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# more adjustments
count(ttdo.final$countryCode) # Lists all countries & number of observations per country
  # trying to isolate ruficollis
ttdo.final <- ttdo.final[which(!ttdo.final$countryCode == "NG"), ] # Exclude NG 
ttdo.final <- ttdo.final[which(!ttdo.final$countryCode == "PY"), ] # Exclude PY
ttdo.final <- ttdo.final[which(!ttdo.final$countryCode == "BR"), ] # Exclude BR
ttdo.final <- ttdo.final[which(!ttdo.final$countryCode == "EC"), ] # Exclude EC

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=ttdo.final, aes(x=month, y=final_elev, group=ttdo.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="ttdo")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
ttdo.pe <- ttdo.final[which(ttdo.final$countryCode == "PE"), ] # Peru only
ttdo.ar <- ttdo.final[which(ttdo.final$countryCode == "AR"), ] # Arg only
ttdo.austral <- subset(ttdo.final, subset = ttdo.final$countryCode %in% c("CL", "AR", "UY"))
ttdo.nona <- subset(ttdo.final, select=oa) 
ttdo.austral.nona <- subset(ttdo.austral, select=oa) 
# is.na(ttdo.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
ttdo.b <- ttdo.nona[which(ttdo.nona$month==11 | ttdo.nona$month==12), ] # breeding
  # NOTE: BREEDING FROM TTDO.FINAL = w/ all countries
ttdo.nb <- ttdo.austral.nona[which(ttdo.austral.nona$month==6 | ttdo.austral.nona$month==7), ] # nonbreeding
  # NOTE: NON-BREEDING JUST AN ASSESSMENT OF AUSTRAL COUNTRIES

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=ttdo.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: ttdo")
p <- p + theme_classic()
print(p)

boxplot(ttdo.b$final_elev, range=3, main="range=3") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=ttdo.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: ttdo")
p <- p + theme_classic()
print(p)

boxplot(ttdo.nb$final_elev, range=3, main="range =3") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
ttdo.b.out <- FindOutliers(ttdo.b, r=3); ttdo.b.out # Detect outliers
# ttdo.b <- ttdo.b[-ttdo.b.out$rownum,] # remove outliers
# Not sure I want to remove any of these as "outliers", as they fall w/in TTDO breeding range from published lit

ttdo.nb.out <- FindOutliers(ttdo.nb, r=3); ttdo.nb.out # Detect outliers
ttdo.nb <- ttdo.nb[-ttdo.nb.out$rownum,] # remove outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
ttdo.b.elevs <- BreedingElevs(ttdo.b)
ttdo.nb.elevs <- NonbreedingElevs(ttdo.nb)
ttdo.elev.range <- cbind(ttdo.nb.elevs, ttdo.b.elevs); ttdo.elev.range
ttdo.elev.range["species"] <- "Oreopholus_ruficollis"
ttdo.elev.range <- ttdo.elev.range[, c(5,1,2,3,4)]; ttdo.elev.range  # reorder columns 
write.csv(ttdo.elev.range, file = "ttdo.elev.range.csv")
 
# Need ULL! 
```



# SUBTROPICAL DORADITO
```{r}
# Import data
name_suggest(q="Pseudocolopteryx acutipennis", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(psac.dl <- occ_download("taxonKey=2482649", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(psac.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
psac <- occ_download_get("0017330-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

psac.cit <- occ_download_get("0017330-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
psac.cit$download # prints one-line output with DOI

write.csv(psac, file = "psac.csv")
psac <- read.csv("psac.csv", header= TRUE)
```

```{r}
# Clean data  
psac.sub <- subset(psac, select=sc) # subset data w/ criteria defined in sc
psac.sub <- psac.sub[which(psac.sub$species == "Pseudocolopteryx acutipennis"),] # verify only desired species
psac.sub <- psac.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
psac.sub <- psac.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
psac.sub <- psac.sub[which(!psac.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
psac.sub <- psac.sub[which(!psac.sub$decimalLongitude == "0"), ] # Drop lon values of 0
psac.sub <- psac.sub[which(!psac.sub$month == "NA"), ] # Drop NA months
psac.sub <- psac.sub[which(!psac.sub$countryCode == "NA"), ] # Drop NA countries
colnames(psac.sub)[colnames(psac.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
psac.sub <- psac.sub[order(-psac.sub$coord_uncert), ] # sort by coordinate uncertainty
psac.sub <- subset(psac.sub, psac.sub$coord_uncert < 3000 | is.na(psac.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(psac.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
# Choosing not to drop data now; may need to later once I see what this all looks like 

# Fetch elevations with elevation() from rgbif
psac.getelev <- elevation(psac.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
psac.qc <- psac.getelev
psac.qc$elev_diff <- (psac.qc$elevation-psac.qc$elevation_geonames) # Make elev_diff variable 
psac.qc <- psac.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
psac.qc <- psac.qc[order(-psac.qc$elev_diff), ] # sort by elev_diff
psac.qc <- subset(psac.qc, psac.qc$elev_diff < 300 | is.na(psac.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
psac.elevs <- psac.qc %>% filter(!is.na(elevation)) # existing elev
psac.noelev <- psac.qc %>% filter(is.na(elevation)) # no original elevs
psac.elevs$final_elev <- psac.elevs$elevation # add final_elev, assign elevation values to it 
psac.noelev$final_elev <- psac.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
psac.final <- rbind(psac.elevs, psac.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
psac.final <- psac.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
psac.final <- psac.final[order(-psac.final$month, -psac.final$final_elev), ] # sort by month
psac.final <- psac.final[which(!psac.final$final_elev == "-32768"), ] # drop ocean points
write.csv(psac.final, file = "psac.final.csv")
save(psac.final, file="psac.final.RData") # save as Rdata object so you don't have to do it every time
psac.final <- read.csv("psac.final.csv", header= TRUE)
# load("psac.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

psac.final <- psac.final[ , !(colnames(psac.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(psac.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
psac.final <- psac.final[!dup, ] # drop duplicate records
write.csv(psac.final, file = "psac.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(-100,50), ylim=c(-60,10)) # south Americaa
points(psac.final$lon, psac.final$lat, col='orange', pch=20, cex=0.75) # add points
points(psac.final$lon, psac.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# I want to see what each country looks like: 
psac.ec <- psac.final[which(psac.final$countryCode == "EC"), ] # EC only 
psac.co <- psac.final[which(psac.final$countryCode == "CO"), ] # Colombia only
psac.ar <- psac.final[which(psac.final$countryCode == "AR"), ] # Arg only
psac.pe <- psac.final[which(psac.final$countryCode == "PE"), ] # Pe only
psac.bo <- psac.final[which(psac.final$countryCode == "BO"), ] # bolivia only
psac.br <- psac.final[which(psac.final$countryCode == "BR"), ] # brazil only

# Ec: 2600-2700 m to 3,800 m Jan-Sept; records scarce Oct, Nov, Dec # drop 
# Co: ~1800-2500 year-round; records scarce in general # drop 
# Arg: 0-3200 m with lots of ups and downs and gap in distribution 
# pe: very high half the year, then low, lots of fluctuation 
# bo: too few records; some from very high, some from very low; none Oct-DEc
# brazil: all below 250 m; no records Dec-April 

# Based on above, Drop these countries from final dataset: 
psac.final <- psac.final[which(!psac.final$countryCode == "EC"), ] # Exclude EC
psac.final <- psac.final[which(!psac.final$countryCode == "CO"), ] # Exclude CO

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=psac.final, aes(x=month, y=final_elev, group=psac.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="psac")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
psac.nona <- subset(psac.final, select=oa) 
# is.na(psac.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
psac.b <- psac.nona[which(psac.nona$month==11 | psac.nona$month==12), ] # Breeding Nov-Dec
  # Note that this might be different for pops breeding in Peru, Ec, Colombia
  # Not possible to know if austral migrants come from Bol/Arg, or Peru, Ec, Colombia
psac.nb <- psac.nona[which(psac.nona$month==5 | psac.nona$month==6), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=psac.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: psac")
p <- p + theme_classic()
print(p)

boxplot(psac.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=psac.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: psac")
p <- p + theme_classic()
print(p)

boxplot(psac.nb$final_elev, range=1.5, main="range =1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
psac.b.out <- FindOutliers(psac.b, r=1.5); psac.b.out # Detect outliers
# NO OUTLIERS; plus, this isn't entirely accurate because this looks like a very country-specific range
# e.g. birds in Argentina may breed MUCH lower than birds in Peru 

psac.nb.out <- FindOutliers(psac.nb, r=1.5); psac.nb.out # Detect outliers
psac.nb <- psac.nb[-psac.nb.out$rownum,] # remove outliers
  # I have problems with the estimated ULL here because of country-specific patterns, but for LLL this is fine
  # There are clearly records of birds descenting to ~0 m in almost every country

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
psac.b.elevs <- BreedingElevs(psac.b)
psac.nb.elevs <- NonbreedingElevs(psac.nb)
psac.elev.range <- cbind(psac.nb.elevs, psac.b.elevs); psac.elev.range
psac.elev.range["species"] <- "Pseudocolopteryx_acutipennis"
psac.elev.range <- psac.elev.range[, c(5,1,2,3,4)]; psac.elev.range  # reorder columns 
write.csv(psac.elev.range, file = "psac.elev.range.csv")
```



# WILSON'S PHALAROPE
```{r}
# Import data
name_suggest(q="Phalaropus tricolor", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form; taxonKey & hasCoordinates must be in character string
(wiph.dl <- occ_download("taxonKey=5229389", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
      ## COMMENT THIS OUT ONCE DONE SO YOU DON'T RE-DOWNLOAD EVERY TIME

occ_download_meta(wiph.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
# wiph <- occ_download_get("0006365-190813142620410", overwrite=TRUE) %>% occ_download_import() 
  # NOTE: Download is so large that R crashes when importing this way 
  # I'm going to manually download from GBIF and import that way

wiph.cit <- occ_download_get("0006365-190813142620410", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
wiph.cit$download # prints one-line output with DOI

write.csv(wiph, file = "wiph.csv")
wiph <- read.csv("//Users/Jessie/Desktop/RDirectory/ENSM/Wilson'sPhalarope.csv", stringsAsFactors=FALSE)
```

```{r}
# Clean data  
wiph.sub <- subset(wiph, select=sc) # subset data w/ criteria defined in sc
wiph.sub <- wiph.sub[which(wiph.sub$species == "Phalaropus tricolor"),] # verify only desired species
wiph.sub <- wiph.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
wiph.sub <- wiph.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
wiph.sub <- wiph.sub[which(!wiph.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
wiph.sub <- wiph.sub[which(!wiph.sub$decimalLongitude == "0"), ] # Drop lon values of 0
wiph.sub <- wiph.sub[which(!wiph.sub$month == "NA"), ] # Drop NA months
wiph.sub <- wiph.sub[which(!wiph.sub$countryCode == "NA"), ] # Drop NA countries
colnames(wiph.sub)[colnames(wiph.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
wiph.sub <- wiph.sub[order(-wiph.sub$coord_uncert), ] # sort by coordinate uncertainty
wiph.sub <- subset(wiph.sub, wiph.sub$coord_uncert < 5000 | is.na(wiph.sub$coord_uncert)) 
    # Drop coord_uncert values >5000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 5000 | is.na(p$coord_uncert),]
    # NOTE: YOU FILTER BY 3,000 M LATER ON 

# Species-specific region adjustments 
wiph.sub$countryCode <- as.factor(wiph.sub$countryCode) # make countryCode a factor to be able to get levels
levels(wiph.sub$countryCode) # get levels 
wiph.sub <- wiph.sub[wiph.sub$countryCode == c("CA","US","EC","PE", "BO", "AR", "CL", "PY", "UY", "BR"), ]
  # Include only known US and CAN breeding distribution and known South American winter distribution 
  # Note: this gives a weird error message but appears to work 
count(wiph.sub$countryCode) # count number that appear to verify that this worked 
# wiph.sub <- wiph.sub[which(!wiph.sub$countryCode == "NL"), ] # Exclude Netherlands

# wiph.SUB IS TOO BIG TO PULL ALL ELEVS FROM - SPLIT BY MONTH, GET ELEVS, RECOMBINE
wiph.jan <- wiph.sub[which(wiph.sub$month == "1"), ]
wiph.feb <- wiph.sub[which(wiph.sub$month == "2"), ]
wiph.mar <- wiph.sub[which(wiph.sub$month == "3"), ]
wiph.apr <- wiph.sub[which(wiph.sub$month == "4"), ]
wiph.may <- wiph.sub[which(wiph.sub$month == "5"), ]
wiph.jun <- wiph.sub[which(wiph.sub$month == "6"), ]
wiph.jul <- wiph.sub[which(wiph.sub$month == "7"), ]
wiph.aug <- wiph.sub[which(wiph.sub$month == "8"), ]
wiph.sep <- wiph.sub[which(wiph.sub$month == "9"), ]
wiph.oct <- wiph.sub[which(wiph.sub$month == "10"), ]
wiph.nov <- wiph.sub[which(wiph.sub$month == "11"), ]
wiph.dec <- wiph.sub[which(wiph.sub$month == "12"), ]

# get elevs from rgbif - clunky AF, I can't even
# writing to csv as I go in case I need to avoid timing out with credits in GeoNames 
wiph1 <- elevation(wiph.jan, elevation_model="srtm3", username="jwilliamson")
write.csv(wiph1, file = "wiph1.csv") 
wiph2 <- elevation(wiph.feb, elevation_model="srtm3", username="jwilliamson")
write.csv(wiph2, file = "wiph2.csv") 
wiph3 <- elevation(wiph.mar, elevation_model="srtm3", username="jwilliamson")
write.csv(wiph3, file = "wiph3.csv") 
wiph4 <- elevation(wiph.apr, elevation_model="srtm3", username="jwilliamson")
write.csv(wiph4, file = "wiph4.csv") 
wiph6 <- elevation(wiph.jun, elevation_model="srtm3", username="jwilliamson0110")
write.csv(wiph6, file = "wiph6.csv") 
wiph7 <- elevation(wiph.jul, elevation_model="srtm3", username="cgadekunm")
write.csv(wiph7, file = "wiph7.csv")
wiph8 <- elevation(wiph.aug, elevation_model="srtm3", username="jwilliamson")
write.csv(wiph8, file = "wiph8.csv")
wiph9 <- elevation(wiph.sep, elevation_model="srtm3", username="jwilliamson")
write.csv(wiph9, file = "wiph9.csv")
wiph10 <- elevation(wiph.oct, elevation_model="srtm3", username="jwilliamson")
write.csv(wiph10, file = "wiph10.csv")
wiph11 <- elevation(wiph.nov, elevation_model="srtm3", username="jwilliamson")
write.csv(wiph11, file = "wiph11.csv") 
wiph12 <- elevation(wiph.dec, elevation_model="srtm3", username="jwilliamson0110")
write.csv(wiph12, file = "wiph12.csv") 

# too big, needs to be split 
# wiph5 <- elevation(wiph.may, elevation_model="srtm3", username="jwilliamson0110") # needs to be split  
count(wiph.may$countryCode) # get numbers/country
(wiph5.split <- split(wiph.may, wiph.may$countryCode)) # split by country 
wiph5.AR <- as.data.frame(wiph5.split$AR) # wrangle list into data frames 
wiph5.CA <- as.data.frame(wiph5.split$CA) 
wiph5.CL <- as.data.frame(wiph5.split$CL) 
wiph5.EC <- as.data.frame(wiph5.split$EC) 
wiph5.PE <- as.data.frame(wiph5.split$PE) 
wiph5.US <- as.data.frame(wiph5.split$US) 

wiph.AR <- elevation(wiph5.AR, elevation_model="srtm3", username="jwilliamson") # get elevs 
wiph.CL <- elevation(wiph5.CL, elevation_model="srtm3", username="jwilliamson")
wiph.CA <- elevation(wiph5.CA, elevation_model="srtm3", username="jwilliamson")
wiph.EC <- elevation(wiph5.EC, elevation_model="srtm3", username="jwilliamson0110")
wiph.PE <- elevation(wiph5.PE, elevation_model="srtm3", username="jwilliamson0110")
wiph.US <- elevation(wiph5.US, elevation_model="srtm3", username="cgadekunm")

wiph.may.all <- rbind(wiph.AR, wiph.CL, wiph.CA, wiph.EC, wiph.PE, wiph.US) # rbind May  

  # rbind mini data frames together again
wiph.all <- rbind(wiph1, wiph2, wiph3, wiph4, wiph.may.all, wiph6, wiph7, wiph8, wiph9, wiph10, wiph11, wiph12) 
write.csv(wiph.all, file = "wiph.all.csv") # ALL elevation records 
# wiph.all <- read.csv("wiph.all.csv", header= TRUE)

wiph.all <- wiph.all[, -1] # when reading in as .csv, R inserts a weird first column called "X"
  # Need to drop this so other code runs 

wiph.all <- subset(wiph.all, wiph.all$coord_uncert < 3000 | is.na(wiph.all$coord_uncert)) 
    # Filter to make more stringent: Drop coord_uncert values >0300 *and* keep NA values for coord_uncert

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
wiph.qc <- wiph.all
wiph.qc$elev_diff <- (wiph.qc$elevation-wiph.qc$elevation_geonames) # Make elev_diff variable 
wiph.qc <- wiph.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
wiph.qc <- wiph.qc[order(-wiph.qc$elev_diff), ] # sort by elev_diff
wiph.qc <- subset(wiph.qc, wiph.qc$elev_diff < 300 | is.na(wiph.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
wiph.elevs <- wiph.qc %>% filter(!is.na(elevation)) # existing elev
wiph.noelev <- wiph.qc %>% filter(is.na(elevation)) # no original elevs
wiph.elevs$final_elev <- wiph.elevs$elevation # add final_elev, assign elevation values to it 
wiph.noelev$final_elev <- wiph.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
wiph.final <- rbind(wiph.elevs, wiph.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
wiph.final <- wiph.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
wiph.final <- wiph.final[order(-wiph.final$month, -wiph.final$final_elev), ] # sort by month
wiph.final <- wiph.final[which(!wiph.final$final_elev == "-32768"), ] # get rid of ocean values
write.csv(wiph.final, file = "wiph.final.csv")
save(wiph.final, file="wiph.final.RData") # save as Rdata object so you don't have to do it every time
wiph.final <- read.csv("wiph.final.csv", header= TRUE)
# load("wiph.final.RData") # to load .RData file
```


```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

wiph.final <- wiph.final[ , !(colnames(wiph.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(wiph.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
wiph.final <- wiph.final[!dup, ] # drop duplicate records
write.csv(wiph.final, file = "wiph.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
#plot(wrld_simpl, axes=TRUE, col="white", xlim=c(-100,50), ylim=c(-60,10)) # south America
points(wiph.final$lon, wiph.final$lat, col='orange', pch=20, cex=0.75) # add points
points(wiph.final$lon, wiph.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=wiph.nonbreed, aes(x=month, y=final_elev, group=wiph.nonbreed$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="wiph.nonbreed")
p <- p + theme_classic()
print(p)

count(wiph.final$countryCode) # Lists all countries & number of observations per country

# Wrangle breeding data 
wiph.breed <- subset(wiph.final, subset = wiph.final$countryCode %in% c("US", "CA"))
wiph.breed <- subset(wiph.breed, wiph.breed$latitude > 38 & wiph.breed$longitude < -96) 
  # keep only breeding latitudes >38 degrees *AND* longitudes west of -96 (to get out core breeding range)
  # Note: Need "&" instead of | to simultaneously filter by both criteria
  # Need space beween "<" and "-96 long" or R thinks I mean "<-", which looks like I'm assigning a variable

# Wrangle nonbreeding data 
wiph.nonbreed <- subset(wiph.final, subset = wiph.final$countryCode %in% c("EC", "PE", "BO", "CL", "AR"))

#wiph.ec <- wiph.final[which(wiph.final$countryCode == "EC"), ] # EC only 
#wiph.ar <- wiph.final[which(wiph.final$countryCode == "AR"), ] # Arg only
#wiph.pe <- wiph.final[which(wiph.final$countryCode == "PE"), ] # Pe only
#wiph.bo <- wiph.final[which(wiph.final$countryCode == "BO"), ] # bolivia only
#wiph.cl <- wiph.final[which(wiph.final$countryCode == "CL"), ] # Chile only

# subset for outlier analysis, check for NAs
wiph.b.nona <- subset(wiph.breed, select=oa) 
wiph.nb.nona <- subset(wiph.nonbreed, select=oa) 
# is.na(wiph.nona) # need no NAs to run outlier function 


# subset by breeding and non-breeding season 
wiph.b <- wiph.b.nona[which(wiph.b.nona$month==5 | wiph.b.nona$month==6), ] # Breeding in northern summer 
wiph.nb <- wiph.nb.nona[which(wiph.nb.nona$month==11 | wiph.nb.nona$month==12), ] # Nonbreeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=wiph.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: wiph")
p <- p + theme_classic()
print(p)

boxplot(wiph.b$final_elev, range=1.5, main="range=1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=wiph.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: wiph")
p <- p + theme_classic()
print(p)

boxplot(wiph.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
wiph.b.out <- FindOutliers(wiph.b, r=1.5); wiph.b.out # Detect outliers
wiph.b <- wiph.b[-wiph.b.out$rownum,] # remove outliers

wiph.nb.out <- FindOutliers(wiph.nb, r=1.5); wiph.nb.out # Detect outliers
# no outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
wiph.nb.elevs <- BreedingElevs(wiph.nb) # remember to pass these backwards since breeding is LOW
wiph.b.elevs <- NonbreedingElevs(wiph.b) # remember to pass these backwards since breeding is LOW
wiph.elev.range <- cbind(wiph.b.elevs, wiph.nb.elevs); wiph.elev.range
wiph.elev.range["species"] <- "Phalaropus_tricolor"
wiph.elev.range <- wiph.elev.range[, c(5,1,2,3,4)]; wiph.elev.range  # reorder columns 
write.csv(wiph.elev.range, file = "wiph.elev.range.csv")
```



# OCHRE-NAPED GROUND-TYRANT
```{r}
# Import data
name_suggest(q="Muscisaxicola flavinucha", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(mufl.dl <- occ_download("taxonKey=2483697", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(mufl.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
mufl <- occ_download_get("0017412-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 

mufl.cit <- occ_download_get("0017412-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
mufl.cit$download # prints one-line output with DOI

write.csv(mufl, file = "mufl.csv")
mufl <- read.csv("mufl.csv", header= TRUE)
```

```{r}
# Clean data  
mufl.sub <- subset(mufl, select=sc) # subset data w/ criteria defined in sc
mufl.sub <- mufl.sub[which(mufl.sub$species == "Muscisaxicola flavinucha"),] # verify only desired species
mufl.sub <- mufl.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
mufl.sub <- mufl.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
mufl.sub <- mufl.sub[which(!mufl.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
mufl.sub <- mufl.sub[which(!mufl.sub$decimalLongitude == "0"), ] # Drop lon values of 0
mufl.sub <- mufl.sub[which(!mufl.sub$month == "NA"), ] # Drop NA months
mufl.sub <- mufl.sub[which(!mufl.sub$countryCode == "NA"), ] # Drop NA countries
colnames(mufl.sub)[colnames(mufl.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
mufl.sub <- mufl.sub[order(-mufl.sub$coord_uncert), ] # sort by coordinate uncertainty
mufl.sub <- subset(mufl.sub, mufl.sub$coord_uncert < 3000 | is.na(mufl.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(mufl.sub$countryCode) # Lists all countries & number of observations per country

# Keep all regions

# Fetch elevations with elevation() from rgbif
mufl.getelev <- elevation(mufl.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
mufl.qc <- mufl.getelev
mufl.qc$elev_diff <- (mufl.qc$elevation-mufl.qc$elevation_geonames) # Make elev_diff variable 
mufl.qc <- mufl.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
mufl.qc <- mufl.qc[order(-mufl.qc$elev_diff), ] # sort by elev_diff
mufl.qc <- subset(mufl.qc, mufl.qc$elev_diff < 300 | is.na(mufl.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
mufl.elevs <- mufl.qc %>% filter(!is.na(elevation)) # existing elev
mufl.noelev <- mufl.qc %>% filter(is.na(elevation)) # no original elevs
mufl.elevs$final_elev <- mufl.elevs$elevation # add final_elev, assign elevation values to it 
mufl.noelev$final_elev <- mufl.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
mufl.final <- rbind(mufl.elevs, mufl.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
mufl.final <- mufl.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
mufl.final <- mufl.final[order(-mufl.final$month, -mufl.final$final_elev), ] # sort by month
mufl.final <- mufl.final[which(!mufl.final$final_elev == "-32768"), ] # drop ocean points
write.csv(mufl.final, file = "mufl.final.csv")
save(mufl.final, file="mufl.final.RData") # save as Rdata object so you don't have to do it every time
mufl.final <- read.csv("mufl.final.csv", header= TRUE)
# load("mufl.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

mufl.final <- mufl.final[ , !(colnames(mufl.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(mufl.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
mufl.final <- mufl.final[!dup, ] # drop duplicate records
write.csv(mufl.final, file = "mufl.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(-100,50), ylim=c(-60,10)) # south America
points(mufl.final$lon, mufl.final$lat, col='orange', pch=20, cex=0.75) # add points
points(mufl.final$lon, mufl.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=mufl.final, aes(x=month, y=final_elev, group=mufl.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="mufl")
p <- p + theme_classic()
print(p)

# Wrangle breeding data 
mufl.breed <- subset(mufl.final, subset = mufl.final$countryCode %in% c("AR", "CL"))
  # REmove few Bolivia and Peru records, as M. flavinucha brevirostris doesn't (supposedly) breed there 

# subset for outlier analysis, check for NAs
mufl.b.nona <- subset(mufl.breed, select=oa) 
mufl.nb.nona <- subset(mufl.final, select=oa) 
# is.na(mufl.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
mufl.b <- mufl.b.nona[which(mufl.b.nona$month==11 | mufl.b.nona$month==12 | mufl.b.nona$month==1), ] 
  # Breeding Oct-February 
mufl.nb <- mufl.nb.nona[which(mufl.nb.nona$month==5 | mufl.nb.nona$month==6 | mufl.nb.nona$month==7), ] 
# Nonbreeding - there are 3 Chile records here, but they're all from N where species is nonbreeding resident so ok

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=mufl.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: mufl")
p <- p + theme_classic()
print(p)

boxplot(mufl.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=mufl.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: mufl")
p <- p + theme_classic()
print(p)

boxplot(mufl.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
mufl.b.out <- FindOutliers(mufl.b, r=1.5); mufl.b.out # Detect outliers
# no outliers

mufl.nb.out <- FindOutliers(mufl.nb, r=1.5); mufl.nb.out # Detect outliers
mufl.nb <- mufl.nb[-mufl.nb.out$rownum,] # remove the outliers by calling row numbers they correspond to 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
mufl.nb.elevs <- BreedingElevs(mufl.nb) # remember to pass these backwards since breeding is LOW
mufl.b.elevs <- NonbreedingElevs(mufl.b) # remember to pass these backwards since breeding is LOW
mufl.elev.range <- cbind(mufl.b.elevs, mufl.nb.elevs); mufl.elev.range
mufl.elev.range["species"] <- "Muscisaxicola_flavinucha"
mufl.elev.range <- mufl.elev.range[, c(5,1,2,3,4)]; mufl.elev.range  # reorder columns 
write.csv(mufl.elev.range, file = "mufl.elev.range.csv")
 
```



# CINNAMON-BELLIED GROUND-TYRANT
```{r}
# Import data
name_suggest(q="Muscisaxicola capistratus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(muca.dl <- occ_download("taxonKey=2483717", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(muca.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
muca <- occ_download_get("0017428-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
muca.cit <- occ_download_get("0017428-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
muca.cit$download # prints one-line output with DOI

write.csv(muca, file = "muca.csv")
muca <- read.csv("muca.csv", header= TRUE)
```

```{r}
# Clean data  
muca.sub <- subset(muca, select=sc) # subset data w/ criteria defined in sc
muca.sub <- muca.sub[which(muca.sub$species == "Muscisaxicola capistratus"),] # verify only desired species
muca.sub <- muca.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
muca.sub <- muca.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
muca.sub <- muca.sub[which(!muca.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
muca.sub <- muca.sub[which(!muca.sub$decimalLongitude == "0"), ] # Drop lon values of 0
muca.sub <- muca.sub[which(!muca.sub$month == "NA"), ] # Drop NA months
muca.sub <- muca.sub[which(!muca.sub$countryCode == "NA"), ] # Drop NA countries
colnames(muca.sub)[colnames(muca.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
muca.sub <- muca.sub[order(-muca.sub$coord_uncert), ] # sort by coordinate uncertainty
muca.sub <- subset(muca.sub, muca.sub$coord_uncert < 3000 | is.na(muca.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(muca.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
# Keep all  

# Fetch elevations with elevation() from rgbif
muca.getelev <- elevation(muca.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
muca.qc <- muca.getelev
muca.qc$elev_diff <- (muca.qc$elevation-muca.qc$elevation_geonames) # Make elev_diff variable 
muca.qc <- muca.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
muca.qc <- muca.qc[order(-muca.qc$elev_diff), ] # sort by elev_diff
muca.qc <- subset(muca.qc, muca.qc$elev_diff < 300 | is.na(muca.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
muca.elevs <- muca.qc %>% filter(!is.na(elevation)) # existing elev
muca.noelev <- muca.qc %>% filter(is.na(elevation)) # no original elevs
muca.elevs$final_elev <- muca.elevs$elevation # add final_elev, assign elevation values to it 
muca.noelev$final_elev <- muca.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
muca.final <- rbind(muca.elevs, muca.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
muca.final <- muca.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
muca.final <- muca.final[order(-muca.final$month, -muca.final$final_elev), ] # sort by month
muca.final <- muca.final[which(!muca.final$final_elev == "-32768"), ] # drop ocean points
write.csv(muca.final, file = "muca.final.csv")
save(muca.final, file="muca.final.RData") # save as Rdata object so you don't have to do it every time
muca.final <- read.csv("muca.final.csv", header= TRUE)
# load("muca.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

muca.final <- muca.final[ , !(colnames(muca.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(muca.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
muca.final <- muca.final[!dup, ] # drop duplicate records
write.csv(muca.final, file = "muca.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(-100,50), ylim=c(-60,10)) # south America
points(muca.final$lon, muca.final$lat, col='orange', pch=20, cex=0.75) # add points
points(muca.final$lon, muca.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=muca.final, aes(x=month, y=final_elev, group=muca.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="muca")
p <- p + theme_classic()
print(p)

# Wrangle breeding data 
muca.breed <- subset(muca.final, subset = muca.final$countryCode %in% c("AR", "CL")) # breeding localities
muca.breed <- subset(muca.breed, muca.breed$latitude < -44) # subset by extent of breeding latitude 

# Wrangle non-breeding data 
muca.clar <- subset(muca.final, subset = muca.final$countryCode %in% c("AR", "CL")) # non-breeding localities
muca.clar <- subset(muca.clar, muca.clar$latitude > -44) # subset by extent of breeding latitude 
muca.bope <- subset(muca.final, subset = muca.final$countryCode %in% c("BO", "PE"))
muca.nonbreed <- rbind(muca.clar, muca.bope)

# subset for outlier analysis, check for NAs
muca.b.nona <- subset(muca.breed, select=oa) 
muca.nb.nona <- subset(muca.nonbreed, select=oa) 
# is.na(muca.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
muca.b <- muca.b.nona[which(muca.b.nona$month==11 | muca.b.nona$month==12 | muca.b.nona$month==1), ] 
  # Breeding Oct-February 
muca.nb <- muca.nb.nona[which(muca.nb.nona$month==5 | muca.nb.nona$month==6 | muca.nb.nona$month==7), ] 
# Nonbreeding - there are 3 Chile records here, but they're all from N where species is nonbreeding resident so ok

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=muca.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: muca")
p <- p + theme_classic()
print(p)

boxplot(muca.b$final_elev, range = 2, main="range = 2") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=muca.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: muca")
p <- p + theme_classic()
print(p)

boxplot(muca.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
muca.b.out <- FindOutliers(muca.b, r=2); muca.b.out # Detect outliers
muca.b <- muca.b[-muca.b.out$rownum,] # remove the outliers by calling row numbers they correspond to 

muca.nb.out <- FindOutliers(muca.nb, r=1.5); muca.nb.out # Detect outliers
muca.nb <- muca.nb[-muca.nb.out$rownum,] # remove the outliers by calling row numbers they correspond to 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
muca.nb.elevs <- BreedingElevs(muca.nb) # remember to pass these backwards since breeding is LOW
muca.b.elevs <- NonbreedingElevs(muca.b) # remember to pass these backwards since breeding is LOW
muca.elev.range <- cbind(muca.b.elevs, muca.nb.elevs); muca.elev.range
muca.elev.range["species"] <- "Muscisaxicola_capistratus"
muca.elev.range <- muca.elev.range[, c(5,1,2,3,4)]; muca.elev.range  # reorder columns 
write.csv(muca.elev.range, file = "muca.elev.range.csv")
```



# BUFF-WINGED CINCLODES  
```{r}
# Import data
# name_suggest(q="Cinclodes fuscus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
#(cifu.dl <- occ_download("taxonKey=2485069", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

# occ_download_meta(cifu.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
#cifu <- occ_download_get("0001282-190813142620410", overwrite=TRUE) %>% occ_download_import() 

#cifu.cit <- occ_download_get("0001282-190813142620410", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
#cifu.cit$download # prints one-line output with DOI

#write.csv(cifu, file = "cifu.csv")

# NOTE: All of the above works, but for some reason downloads Xiphorhynchus fuscus (Lesser Woodcreeper) records
# read in data manually
cifu <- read.csv("//Users/Jessie/Desktop/RDirectory/ENSM/Cinclodes_fuscus.csv", stringsAsFactors=FALSE)
```

```{r}
# Clean data  
cifu.sub <- cifu[which(cifu$scientificName == "Cinclodes fuscus (Vieillot, 1818)"),] # verify only desired species
    # Doing it this way becuase there is a terrible GBIF error and Cinclodes sp. have genus "Xiphorynchus"
cifu.sub <- subset(cifu, select=sc) # subset data w/ criteria defined in sc
cifu.sub$species <- "Cinclodes fuscus" # Make sure proper SciName is listed to eliminate confusion
cifu.sub <- cifu.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
cifu.sub <- cifu.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
cifu.sub <- cifu.sub[which(!cifu.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
cifu.sub <- cifu.sub[which(!cifu.sub$decimalLongitude == "0"), ] # Drop lon values of 0
cifu.sub <- cifu.sub[which(!cifu.sub$month == "NA"), ] # Drop NA months
cifu.sub <- cifu.sub[which(!cifu.sub$countryCode == "NA"), ] # Drop NA countries
colnames(cifu.sub)[colnames(cifu.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
cifu.sub <- cifu.sub[order(-cifu.sub$coord_uncert), ] # sort by coordinate uncertainty
cifu.sub <- subset(cifu.sub, cifu.sub$coord_uncert < 3000 | is.na(cifu.sub$coord_uncert)) 
    # Drop coord_uncert values > 3000 *and* keep NA values for coord_uncert
count(cifu.sub$countryCode)

# Species-specific region adjustments 
cifu.sub <- cifu.sub[which(cifu.sub$countryCode == "CL"), ] # Keep only Chile records

# Fetch elevations with elevation() from rgbif
cifu.getelev <- elevation(cifu.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
cifu.qc <- cifu.getelev
cifu.qc$elev_diff <- (cifu.qc$elevation-cifu.qc$elevation_geonames) # Make elev_diff variable 
cifu.qc <- cifu.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
cifu.qc <- cifu.qc[order(-cifu.qc$elev_diff), ] # sort by elev_diff
cifu.qc <- subset(cifu.qc, cifu.qc$elev_diff < 300 | is.na(cifu.qc$elev_diff)) 
cifu.qc <- subset(cifu.qc, cifu.qc$elev_diff > -300 | is.na(cifu.qc$elev_diff))  # drop negative values 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
cifu.elevs <- cifu.qc %>% filter(!is.na(elevation)) # existing elev
cifu.noelev <- cifu.qc %>% filter(is.na(elevation)) # no original elevs
cifu.elevs$final_elev <- cifu.elevs$elevation # add final_elev, assign elevation values to it 
cifu.noelev$final_elev <- cifu.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
cifu.final <- rbind(cifu.elevs, cifu.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
cifu.final <- cifu.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
cifu.final <- cifu.final[order(-cifu.final$month, -cifu.final$final_elev), ] # sort by month
cifu.final <- cifu.final[which(!cifu.final$final_elev == "-32768"), ] # get rid of weird elevs
write.csv(cifu.final, file = "cifu.final.csv")
save(cifu.final, file="cifu.final.RData") # save as Rdata object so you don't have to do it every time
cifu.final <- read.csv("cifu.final.csv", header= TRUE)
# load("cifu.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

cifu.final <- cifu.final[ , !(colnames(cifu.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(cifu.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
cifu.final <- cifu.final[!dup, ] # drop duplicate records
write.csv(cifu.final, file = "cifu.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(-100,50), ylim=c(-60,10)) # south America
points(cifu.final$lon, cifu.final$lat, col='orange', pch=20, cex=0.75) # add points
points(cifu.final$lon, cifu.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=cifu.final, aes(x=month, y=final_elev, group=cifu.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="cifu")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
cifu.nona <- subset(cifu.final, select=oa) 
is.na(cifu.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
cifu.b <- cifu.nona[which(cifu.nona$month==11 | cifu.nona$month==12), ] # Breeding Sept-Jan
cifu.nb <- cifu.nona[which(cifu.nona$month==6 | cifu.nona$month==7), ] # Nonbreding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=cifu.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: cifu")
p <- p + theme_classic()
print(p)

boxplot(cifu.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=cifu.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: cifu")
p <- p + theme_classic()
print(p)

boxplot(cifu.nb$final_elev, range=9, main="range=9") # Non-breeding lumped; check outlier threshold
# This is kind of a tricky one; I set a very, very conservative limit based on where it looked like a natural break 
# in the distribution occurred, according to the plot

# OUTLIER ANALYSIS AND REMOVAL 
cifu.b.out <- FindOutliers(cifu.b, r=1.5); cifu.b.out # Detect outliers
# no outliers

cifu.nb.out <- FindOutliers(cifu.nb, r=9); cifu.nb.out # Detect outliers
cifu.nb <- cifu.nb[-cifu.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
cifu.b.elevs <- BreedingElevs(cifu.b)
cifu.nb.elevs <- NonbreedingElevs(cifu.nb)
cifu.elev.range <- cbind(cifu.nb.elevs, cifu.b.elevs); cifu.elev.range
cifu.elev.range["species"] <- "Cinclodes_fuscus"
cifu.elev.range <- cifu.elev.range[, c(5,1,2,3,4)]; cifu.elev.range  # reorder columns 
write.csv(cifu.elev.range, file = "cifu.elev.range.csv")
 
```



# HILL PIGEON
```{r}
# Import data
name_suggest(q="Columba rupestris", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(coru.dl <- occ_download("taxonKey=5231820", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(coru.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
coru <- occ_download_get("0017566-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
coru.cit <- occ_download_get("0017566-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
coru.cit$download # prints one-line output with DOI

write.csv(coru, file = "coru.csv")
coru <- read.csv("coru.csv", header= TRUE)
```

```{r}
# Clean data  
coru.sub <- subset(coru, select=sc) # subset data w/ criteria defined in sc
coru.sub <- coru.sub[which(coru.sub$species == "Columba rupestris"),] # verify only desired species
coru.sub <- coru.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
coru.sub <- coru.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
coru.sub <- coru.sub[which(!coru.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
coru.sub <- coru.sub[which(!coru.sub$decimalLongitude == "0"), ] # Drop lon values of 0
coru.sub <- coru.sub[which(!coru.sub$month == "NA"), ] # Drop NA months
coru.sub <- coru.sub[which(!coru.sub$countryCode == "NA"), ] # Drop NA countries
colnames(coru.sub)[colnames(coru.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
coru.sub <- coru.sub[order(-coru.sub$coord_uncert), ] # sort by coordinate uncertainty
coru.sub <- subset(coru.sub, coru.sub$coord_uncert < 3000 | is.na(coru.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(coru.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
coru.sub <- subset(coru.sub, subset = coru.sub$countryCode %in% c("IN", "NP")) # keep countries 

# Fetch elevations with elevation() from rgbif
coru.getelev <- elevation(coru.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
coru.qc <- coru.getelev
coru.qc$elev_diff <- (coru.qc$elevation-coru.qc$elevation_geonames) # Make elev_diff variable 
coru.qc <- coru.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
coru.qc <- coru.qc[order(-coru.qc$elev_diff), ] # sort by elev_diff
coru.qc <- subset(coru.qc, coru.qc$elev_diff < 300 | is.na(coru.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
coru.elevs <- coru.qc %>% filter(!is.na(elevation)) # existing elev
coru.noelev <- coru.qc %>% filter(is.na(elevation)) # no original elevs
coru.elevs$final_elev <- coru.elevs$elevation # add final_elev, assign elevation values to it 
coru.noelev$final_elev <- coru.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
coru.final <- rbind(coru.elevs, coru.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
coru.final <- coru.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
coru.final <- coru.final[order(-coru.final$month, -coru.final$final_elev), ] # sort by month
coru.final <- coru.final[which(!coru.final$final_elev == "-32768"), ] # drop ocean points
write.csv(coru.final, file = "coru.final.csv")
save(coru.final, file="coru.final.RData") # save as Rdata object so you don't have to do it every time
coru.final <- read.csv("coru.final.csv", header= TRUE)
# load("coru.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

coru.final <- coru.final[ , !(colnames(coru.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(coru.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
coru.final <- coru.final[!dup, ] # drop duplicate records
write.csv(coru.final, file = "coru.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(coru.final$lon, coru.final$lat, col='orange', pch=20, cex=0.75) # add points
points(coru.final$lon, coru.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# country-specific
coru.in <- coru.final[which(coru.final$countryCode == "IN"), ] # india
coru.np <- coru.final[which(coru.final$countryCode == "NP"), ] # nepal

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=coru.final, aes(x=month, y=final_elev, group=coru.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="coru")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
coru.nona <- subset(coru.in, select=oa) 
is.na(coru.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
coru.b <- coru.nona[which(coru.nona$month==5 | coru.nona$month==6), ] # Breeding April-July
coru.nb <- coru.nona[which(coru.nona$month==11 | coru.nona$month==12), ] # nonbreeding

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=coru.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: coru")
p <- p + theme_classic()
print(p)

boxplot(coru.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=coru.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: coru")
p <- p + theme_classic()
print(p)

boxplot(coru.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
coru.b.out <- FindOutliers(coru.b, r=1.5); coru.b.out # Detect outliers
coru.b <- coru.b[-coru.b.out$rownum,] # remove the outliers 

coru.nb.out <- FindOutliers(coru.nb, r=1.5); coru.nb.out # Detect outliers
    # No outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
coru.b.elevs <- BreedingElevs(coru.b)
coru.nb.elevs <- NonbreedingElevs(coru.nb)
coru.elev.range <- cbind(coru.nb.elevs, coru.b.elevs); coru.elev.range
coru.elev.range["species"] <- "Columba_rupestris"
coru.elev.range <- coru.elev.range[, c(5,1,2,3,4)]; coru.elev.range  # reorder columns 
write.csv(coru.elev.range, file = "coru.elev.range.csv")
```



# LESSER SAND PLOVER
```{r}
# Import data
name_suggest(q="Charadrius mongolus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(chmo.dl <- occ_download("taxonKey=9722670", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(chmo.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
chmo <- occ_download_get("0018207-191105090559680", overwrite=TRUE) %>% occ_download_import()
  # So weird: at this point, the "fill=FALSE, quote="" " I was using to prevent function from breaking 
  # stopped working - then GBIF would give me a huge error message about improper downloads...
  # So I removed this and it started working fine again :/ 

chmo.cit <- occ_download_get("0018207-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
chmo.cit$download # prints one-line output with DOI

write.csv(chmo, file = "chmo.csv")
chmo <- read.csv("chmo.csv", header= TRUE)
```

```{r}
# Clean data  
chmo.sub <- subset(chmo, select=sc) # subset data w/ criteria defined in sc
chmo.sub <- chmo.sub[which(chmo.sub$species == "Charadrius mongolus"),] # verify only desired species
chmo.sub <- chmo.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
chmo.sub <- chmo.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
chmo.sub <- chmo.sub[which(!chmo.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
chmo.sub <- chmo.sub[which(!chmo.sub$decimalLongitude == "0"), ] # Drop lon values of 0
chmo.sub <- chmo.sub[which(!chmo.sub$month == "NA"), ] # Drop NA months
chmo.sub <- chmo.sub[which(!chmo.sub$countryCode == "NA"), ] # Drop NA countries
colnames(chmo.sub)[colnames(chmo.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
chmo.sub <- chmo.sub[order(-chmo.sub$coord_uncert), ] # sort by coordinate uncertainty
chmo.sub <- subset(chmo.sub, chmo.sub$coord_uncert < 3000 | is.na(chmo.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(chmo.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
chmo.sub <- chmo.sub[which(chmo.sub$countryCode == "IN"), ] # India only

# Fetch elevations with elevation() from rgbif
chmo.getelev <- elevation(chmo.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
chmo.qc <- chmo.getelev
chmo.qc$elev_diff <- (chmo.qc$elevation-chmo.qc$elevation_geonames) # Make elev_diff variable 
chmo.qc <- chmo.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
chmo.qc <- chmo.qc[order(-chmo.qc$elev_diff), ] # sort by elev_diff
chmo.qc <- subset(chmo.qc, chmo.qc$elev_diff < 300 | is.na(chmo.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
chmo.elevs <- chmo.qc %>% filter(!is.na(elevation)) # existing elev
chmo.noelev <- chmo.qc %>% filter(is.na(elevation)) # no original elevs
chmo.elevs$final_elev <- chmo.elevs$elevation # add final_elev, assign elevation values to it 
chmo.noelev$final_elev <- chmo.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
chmo.final <- rbind(chmo.elevs, chmo.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
chmo.final <- chmo.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
chmo.final <- chmo.final[order(-chmo.final$month, -chmo.final$final_elev), ] # sort by month
chmo.final <- chmo.final[which(!chmo.final$final_elev == "-32768"), ] # drop ocean points
write.csv(chmo.final, file = "chmo.final.csv")
save(chmo.final, file="chmo.final.RData") # save as Rdata object so you don't have to do it every time
chmo.final <- read.csv("chmo.final.csv", header= TRUE)
# load("chmo.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

chmo.final <- chmo.final[ , !(colnames(chmo.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(chmo.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
chmo.final <- chmo.final[!dup, ] # drop duplicate records
write.csv(chmo.final, file = "chmo.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(chmo.final$lon, chmo.final$lat, col='orange', pch=20, cex=0.75) # add points
points(chmo.final$lon, chmo.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=chmo.final, aes(x=month, y=final_elev, group=chmo.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="chmo")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
chmo.nona <- subset(chmo.final, select=oa) 
is.na(chmo.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
chmo.b <- chmo.nona[which(chmo.nona$month==6 | chmo.nona$month==7), ] # Breeding June-mid-July
chmo.nb <- chmo.nona[which(chmo.nona$month==12 | chmo.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=chmo.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: chmo")
p <- p + theme_classic()
print(p)

boxplot(chmo.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=chmo.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: chmo")
p <- p + theme_classic()
print(p)

boxplot(chmo.nb$final_elev, range=10, main="range=12") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
chmo.b.out <- FindOutliers(chmo.b, r=1.5); chmo.b.out # Detect outliers
# no outliers

chmo.nb.out <- FindOutliers(chmo.nb, r=10); chmo.nb.out # Detect outliers
chmo.nb <- chmo.nb[-chmo.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
chmo.b.elevs <- BreedingElevs(chmo.b)
chmo.nb.elevs <- NonbreedingElevs(chmo.nb)
chmo.elev.range <- cbind(chmo.nb.elevs, chmo.b.elevs); chmo.elev.range
chmo.elev.range["species"] <- "Charadrius_mongolus"
chmo.elev.range <- chmo.elev.range[, c(5,1,2,3,4)]; chmo.elev.range  # reorder columns 
write.csv(chmo.elev.range, file = "chmo.elev.range.csv")
``` 



# EURASIAN HOBBY
```{r}
# Import data
name_suggest(q="Falco subbuteo", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(fasu.dl <- occ_download("taxonKey=2481035", "hasCoordinate=TRUE", "country=IN", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(fasu.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
fasu <- occ_download_get("0018360-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

fasu.cit <- occ_download_get("0018360-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
fasu.cit$download # prints one-line output with DOI

write.csv(fasu, file = "fasu.csv")
fasu <- read.csv("fasu.csv", header= TRUE)
```

```{r}
# Clean data  
fasu.sub <- subset(fasu, select=sc) # subset data w/ criteria defined in sc
fasu.sub <- fasu.sub[which(fasu.sub$species == "Falco subbuteo"),] # verify only desired species
fasu.sub <- fasu.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
fasu.sub <- fasu.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
fasu.sub <- fasu.sub[which(!fasu.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
fasu.sub <- fasu.sub[which(!fasu.sub$decimalLongitude == "0"), ] # Drop lon values of 0
fasu.sub <- fasu.sub[which(!fasu.sub$month == "NA"), ] # Drop NA months
fasu.sub <- fasu.sub[which(!fasu.sub$countryCode == "NA"), ] # Drop NA countries
colnames(fasu.sub)[colnames(fasu.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
fasu.sub <- fasu.sub[order(-fasu.sub$coord_uncert), ] # sort by coordinate uncertainty
fasu.sub <- subset(fasu.sub, fasu.sub$coord_uncert < 3000 | is.na(fasu.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(fasu.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
fasu.sub <- fasu.sub[which(fasu.sub$countryCode == "IN"), ] 

# Fetch elevations with elevation() from rgbif
fasu.getelev <- elevation(fasu.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
fasu.qc <- fasu.getelev
fasu.qc$elev_diff <- (fasu.qc$elevation-fasu.qc$elevation_geonames) # Make elev_diff variable 
fasu.qc <- fasu.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
fasu.qc <- fasu.qc[order(-fasu.qc$elev_diff), ] # sort by elev_diff
fasu.qc <- subset(fasu.qc, fasu.qc$elev_diff < 300 | is.na(fasu.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
fasu.elevs <- fasu.qc %>% filter(!is.na(elevation)) # existing elev
fasu.noelev <- fasu.qc %>% filter(is.na(elevation)) # no original elevs
fasu.elevs$final_elev <- fasu.elevs$elevation # add final_elev, assign elevation values to it 
fasu.noelev$final_elev <- fasu.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
fasu.final <- rbind(fasu.elevs, fasu.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
fasu.final <- fasu.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
fasu.final <- fasu.final[order(-fasu.final$month, -fasu.final$final_elev), ] # sort by month
fasu.final <- fasu.final[which(!fasu.final$final_elev == "-32768"), ] # drop ocean points
write.csv(fasu.final, file = "fasu.final.csv")
save(fasu.final, file="fasu.final.RData") # save as Rdata object so you don't have to do it every time
fasu.final <- read.csv("fasu.final.csv", header= TRUE)
# load("fasu.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

fasu.final <- fasu.final[ , !(colnames(fasu.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(fasu.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
fasu.final <- fasu.final[!dup, ] # drop duplicate records
write.csv(fasu.final, file = "fasu.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(fasu.final$lon, fasu.final$lat, col='orange', pch=20, cex=0.75) # add points
points(fasu.final$lon, fasu.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=fasu.final, aes(x=month, y=final_elev, group=fasu.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="fasu")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
fasu.nona <- subset(fasu.final, select=oa) 
is.na(fasu.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
fasu.b <- fasu.nona[which(fasu.nona$month==6 | fasu.nona$month==7), ] # breeding May-July
fasu.nb <- fasu.nona[which(fasu.nona$month==12 | fasu.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=fasu.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: fasu")
p <- p + theme_classic()
print(p)

boxplot(fasu.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=fasu.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: fasu")
p <- p + theme_classic()
print(p)

boxplot(fasu.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
fasu.b.out <- FindOutliers(fasu.b, r=1.5); fasu.b.out # Detect outliers
fasu.b <- fasu.b[-fasu.b.out$rownum,] # remove the outliers 

fasu.nb.out <- FindOutliers(fasu.nb, r=1.5); fasu.nb.out # Detect outliers
fasu.nb <- fasu.nb[-fasu.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
fasu.b.elevs <- BreedingElevs(fasu.b)
fasu.nb.elevs <- NonbreedingElevs(fasu.nb)
fasu.elev.range <- cbind(fasu.nb.elevs, fasu.b.elevs); fasu.elev.range
fasu.elev.range["species"] <- "Falco_subbuteo"
fasu.elev.range <- fasu.elev.range[, c(5,1,2,3,4)]; fasu.elev.range  # reorder columns 
write.csv(fasu.elev.range, file = "fasu.elev.range.csv")
 
```



# DEMOISELLE CRANE
```{r}
# Import data
name_suggest(q="Anthropoides virgo", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(anvi.dl <- occ_download("taxonKey=2474936", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(anvi.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
anvi <- occ_download_get("0018366-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

anvi.cit <- occ_download_get("0018366-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
anvi.cit$download # prints one-line output with DOI

write.csv(anvi, file = "anvi.csv")
anvi <- read.csv("anvi.csv", header= TRUE)
```

```{r}
# Clean data  
anvi.sub <- subset(anvi, select=sc) # subset data w/ criteria defined in sc
anvi.sub <- anvi.sub[which(anvi.sub$species == "Anthropoides virgo"),] # verify only desired species
anvi.sub <- anvi.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
anvi.sub <- anvi.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
anvi.sub <- anvi.sub[which(!anvi.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
anvi.sub <- anvi.sub[which(!anvi.sub$decimalLongitude == "0"), ] # Drop lon values of 0
anvi.sub <- anvi.sub[which(!anvi.sub$month == "NA"), ] # Drop NA months
anvi.sub <- anvi.sub[which(!anvi.sub$countryCode == "NA"), ] # Drop NA countries
colnames(anvi.sub)[colnames(anvi.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
anvi.sub <- anvi.sub[order(-anvi.sub$coord_uncert), ] # sort by coordinate uncertainty
anvi.sub <- subset(anvi.sub, anvi.sub$coord_uncert < 3000 | is.na(anvi.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(anvi.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
anvi.sub <- subset(anvi.sub, subset = anvi.sub$countryCode %in% c("IN", "KZ", "MN", "CN", "RU"))

# Fetch elevations with elevation() from rgbif
anvi.getelev <- elevation(anvi.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
anvi.qc <- anvi.getelev
anvi.qc$elev_diff <- (anvi.qc$elevation-anvi.qc$elevation_geonames) # Make elev_diff variable 
anvi.qc <- anvi.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
anvi.qc <- anvi.qc[order(-anvi.qc$elev_diff), ] # sort by elev_diff
anvi.qc <- subset(anvi.qc, anvi.qc$elev_diff < 300 | is.na(anvi.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
anvi.elevs <- anvi.qc %>% filter(!is.na(elevation)) # existing elev
anvi.noelev <- anvi.qc %>% filter(is.na(elevation)) # no original elevs
anvi.elevs$final_elev <- anvi.elevs$elevation # add final_elev, assign elevation values to it 
anvi.noelev$final_elev <- anvi.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
anvi.final <- rbind(anvi.elevs, anvi.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
anvi.final <- anvi.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
anvi.final <- anvi.final[order(-anvi.final$month, -anvi.final$final_elev), ] # sort by month
anvi.final <- anvi.final[which(!anvi.final$final_elev == "-32768"), ] # drop ocean points
write.csv(anvi.final, file = "anvi.final.csv")
save(anvi.final, file="anvi.final.RData") # save as Rdata object so you don't have to do it every time
anvi.final <- read.csv("anvi.final.csv", header= TRUE)
# load("anvi.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

anvi.final <- anvi.final[ , !(colnames(anvi.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(anvi.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
anvi.final <- anvi.final[!dup, ] # drop duplicate records
write.csv(anvi.final, file = "anvi.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(40,125), ylim=c(5,60)) # Indian subcontinent
points(anvi.final$lon, anvi.final$lat, col='orange', pch=20, cex=0.75) # add points
points(anvi.final$lon, anvi.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=anvi.nonbreed, aes(x=month, y=final_elev, group=anvi.nonbreed$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="anvi")
p <- p + theme_classic()
print(p)

# subset by breeding and nonbreeding: 
anvi.breed <- subset(anvi.final, subset = anvi.final$countryCode %in% c("KZ", "MN", "CN", "RU"))
anvi.nonbreed <- subset(anvi.final, subset = anvi.final$countryCode %in% c("IN"))

# subset for outlier analysis, check for NAs
anvi.b.nona <- subset(anvi.breed, select=oa) 
anvi.nb.nona <- subset(anvi.nonbreed, select=oa) 

# subset by breeding and non-breeding season 
anvi.b <- anvi.b.nona[which(anvi.b.nona$month==6 | anvi.b.nona$month==7), ] # breeding April-May-June-July
anvi.nb <- anvi.nb.nona[which(anvi.nb.nona$month==12 | anvi.nb.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=anvi.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: anvi")
p <- p + theme_classic()
print(p)

boxplot(anvi.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=anvi.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: anvi")
p <- p + theme_classic()
print(p)

boxplot(anvi.nb$final_elev, range=2, main="range=2") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
anvi.b.out <- FindOutliers(anvi.b, r=1.5); anvi.b.out # Detect outliers
anvi.b <- anvi.b[-anvi.b.out$rownum,] # remove the outliers 

anvi.nb.out <- FindOutliers(anvi.nb, r=2); anvi.nb.out # Detect outliers
anvi.nb <- anvi.nb[-anvi.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
anvi.b.elevs <- BreedingElevs(anvi.b)
anvi.nb.elevs <- NonbreedingElevs(anvi.nb)
anvi.elev.range <- cbind(anvi.nb.elevs, anvi.b.elevs); anvi.elev.range
anvi.elev.range["species"] <- "Anthropoides_virgo"
anvi.elev.range <- anvi.elev.range[, c(5,1,2,3,4)]; anvi.elev.range  # reorder columns 
write.csv(anvi.elev.range, file = "anvi.elev.range.csv")
 
```


# ORIENTAL TURTLE DOVE
```{r}
# Import data
name_suggest(q="Streptopelia orientalis", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(stor.dl <- occ_download("taxonKey=2495681", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(stor.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
stor <- occ_download_get("0018368-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

stor.cit <- occ_download_get("0018368-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
stor.cit$download # prints one-line output with DOI

write.csv(stor, file = "stor.csv")
stor <- read.csv("stor.csv", header= TRUE)
```

```{r}
# Clean data  
stor.sub <- subset(stor, select=sc) # subset data w/ criteria defined in sc
stor.sub <- stor.sub[which(stor.sub$species == "Streptopelia orientalis"),] # verify only desired species
stor.sub <- stor.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
stor.sub <- stor.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
stor.sub <- stor.sub[which(!stor.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
stor.sub <- stor.sub[which(!stor.sub$decimalLongitude == "0"), ] # Drop lon values of 0
stor.sub <- stor.sub[which(!stor.sub$month == "NA"), ] # Drop NA months
stor.sub <- stor.sub[which(!stor.sub$countryCode == "NA"), ] # Drop NA countries
colnames(stor.sub)[colnames(stor.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
stor.sub <- stor.sub[order(-stor.sub$coord_uncert), ] # sort by coordinate uncertainty
stor.sub <- subset(stor.sub, stor.sub$coord_uncert < 3000 | is.na(stor.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(stor.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
stor.sub <- subset(stor.sub, subset = stor.sub$countryCode %in% c("IN", "NP", "PK"))

# Too large, so split into several:
stor.split <- split(stor.sub, (seq(nrow(stor.sub))-1) %/% 5000) # splits data into chunks of 9000 (10k too big)
# stor.split.unlist <- do.call(rbind.data.frame, stor.split) # unsplits and makes a data frame 

stor0 <- as.data.frame(stor.split$"0")
stor1 <- as.data.frame(stor.split$"1")
stor2 <- as.data.frame(stor.split$"2")

# Fetch elevations with elevation() from rgbif
stor.e0 <- elevation(stor0, elevation_model="srtm3", username="jwilliamson0110")
stor.e1 <- elevation(stor1, elevation_model="srtm3", username="jessiewgym")
stor.e2 <- elevation(stor2, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# rbind mini data frames together again
stor.all <- rbind(stor.e0, stor.e1, stor.e2) # good, same length as stor.sub

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
stor.qc <- stor.all
stor.qc$elev_diff <- (stor.qc$elevation-stor.qc$elevation_geonames) # Make elev_diff variable 
stor.qc <- stor.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
stor.qc <- stor.qc[order(-stor.qc$elev_diff), ] # sort by elev_diff
stor.qc <- subset(stor.qc, stor.qc$elev_diff < 300 | is.na(stor.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
stor.elevs <- stor.qc %>% filter(!is.na(elevation)) # existing elev
stor.noelev <- stor.qc %>% filter(is.na(elevation)) # no original elevs
stor.elevs$final_elev <- stor.elevs$elevation # add final_elev, assign elevation values to it 
stor.noelev$final_elev <- stor.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
stor.final <- rbind(stor.elevs, stor.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
stor.final <- stor.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
stor.final <- stor.final[order(-stor.final$month, -stor.final$final_elev), ] # sort by month
stor.final <- stor.final[which(!stor.final$final_elev == "-32768"), ] # drop ocean points
write.csv(stor.final, file = "stor.final.csv")
save(stor.final, file="stor.final.RData") # save as Rdata object so you don't have to do it every time
stor.final <- read.csv("stor.final.csv", header= TRUE)
# load("stor.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

stor.final <- stor.final[ , !(colnames(stor.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(stor.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
stor.final <- stor.final[!dup, ] # drop duplicate records
write.csv(stor.final, file = "stor.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # India, Nepal, Pakistan
points(stor.final$lon, stor.final$lat, col='orange', pch=20, cex=0.75) # add points
points(stor.final$lon, stor.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=stor.final, aes(x=month, y=final_elev, group=stor.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="stor")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
stor.nona <- subset(stor.final, select=oa) 
is.na(stor.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
stor.b <- stor.nona[which(stor.nona$month==5 | stor.nona$month==6), ] # breeding May-July
stor.nb <- stor.nona[which(stor.nona$month==11 | stor.nona$month==12), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=stor.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: stor")
p <- p + theme_classic()
print(p)

boxplot(stor.b$final_elev, range = 1.7, main="range = 1.7") # Breeding lumped; check outlier threshold 
# Awkward number, but I wanted to hit a natural-ish break in the distribution

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=stor.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: stor")
p <- p + theme_classic()
print(p)

boxplot(stor.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
stor.b.out <- FindOutliers(stor.b, r=1.7); stor.b.out # Detect outliers
stor.b <- stor.b[-stor.b.out$rownum,] # remove the outliers 

stor.nb.out <- FindOutliers(stor.nb, r=1.5); stor.nb.out # Detect outliers
stor.nb <- stor.nb[-stor.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
stor.b.elevs <- BreedingElevs(stor.b)
stor.nb.elevs <- NonbreedingElevs(stor.nb)
stor.elev.range <- cbind(stor.nb.elevs, stor.b.elevs); stor.elev.range
stor.elev.range["species"] <- "Streptopelia_orientalis"
stor.elev.range <- stor.elev.range[, c(5,1,2,3,4)]; stor.elev.range  # reorder columns 
write.csv(stor.elev.range, file = "stor.elev.range.csv")
 
```



# HIMALAYAN (ORIENTAL) CUCKOO
```{r}
# Import data
name_suggest(q="Cuculus saturatus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(cusa.dl <- occ_download("taxonKey=9548093", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(cusa.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
cusa <- occ_download_get("0018377-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

cusa.cit <- occ_download_get("0018377-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
cusa.cit$download # prints one-line output with DOI

write.csv(cusa, file = "cusa.csv")
cusa <- read.csv("cusa.csv", header= TRUE)
```

```{r}
# Clean data  
cusa.sub <- subset(cusa, select=sc) # subset data w/ criteria defined in sc
cusa.sub <- cusa.sub[which(cusa.sub$species == "Cuculus saturatus"),] # verify only desired species
cusa.sub <- cusa.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
cusa.sub <- cusa.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
cusa.sub <- cusa.sub[which(!cusa.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
cusa.sub <- cusa.sub[which(!cusa.sub$decimalLongitude == "0"), ] # Drop lon values of 0
cusa.sub <- cusa.sub[which(!cusa.sub$month == "NA"), ] # Drop NA months
cusa.sub <- cusa.sub[which(!cusa.sub$countryCode == "NA"), ] # Drop NA countries
colnames(cusa.sub)[colnames(cusa.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
cusa.sub <- cusa.sub[order(-cusa.sub$coord_uncert), ] # sort by coordinate uncertainty
cusa.sub <- subset(cusa.sub, cusa.sub$coord_uncert < 3000 | is.na(cusa.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(cusa.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
cusa.sub <- subset(cusa.sub, subset = cusa.sub$countryCode %in% c("IN"))
cusa.nonbreed <- subset(cusa.sub, subset = cusa.sub$countryCode %in% c("TH", "MY", "TW", "ID"))

# Fetch elevations with elevation() from rgbif
cusa.getelev <- elevation(cusa.sub, elevation_model="srtm3", username="jwilliamson")
cusa.nb.getelev <- elevation(cusa.nonbreed, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

cusa.all <- rbind(cusa.getelev, cusa.nb.getelev) 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
cusa.qc <- cusa.all
cusa.qc$elev_diff <- (cusa.qc$elevation-cusa.qc$elevation_geonames) # Make elev_diff variable 
cusa.qc <- cusa.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
cusa.qc <- cusa.qc[order(-cusa.qc$elev_diff), ] # sort by elev_diff
cusa.qc <- subset(cusa.qc, cusa.qc$elev_diff < 300 | is.na(cusa.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
cusa.elevs <- cusa.qc %>% filter(!is.na(elevation)) # existing elev
cusa.noelev <- cusa.qc %>% filter(is.na(elevation)) # no original elevs
cusa.elevs$final_elev <- cusa.elevs$elevation # add final_elev, assign elevation values to it 
cusa.noelev$final_elev <- cusa.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
cusa.final <- rbind(cusa.elevs, cusa.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
cusa.final <- cusa.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
cusa.final <- cusa.final[order(-cusa.final$month, -cusa.final$final_elev), ] # sort by month
cusa.final <- cusa.final[which(!cusa.final$final_elev == "-32768"), ] # drop ocean points
write.csv(cusa.final, file = "cusa.final.csv")
save(cusa.final, file="cusa.final.RData") # save as Rdata object so you don't have to do it every time
cusa.final <- read.csv("cusa.final.csv", header= TRUE)
# load("cusa.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

cusa.final <- cusa.final[ , !(colnames(cusa.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(cusa.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
cusa.final <- cusa.final[!dup, ] # drop duplicate records
write.csv(cusa.final, file = "cusa.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(70,140), ylim=c(-20,40)) # Indian subcontinent
points(cusa.final$lon, cusa.final$lat, col='orange', pch=20, cex=0.75) # add points
points(cusa.final$lon, cusa.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=cusa.breed, aes(x=month, y=final_elev, group=cusa.breed$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="cusa")
p <- p + theme_classic()
print(p)

cusa.breed <- subset(cusa.final, subset = cusa.final$countryCode %in% c("IN"))
cusa.nonbreed <- subset(cusa.final, subset = cusa.final$countryCode %in% c("TH", "MY", "TW", "ID"))

# subset for outlier analysis, check for NAs
cusa.b.nona <- subset(cusa.breed, select=oa) 
cusa.nb.nona <- subset(cusa.nonbreed, select=oa) 

# subset by breeding and non-breeding season 
cusa.b <- cusa.b.nona[which(cusa.b.nona$month==5 | cusa.b.nona$month==6), ] # Breeding May and June
  # Hmm...Bird goes WAY up in elevation from August to September, oddly, but that'd be late for breeding
cusa.nb <- cusa.nb.nona[which(cusa.nb.nona$month==10 | cusa.nb.nona$month==11 | cusa.nb.nona$month==12 | cusa.nb.nona$month==1), ] # nonbreeding
  # relatively few winter month records, so I'm gonna use 10,11, 12, 1

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=cusa.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: cusa")
p <- p + theme_classic()
print(p)

boxplot(cusa.b$final_elev, range = 2, main="range = 2") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=cusa.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: cusa")
p <- p + theme_classic()
print(p)

boxplot(cusa.nb$final_elev, range=2, main="range=2") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
cusa.b.out <- FindOutliers(cusa.b, r=2); cusa.b.out # Detect outliers
cusa.b <- cusa.b[-cusa.b.out$rownum,] # remove the outliers 

cusa.nb.out <- FindOutliers(cusa.nb, r=2); cusa.nb.out # Detect outliers
cusa.nb <- cusa.nb[-cusa.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
cusa.b.elevs <- BreedingElevs(cusa.b)
cusa.nb.elevs <- NonbreedingElevs(cusa.nb)
cusa.elev.range <- cbind(cusa.nb.elevs, cusa.b.elevs); cusa.elev.range
cusa.elev.range["species"] <- "Cuculus_saturatus"
cusa.elev.range <- cusa.elev.range[, c(5,1,2,3,4)]; cusa.elev.range  # reorder columns 
write.csv(cusa.elev.range, file = "cusa.elev.range.csv")
```


# EURASIAN WRYNECK
```{r}
# Import data
name_suggest(q="Jynx torquilla", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(jyto.dl <- occ_download("taxonKey=8012314", "hasCoordinate=TRUE", "country=IN", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(jyto.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
jyto <- occ_download_get("0018384-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

jyto.cit <- occ_download_get("0018384-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
jyto.cit$download # prints one-line output with DOI

write.csv(jyto, file = "jyto.csv")
jyto <- read.csv("jyto.csv", header= TRUE)
```

```{r}
# Clean data  
jyto.sub <- subset(jyto, select=sc) # subset data w/ criteria defined in sc
jyto.sub <- jyto.sub[which(jyto.sub$species == "Jynx torquilla"),] # verify only desired species
jyto.sub <- jyto.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
jyto.sub <- jyto.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
jyto.sub <- jyto.sub[which(!jyto.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
jyto.sub <- jyto.sub[which(!jyto.sub$decimalLongitude == "0"), ] # Drop lon values of 0
jyto.sub <- jyto.sub[which(!jyto.sub$month == "NA"), ] # Drop NA months
jyto.sub <- jyto.sub[which(!jyto.sub$countryCode == "NA"), ] # Drop NA countries
colnames(jyto.sub)[colnames(jyto.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
jyto.sub <- jyto.sub[order(-jyto.sub$coord_uncert), ] # sort by coordinate uncertainty
jyto.sub <- subset(jyto.sub, jyto.sub$coord_uncert < 3000 | is.na(jyto.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(jyto.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
jyto.sub <- subset(jyto.sub, subset = jyto.sub$countryCode %in% c("IN"))

# Fetch elevations with elevation() from rgbif
jyto.getelev <- elevation(jyto.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
jyto.qc <- jyto.getelev
jyto.qc$elev_diff <- (jyto.qc$elevation-jyto.qc$elevation_geonames) # Make elev_diff variable 
jyto.qc <- jyto.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
jyto.qc <- jyto.qc[order(-jyto.qc$elev_diff), ] # sort by elev_diff
jyto.qc <- subset(jyto.qc, jyto.qc$elev_diff < 300 | is.na(jyto.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
jyto.elevs <- jyto.qc %>% filter(!is.na(elevation)) # existing elev
jyto.noelev <- jyto.qc %>% filter(is.na(elevation)) # no original elevs
jyto.elevs$final_elev <- jyto.elevs$elevation # add final_elev, assign elevation values to it 
jyto.noelev$final_elev <- jyto.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
jyto.final <- rbind(jyto.elevs, jyto.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
jyto.final <- jyto.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
jyto.final <- jyto.final[order(-jyto.final$month, -jyto.final$final_elev), ] # sort by month
jyto.final <- jyto.final[which(!jyto.final$final_elev == "-32768"), ] # drop ocean points
write.csv(jyto.final, file = "jyto.final.csv")
save(jyto.final, file="jyto.final.RData") # save as Rdata object so you don't have to do it every time
jyto.final <- read.csv("jyto.final.csv", header= TRUE)
# load("jyto.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

jyto.final <- jyto.final[ , !(colnames(jyto.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(jyto.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
jyto.final <- jyto.final[!dup, ] # drop duplicate records
write.csv(jyto.final, file = "jyto.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(jyto.final$lon, jyto.final$lat, col='orange', pch=20, cex=0.75) # add points
points(jyto.final$lon, jyto.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=jyto.final, aes(x=month, y=final_elev, group=jyto.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="jyto")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
jyto.nona <- subset(jyto.final, select=oa) 
is.na(jyto.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
jyto.b <- jyto.nona[which(jyto.nona$month==5 | jyto.nona$month==6 | jyto.nona$month==7), ] # Breeding May-July
jyto.nb <- jyto.nona[which(jyto.nona$month==11 | jyto.nona$month==12 | jyto.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=jyto.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: jyto")
p <- p + theme_classic()
print(p)

boxplot(jyto.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=jyto.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: jyto")
p <- p + theme_classic()
print(p)

boxplot(jyto.nb$final_elev, range=3, main="range=3") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
jyto.b.out <- FindOutliers(jyto.b, r=1.5); jyto.b.out # Detect outliers
# no outliers

jyto.nb.out <- FindOutliers(jyto.nb, r=3); jyto.nb.out # Detect outliers
jyto.nb <- jyto.nb[-jyto.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
jyto.b.elevs <- BreedingElevs(jyto.b)
jyto.nb.elevs <- NonbreedingElevs(jyto.nb)
jyto.elev.range <- cbind(jyto.nb.elevs, jyto.b.elevs); jyto.elev.range
jyto.elev.range["species"] <- "Jynx torquilla"
jyto.elev.range <- jyto.elev.range[, c(5,1,2,3,4)]; jyto.elev.range  # reorder columns 
write.csv(jyto.elev.range, file = "jyto.elev.range.csv")
```



# GRAY-FLANKED CINCLODES
```{r}
# Import data
name_suggest(q="Cinclodes oustaleti", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
# (wtgr.dl <- occ_download("taxonKey=2485054", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(gfci.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
gfci <- occ_download_get("0003727-190813142620410", overwrite=TRUE) %>% occ_download_import() 

gfci.cit <- occ_download_get("0003727-190813142620410", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
gfci.cit$download # prints one-line output with DOI

write.csv(gfci, file = "gfci.csv")
gfci <- read.csv("gfci.csv", header= TRUE)
```

```{r}
# Clean data  
gfci.sub <- subset(gfci, select=sc) # subset data w/ criteria defined in sc
gfci.sub <- gfci.sub[which(gfci.sub$species == "Cinclodes oustaleti"),] # verify only desired species
gfci.sub <- gfci.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
gfci.sub <- gfci.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
gfci.sub <- gfci.sub[which(!gfci.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
gfci.sub <- gfci.sub[which(!gfci.sub$decimalLongitude == "0"), ] # Drop lon values of 0
gfci.sub <- gfci.sub[which(!gfci.sub$month == "NA"), ] # Drop NA months
gfci.sub <- gfci.sub[which(!gfci.sub$countryCode == "NA"), ] # Drop NA countries
colnames(gfci.sub)[colnames(gfci.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
gfci.sub <- gfci.sub[order(-gfci.sub$coord_uncert), ] # sort by coordinate uncertainty
gfci.sub <- subset(gfci.sub, gfci.sub$coord_uncert < 3000 | is.na(gfci.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert

# Species-specific region adjustments 
gfci.sub <- gfci.sub[which(gfci.sub$countryCode == "CL"), ] # Keep only Chile records 

# Fetch elevations with elevation() from rgbif
gfci.getelev <- elevation(gfci.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
gfci.qc <- gfci.getelev
gfci.qc$elev_diff <- (gfci.qc$elevation-gfci.qc$elevation_geonames) # Make elev_diff variable 
gfci.qc <- gfci.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
gfci.qc <- gfci.qc[order(-gfci.qc$elev_diff), ] # sort by elev_diff
gfci.qc <- subset(gfci.qc, gfci.qc$elev_diff < 300 | is.na(gfci.qc$elev_diff)) 
gfci.qc <- subset(gfci.qc, gfci.qc$elev_diff > -300 | is.na(gfci.qc$elev_diff))  # drop negative values
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
gfci.elevs <- gfci.qc %>% filter(!is.na(elevation)) # existing elev
gfci.noelev <- gfci.qc %>% filter(is.na(elevation)) # no original elevs
gfci.elevs$final_elev <- gfci.elevs$elevation # add final_elev, assign elevation values to it 
gfci.noelev$final_elev <- gfci.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
gfci.final <- rbind(gfci.elevs, gfci.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
gfci.final <- gfci.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
gfci.final <- gfci.final[order(-gfci.final$month, -gfci.final$final_elev), ] # sort by month
gfci.final <- gfci.final[which(!gfci.final$final_elev == "-32768"), ] # get rid of weird elevs
write.csv(gfci.final, file = "gfci.final.csv")
save(gfci.final, file="gfci.final.RData") # save as Rdata object so you don't have to do it every time
gfci.final <- read.csv("gfci.final.csv", header= TRUE)
# load("gfci.final.RData") # to load .RData file
```


```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

gfci.final <- gfci.final[ , !(colnames(gfci.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(gfci.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
gfci.final <- gfci.final[!dup, ] # drop duplicate records
write.csv(gfci.final, file = "gfci.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(-90,-60), ylim=c(-60,10)) # south America
points(gfci.final$lon, gfci.final$lat, col='orange', pch=20, cex=0.75) # add points
points(gfci.final$lon, gfci.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=gfci.final, aes(x=month, y=final_elev, group=gfci.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="gfci")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
gfci.nona <- subset(gfci.final, select=oa) 
is.na(gfci.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
gfci.b <- gfci.nona[which(gfci.nona$month==10 | gfci.nona$month==11 | gfci.nona$month==12), ] 
  # breeding Oct-Nov-DEc 
gfci.nb <- gfci.nona[which(gfci.nona$month==5 | gfci.nona$month==6 | gfci.nona$month==7), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=gfci.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: gfci")
p <- p + theme_classic()
print(p)

boxplot(gfci.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=gfci.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: gfci")
p <- p + theme_classic()
print(p)

boxplot(gfci.nb$final_elev, range=8, main="range=8") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
gfci.b.out <- FindOutliers(gfci.b, r=1.5); gfci.b.out # Detect outliers
#gfci.b <- gfci.b[-gfci.b.out$rownum,] # remove the outliers 

gfci.nb.out <- FindOutliers(gfci.nb, r=8); gfci.nb.out # Detect outliers
gfci.nb <- gfci.nb[-gfci.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
gfci.b.elevs <- BreedingElevs(gfci.b)
gfci.nb.elevs <- NonbreedingElevs(gfci.nb)
gfci.elev.range <- cbind(gfci.nb.elevs, gfci.b.elevs); gfci.elev.range
gfci.elev.range["species"] <- "Cinclodes_oustaleti"
gfci.elev.range <- gfci.elev.range[, c(5,1,2,3,4)]; gfci.elev.range  # reorder columns 
write.csv(gfci.elev.range, file = "gfci.elev.range.csv")
```



# HUME'S LARK
```{r}
# Import data
name_suggest(q="Calandrella acutirostris", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(caac.dl <- occ_download("taxonKey=5230986", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(caac.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
caac <- occ_download_get("0018943-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

caac.cit <- occ_download_get("0018943-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
caac.cit$download # prints one-line output with DOI

write.csv(caac, file = "caac.csv")
caac <- read.csv("caac.csv", header= TRUE)
```

```{r}
# Clean data  
caac.sub <- subset(caac, select=sc) # subset data w/ criteria defined in sc
caac.sub <- caac.sub[which(caac.sub$species == "Calandrella acutirostris"),] # verify only desired species
caac.sub <- caac.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
caac.sub <- caac.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
caac.sub <- caac.sub[which(!caac.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
caac.sub <- caac.sub[which(!caac.sub$decimalLongitude == "0"), ] # Drop lon values of 0
caac.sub <- caac.sub[which(!caac.sub$month == "NA"), ] # Drop NA months
caac.sub <- caac.sub[which(!caac.sub$countryCode == "NA"), ] # Drop NA countries
colnames(caac.sub)[colnames(caac.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
caac.sub <- caac.sub[order(-caac.sub$coord_uncert), ] # sort by coordinate uncertainty
caac.sub <- subset(caac.sub, caac.sub$coord_uncert < 3000 | is.na(caac.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(caac.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
caac.sub <- subset(caac.sub, subset = caac.sub$countryCode %in% c("IN", "NP", "PK"))

# Fetch elevations with elevation() from rgbif
caac.getelev <- elevation(caac.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
caac.qc <- caac.getelev
caac.qc$elev_diff <- (caac.qc$elevation-caac.qc$elevation_geonames) # Make elev_diff variable 
caac.qc <- caac.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
caac.qc <- caac.qc[order(-caac.qc$elev_diff), ] # sort by elev_diff
caac.qc <- subset(caac.qc, caac.qc$elev_diff < 300 | is.na(caac.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
caac.elevs <- caac.qc %>% filter(!is.na(elevation)) # existing elev
caac.noelev <- caac.qc %>% filter(is.na(elevation)) # no original elevs
caac.elevs$final_elev <- caac.elevs$elevation # add final_elev, assign elevation values to it 
caac.noelev$final_elev <- caac.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
caac.final <- rbind(caac.elevs, caac.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
caac.final <- caac.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
caac.final <- caac.final[order(-caac.final$month, -caac.final$final_elev), ] # sort by month
caac.final <- caac.final[which(!caac.final$final_elev == "-32768"), ] # drop ocean points
write.csv(caac.final, file = "caac.final.csv")
save(caac.final, file="caac.final.RData") # save as Rdata object so you don't have to do it every time
caac.final <- read.csv("caac.final.csv", header= TRUE)
# load("caac.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

caac.final <- caac.final[ , !(colnames(caac.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(caac.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
caac.final <- caac.final[!dup, ] # drop duplicate records
write.csv(caac.final, file = "caac.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(caac.final$lon, caac.final$lat, col='orange', pch=20, cex=0.75) # add points
points(caac.final$lon, caac.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

caac.in <- subset(caac.final, subset = caac.final$countryCode %in% c("IN"))

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=caac.final, aes(x=month, y=final_elev, group=caac.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="caac")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
caac.nona <- subset(caac.in, select=oa) 
is.na(caac.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
caac.b <- caac.nona[which(caac.nona$month==6 | caac.nona$month==7), ]
# HBW says: Season mainly MayAug, chiefly from Jun at higher altitudes; CHECK W/ GRIMMETT
# Grimmett says breeding May to August 
caac.nb <- caac.nona[which(caac.nona$month==12 | caac.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=caac.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: caac")
p <- p + theme_classic()
print(p)

boxplot(caac.b$final_elev, range = 1.5, main="range =1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=caac.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: caac")
p <- p + theme_classic()
print(p)

boxplot(caac.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
caac.b.out <- FindOutliers(caac.b, r=1.5); caac.b.out # Detect outliers
caac.b <- caac.b[-caac.b.out$rownum,] # remove the outliers 

caac.nb.out <- FindOutliers(caac.nb, r=1.5); caac.nb.out # Detect outliers
caac.nb <- caac.nb[-caac.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
caac.b.elevs <- BreedingElevs(caac.b)
caac.nb.elevs <- NonbreedingElevs(caac.nb)
caac.elev.range <- cbind(caac.nb.elevs, caac.b.elevs); caac.elev.range
caac.elev.range["species"] <- "Calandrella_acutirostris"
caac.elev.range <- caac.elev.range[, c(5,1,2,3,4)]; caac.elev.range  # reorder columns 
write.csv(caac.elev.range, file = "caac.elev.range.csv")
```



# MOUNTAIN CHIFFCHAFF
```{r}
# Import data
name_suggest(q="Phylloscopus sindianus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(phsi.dl <- occ_download("taxonKey=7341578", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(phsi.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
phsi <- occ_download_get("0018950-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

phsi.cit <- occ_download_get("0018950-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
phsi.cit$download # prints one-line output with DOI

write.csv(phsi, file = "phsi.csv")
phsi <- read.csv("phsi.csv", header= TRUE)
```

```{r}
# Clean data  
phsi.sub <- subset(phsi, select=sc) # subset data w/ criteria defined in sc
phsi.sub <- phsi.sub[which(phsi.sub$species == "Phylloscopus sindianus"),] # verify only desired species
phsi.sub <- phsi.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
phsi.sub <- phsi.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
phsi.sub <- phsi.sub[which(!phsi.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
phsi.sub <- phsi.sub[which(!phsi.sub$decimalLongitude == "0"), ] # Drop lon values of 0
phsi.sub <- phsi.sub[which(!phsi.sub$month == "NA"), ] # Drop NA months
phsi.sub <- phsi.sub[which(!phsi.sub$countryCode == "NA"), ] # Drop NA countries
colnames(phsi.sub)[colnames(phsi.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
phsi.sub <- phsi.sub[order(-phsi.sub$coord_uncert), ] # sort by coordinate uncertainty
phsi.sub <- subset(phsi.sub, phsi.sub$coord_uncert < 3000 | is.na(phsi.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(phsi.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
phsi.sub <- subset(phsi.sub, subset = phsi.sub$countryCode %in% c("IN"))

# Fetch elevations with elevation() from rgbif
phsi.getelev <- elevation(phsi.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
phsi.qc <- phsi.getelev
phsi.qc$elev_diff <- (phsi.qc$elevation-phsi.qc$elevation_geonames) # Make elev_diff variable 
phsi.qc <- phsi.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
phsi.qc <- phsi.qc[order(-phsi.qc$elev_diff), ] # sort by elev_diff
phsi.qc <- subset(phsi.qc, phsi.qc$elev_diff < 300 | is.na(phsi.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
phsi.elevs <- phsi.qc %>% filter(!is.na(elevation)) # existing elev
phsi.noelev <- phsi.qc %>% filter(is.na(elevation)) # no original elevs
phsi.elevs$final_elev <- phsi.elevs$elevation # add final_elev, assign elevation values to it 
phsi.noelev$final_elev <- phsi.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
phsi.final <- rbind(phsi.elevs, phsi.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
phsi.final <- phsi.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
phsi.final <- phsi.final[order(-phsi.final$month, -phsi.final$final_elev), ] # sort by month
phsi.final <- phsi.final[which(!phsi.final$final_elev == "-32768"), ] # drop ocean points
write.csv(phsi.final, file = "phsi.final.csv")
save(phsi.final, file="phsi.final.RData") # save as Rdata object so you don't have to do it every time
phsi.final <- read.csv("phsi.final.csv", header= TRUE)
# load("phsi.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

phsi.final <- phsi.final[ , !(colnames(phsi.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(phsi.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
phsi.final <- phsi.final[!dup, ] # drop duplicate records
write.csv(phsi.final, file = "phsi.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(phsi.final$lon, phsi.final$lat, col='orange', pch=20, cex=0.75) # add points
points(phsi.final$lon, phsi.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=phsi.final, aes(x=month, y=final_elev, group=phsi.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="phsi")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
phsi.nona <- subset(phsi.final, select=oa) 
is.na(phsi.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
phsi.b <- phsi.nona[which(phsi.nona$month==5 | phsi.nona$month==6 | phsi.nona$month==7), ] 
  # HBW says May to early August
  # Grimmett says May-July
phsi.nb <- phsi.nona[which(phsi.nona$month==1 | phsi.nona$month==2), ]
  # Only real nonbreeding data available??

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phsi.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: phsi")
p <- p + theme_classic()
print(p)

boxplot(phsi.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phsi.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: phsi")
p <- p + theme_classic()
print(p)

boxplot(phsi.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
phsi.b.out <- FindOutliers(phsi.b, r=1.5); phsi.b.out # Detect outliers
phsi.b <- phsi.b[-phsi.b.out$rownum,] # remove the outliers 

phsi.nb.out <- FindOutliers(phsi.nb, r=1.5); phsi.nb.out # Detect outliers
# no outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
phsi.b.elevs <- BreedingElevs(phsi.b)
phsi.nb.elevs <- NonbreedingElevs(phsi.nb)
phsi.elev.range <- cbind(phsi.nb.elevs, phsi.b.elevs); phsi.elev.range
phsi.elev.range["species"] <- "Phylloscopus_sindianus"
phsi.elev.range <- phsi.elev.range[, c(5,1,2,3,4)]; phsi.elev.range  # reorder columns 
write.csv(phsi.elev.range, file = "phsi.elev.range.csv")
```



# LEMON-RUMPED LEAF-WARBLER
```{r}
# Import data
name_suggest(q="Phylloscopus chloronotus", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(phch.dl <- occ_download("taxonKey=2493059", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(phch.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
phch <- occ_download_get("0018956-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

phch.cit <- occ_download_get("0018956-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
phch.cit$download # prints one-line output with DOI

write.csv(phch, file = "phch.csv")
phch <- read.csv("phch.csv", header= TRUE)
```

```{r}
# Clean data  
phch.sub <- subset(phch, select=sc) # subset data w/ criteria defined in sc
phch.sub <- phch.sub[which(phch.sub$species == "Phylloscopus chloronotus"),] # verify only desired species
phch.sub <- phch.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
phch.sub <- phch.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
phch.sub <- phch.sub[which(!phch.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
phch.sub <- phch.sub[which(!phch.sub$decimalLongitude == "0"), ] # Drop lon values of 0
phch.sub <- phch.sub[which(!phch.sub$month == "NA"), ] # Drop NA months
phch.sub <- phch.sub[which(!phch.sub$countryCode == "NA"), ] # Drop NA countries
colnames(phch.sub)[colnames(phch.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
phch.sub <- phch.sub[order(-phch.sub$coord_uncert), ] # sort by coordinate uncertainty
phch.sub <- subset(phch.sub, phch.sub$coord_uncert < 3000 | is.na(phch.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(phch.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
phch.sub <- subset(phch.sub, subset = phch.sub$countryCode %in% c("IN", "NP", "PK"))

# Fetch elevations with elevation() from rgbif
phch.getelev <- elevation(phch.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
phch.qc <- phch.getelev
phch.qc$elev_diff <- (phch.qc$elevation-phch.qc$elevation_geonames) # Make elev_diff variable 
phch.qc <- phch.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
phch.qc <- phch.qc[order(-phch.qc$elev_diff), ] # sort by elev_diff
phch.qc <- subset(phch.qc, phch.qc$elev_diff < 300 | is.na(phch.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
phch.elevs <- phch.qc %>% filter(!is.na(elevation)) # existing elev
phch.noelev <- phch.qc %>% filter(is.na(elevation)) # no original elevs
phch.elevs$final_elev <- phch.elevs$elevation # add final_elev, assign elevation values to it 
phch.noelev$final_elev <- phch.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
phch.final <- rbind(phch.elevs, phch.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
phch.final <- phch.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
phch.final <- phch.final[order(-phch.final$month, -phch.final$final_elev), ] # sort by month
phch.final <- phch.final[which(!phch.final$final_elev == "-32768"), ] # drop ocean points
write.csv(phch.final, file = "phch.final.csv")
save(phch.final, file="phch.final.RData") # save as Rdata object so you don't have to do it every time
phch.final <- read.csv("phch.final.csv", header= TRUE)
# load("phch.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

phch.final <- phch.final[ , !(colnames(phch.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(phch.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
phch.final <- phch.final[!dup, ] # drop duplicate records
write.csv(phch.final, file = "phch.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(phch.final$lon, phch.final$lat, col='orange', pch=20, cex=0.75) # add points
points(phch.final$lon, phch.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# india only
phch.in <- subset(phch.final, subset = phch.final$countryCode %in% c("IN"))

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=phch.in, aes(x=month, y=final_elev, group=phch.in$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="phch")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
phch.nona <- subset(phch.in, select=oa) 
is.na(phch.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
phch.b <- phch.nona[which(phch.nona$month==6 | phch.nona$month==7), ] 
  # Breeding AprJul, main season late MayJun
  # Grimmett says April through July
phch.nb <- phch.nona[which(phch.nona$month==12 | phch.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phch.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: phch")
p <- p + theme_classic()
print(p)

boxplot(phch.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phch.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: phch")
p <- p + theme_classic()
print(p)

boxplot(phch.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
phch.b.out <- FindOutliers(phch.b, r=1.5); phch.b.out # Detect outliers
phch.b <- phch.b[-phch.b.out$rownum,] # remove the outliers 

phch.nb.out <- FindOutliers(phch.nb, r=1.5); phch.nb.out # Detect outliers
# no outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
phch.b.elevs <- BreedingElevs(phch.b)
phch.nb.elevs <- NonbreedingElevs(phch.nb)
phch.elev.range <- cbind(phch.nb.elevs, phch.b.elevs); phch.elev.range
phch.elev.range["species"] <- "Phylloscopus_chloronotus"
phch.elev.range <- phch.elev.range[, c(5,1,2,3,4)]; phch.elev.range  # reorder columns 
write.csv(phch.elev.range, file = "phch.elev.range.csv")
```



# HUME'S LEAF-WARBLER
```{r}
# Import data
name_suggest(q="Phylloscopus humei", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(phhu.dl <- occ_download("taxonKey=7341522", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(phhu.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
phhu <- occ_download_get("0019069-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

phhu.cit <- occ_download_get("0019069-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
phhu.cit$download # prints one-line output with DOI

write.csv(phhu, file = "phhu.csv")
phhu <- read.csv("phhu.csv", header= TRUE)
```

```{r}
# Clean data  
phhu.sub <- subset(phhu, select=sc) # subset data w/ criteria defined in sc
phhu.sub <- phhu.sub[which(phhu.sub$species == "Phylloscopus humei"),] # verify only desired species
phhu.sub <- phhu.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
phhu.sub <- phhu.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
phhu.sub <- phhu.sub[which(!phhu.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
phhu.sub <- phhu.sub[which(!phhu.sub$decimalLongitude == "0"), ] # Drop lon values of 0
phhu.sub <- phhu.sub[which(!phhu.sub$month == "NA"), ] # Drop NA months
phhu.sub <- phhu.sub[which(!phhu.sub$countryCode == "NA"), ] # Drop NA countries
colnames(phhu.sub)[colnames(phhu.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
phhu.sub <- phhu.sub[order(-phhu.sub$coord_uncert), ] # sort by coordinate uncertainty
phhu.sub <- subset(phhu.sub, phhu.sub$coord_uncert < 3000 | is.na(phhu.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(phhu.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
phhu.sub <- subset(phhu.sub, subset = phhu.sub$countryCode %in% c("IN", "NP"))

phhu.split <- split(phhu.sub, (seq(nrow(phhu.sub))-1) %/% 5050) # splits data into chunks of 9000 (10k too big)
# phhu.split.unlist <- do.call(rbind.data.frame, phhu.split) # unsplits and makes a data frame 

phhu0 <- as.data.frame(phhu.split$"0")
phhu1 <- as.data.frame(phhu.split$"1")
phhu2 <- as.data.frame(phhu.split$"2")

# Fetch elevations with elevation() from rgbif
phhu.e0 <- elevation(phhu0, elevation_model="srtm3", username="jwilliamson0110")
phhu.e1 <- elevation(phhu1, elevation_model="srtm3", username="jessiewgym")
phhu.e2 <- elevation(phhu2, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# rbind mini data frames together again
phhu.all <- rbind(phhu.e0, phhu.e1, phhu.e2) # good, same length as phhu.sub

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
phhu.qc <- phhu.all
phhu.qc$elev_diff <- (phhu.qc$elevation-phhu.qc$elevation_geonames) # Make elev_diff variable 
phhu.qc <- phhu.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
phhu.qc <- phhu.qc[order(-phhu.qc$elev_diff), ] # sort by elev_diff
phhu.qc <- subset(phhu.qc, phhu.qc$elev_diff < 300 | is.na(phhu.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
phhu.elevs <- phhu.qc %>% filter(!is.na(elevation)) # existing elev
phhu.noelev <- phhu.qc %>% filter(is.na(elevation)) # no original elevs
phhu.elevs$final_elev <- phhu.elevs$elevation # add final_elev, assign elevation values to it 
phhu.noelev$final_elev <- phhu.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
phhu.final <- rbind(phhu.elevs, phhu.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
phhu.final <- phhu.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
phhu.final <- phhu.final[order(-phhu.final$month, -phhu.final$final_elev), ] # sort by month
phhu.final <- phhu.final[which(!phhu.final$final_elev == "-32768"), ] # drop ocean points
write.csv(phhu.final, file = "phhu.final.csv")
save(phhu.final, file="phhu.final.RData") # save as Rdata object so you don't have to do it every time
phhu.final <- read.csv("phhu.final.csv", header= TRUE)
# load("phhu.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE - FOR INDIA

phhu.final <- phhu.final[ , !(colnames(phhu.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(phhu.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
phhu.final <- phhu.final[!dup, ] # drop duplicate records
write.csv(phhu.final, file = "phhu.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(phhu.final$lon, phhu.final$lat, col='orange', pch=20, cex=0.75) # add points
points(phhu.final$lon, phhu.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# split by country: 
phhu.in <- subset(phhu.final, subset = phhu.final$countryCode %in% c("IN"))

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=phhu.in, aes(x=month, y=final_elev, group=phhu.in$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="phhu")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
phhu.nona <- subset(phhu.in, select=oa) 
is.na(phhu.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
phhu.b <- phhu.nona[which(phhu.nona$month==6 | phhu.nona$month==7), ] # Breeding April-July
phhu.nb <- phhu.nona[which(phhu.nona$month==12 | phhu.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phhu.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: phhu")
p <- p + theme_classic()
print(p)

boxplot(phhu.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phhu.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: phhu")
p <- p + theme_classic()
print(p)

boxplot(phhu.nb$final_elev, range=3, main="range=3") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
phhu.b.out <- FindOutliers(phhu.b, r=1.5); phhu.b.out # Detect outliers
phhu.b <- subset(phhu.b, phhu.b$final_elev < 4605)
# manually removing outlier 5100 m point since it doesn't come up w/ outlier check

phhu.nb.out <- FindOutliers(phhu.nb, r=3); phhu.nb.out # Detect outliers
phhu.nb <- phhu.nb[-phhu.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
phhu.b.elevs <- BreedingElevs(phhu.b)
phhu.nb.elevs <- NonbreedingElevs(phhu.nb)
phhu.elev.range <- cbind(phhu.nb.elevs, phhu.b.elevs); phhu.elev.range
phhu.elev.range["species"] <- "Phylloscopus_humei_India"
phhu.elev.range <- phhu.elev.range[, c(5,1,2,3,4)]; phhu.elev.range  # reorder columns 
write.csv(phhu.elev.range, file = "phhu.elev.range.csv")
```


This is still phhu, but for Nepal: 
```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE - FOR NEPAL

# split by country: 
phhu.np <- subset(phhu.final, subset = phhu.final$countryCode %in% c("NP"))

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=phhu.np, aes(x=month, y=final_elev, group=phhu.np$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="phhu")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
phhu.np.nona <- subset(phhu.np, select=oa) 
is.na(phhu.np.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
phhu.np.b <- phhu.np.nona[which(phhu.np.nona$month==6 | phhu.np.nona$month==7), ] # Breeding April-July
phhu.np.nb <- phhu.np.nona[which(phhu.np.nona$month==12 | phhu.np.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phhu.np.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: phhu.np")
p <- p + theme_classic()
print(p)

boxplot(phhu.np.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phhu.np.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: phhu.np")
p <- p + theme_classic()
print(p)

boxplot(phhu.np.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
phhu.np.b.out <- FindOutliers(phhu.np.b, r=1.5); phhu.np.b.out # Detect outliers
phhu.np.b <- phhu.np.b[-phhu.np.b.out$rownum,] # remove the outliers 

phhu.np.nb.out <- FindOutliers(phhu.np.nb, r=1.5); phhu.np.nb.out # Detect outliers
phhu.np.nb <- phhu.np.nb[-phhu.np.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
phhu.np.b.elevs <- BreedingElevs(phhu.np.b)
phhu.np.nb.elevs <- NonbreedingElevs(phhu.np.nb)
phhu.np.elev.range <- cbind(phhu.np.nb.elevs, phhu.np.b.elevs); phhu.np.elev.range
phhu.np.elev.range["species"] <- "Phylloscopus_humei_Nepal"
phhu.np.elev.range <- phhu.np.elev.range[, c(5,1,2,3,4)]; phhu.np.elev.range  # reorder columns 
write.csv(phhu.np.elev.range, file = "phhu.np.elev.range.csv")
```



# GREENISH WARBLER
```{r}
# Import data
name_suggest(q="Phylloscopus trochiloides", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(phtr.dl <- occ_download("taxonKey=2493084", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(phtr.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
phtr <- occ_download_get("0019339-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

phtr.cit <- occ_download_get("0019339-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
phtr.cit$download # prints one-line output with DOI

write.csv(phtr, file = "phtr.csv")
phtr <- read.csv("phtr.csv", header= TRUE)
```

```{r}
# Clean data  
phtr.sub <- subset(phtr, select=sc) # subset data w/ criteria defined in sc
phtr.sub <- phtr.sub[which(phtr.sub$species == "Phylloscopus trochiloides"),] # verify only desired species
phtr.sub <- phtr.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
phtr.sub <- phtr.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
phtr.sub <- phtr.sub[which(!phtr.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
phtr.sub <- phtr.sub[which(!phtr.sub$decimalLongitude == "0"), ] # Drop lon values of 0
phtr.sub <- phtr.sub[which(!phtr.sub$month == "NA"), ] # Drop NA months
phtr.sub <- phtr.sub[which(!phtr.sub$countryCode == "NA"), ] # Drop NA countries
colnames(phtr.sub)[colnames(phtr.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
phtr.sub <- phtr.sub[order(-phtr.sub$coord_uncert), ] # sort by coordinate uncertainty
phtr.sub <- subset(phtr.sub, phtr.sub$coord_uncert < 3000 | is.na(phtr.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(phtr.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
phtr.sub <- subset(phtr.sub, subset = phtr.sub$countryCode %in% c("IN", "NP"))

phtr.split <- split(phtr.sub, (seq(nrow(phtr.sub))-1) %/% 5000) # splits data into chunks of 9000 (10k too big)
# phtr.split.unlist <- do.call(rbind.data.frame, phtr.split) # unsplits and makes a data frame 

phtr0 <- as.data.frame(phtr.split$"0")
phtr1 <- as.data.frame(phtr.split$"1")
phtr2 <- as.data.frame(phtr.split$"2")
phtr3 <- as.data.frame(phtr.split$"3")
phtr4 <- as.data.frame(phtr.split$"4")
phtr5 <- as.data.frame(phtr.split$"5")
phtr6 <- as.data.frame(phtr.split$"6")
phtr7 <- as.data.frame(phtr.split$"7")

# Fetch elevations with elevation() from rgbif
phtr.e0 <- elevation(phtr0, elevation_model="srtm3", username="jwilliamson0110")
phtr.e1 <- elevation(phtr1, elevation_model="srtm3", username="jessiewgym")
phtr.e2 <- elevation(phtr2, elevation_model="srtm3", username="jwilliamson")
phtr.e3 <- elevation(phtr3, elevation_model="srtm3", username="willford1")
phtr.e4 <- elevation(phtr4, elevation_model="srtm3", username="selina1") 
phtr.e5 <- elevation(phtr5, elevation_model="srtm3", username="jessiefulbright") 
phtr.e6 <- elevation(phtr6, elevation_model="srtm3", username="selina2")
phtr.e7 <- elevation(phtr7, elevation_model="srtm3", username="cgadekunm") 
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# rbind mini data frames together again
phtr.all <- rbind(phtr.e0, phtr.e1, phtr.e2, phtr.e3, phtr.e4, phtr.e5, phtr.e6, phtr.e7) # good, same length as phtr.sub

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
phtr.qc <- phtr.all
phtr.qc$elev_diff <- (phtr.qc$elevation-phtr.qc$elevation_geonames) # Make elev_diff variable 
phtr.qc <- phtr.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
phtr.qc <- phtr.qc[order(-phtr.qc$elev_diff), ] # sort by elev_diff
phtr.qc <- subset(phtr.qc, phtr.qc$elev_diff < 300 | is.na(phtr.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
phtr.elevs <- phtr.qc %>% filter(!is.na(elevation)) # existing elev
phtr.noelev <- phtr.qc %>% filter(is.na(elevation)) # no original elevs
phtr.elevs$final_elev <- phtr.elevs$elevation # add final_elev, assign elevation values to it 
phtr.noelev$final_elev <- phtr.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
phtr.final <- rbind(phtr.elevs, phtr.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
phtr.final <- phtr.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
phtr.final <- phtr.final[order(-phtr.final$month, -phtr.final$final_elev), ] # sort by month
phtr.final <- phtr.final[which(!phtr.final$final_elev == "-32768"), ] # drop ocean points
write.csv(phtr.final, file = "phtr.final.csv")
save(phtr.final, file="phtr.final.RData") # save as Rdata object so you don't have to do it every time
phtr.final <- read.csv("phtr.final.csv", header= TRUE)
# load("phtr.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE  - FOR INDIA 

phtr.final <- phtr.final[ , !(colnames(phtr.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(phtr.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
phtr.final <- phtr.final[!dup, ] # drop duplicate records
write.csv(phtr.final, file = "phtr.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(phtr.final$lon, phtr.final$lat, col='orange', pch=20, cex=0.75) # add points
points(phtr.final$lon, phtr.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

phtr.in <- subset(phtr.final, subset = phtr.final$countryCode %in% c("IN"))

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=phtr.final, aes(x=month, y=final_elev, group=phtr.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="phtr")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
phtr.nona <- subset(phtr.final, select=oa) 
is.na(phtr.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
phtr.b <- phtr.nona[which(phtr.nona$month==6 | phtr.nona$month==7), ] # breeding May-mid Aug
phtr.nb <- phtr.nona[which(phtr.nona$month==12 | phtr.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phtr.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: phtr")
p <- p + theme_classic()
print(p)

boxplot(phtr.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phtr.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: phtr")
p <- p + theme_classic()
print(p)

boxplot(phtr.nb$final_elev, range=3, main="range=3") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
phtr.b.out <- FindOutliers(phtr.b, r=1.5); phtr.b.out # Detect outliers
phtr.b <- phtr.b[-phtr.b.out$rownum,] # remove the outliers 

phtr.nb.out <- FindOutliers(phtr.nb, r=3); phtr.nb.out # Detect outliers
phtr.nb <- phtr.nb[-phtr.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
phtr.b.elevs <- BreedingElevs(phtr.b)
phtr.nb.elevs <- NonbreedingElevs(phtr.nb)
phtr.elev.range <- cbind(phtr.nb.elevs, phtr.b.elevs); phtr.elev.range
phtr.elev.range["species"] <- "Phylloscopus_trochiloides_India"
phtr.elev.range <- phtr.elev.range[, c(5,1,2,3,4)]; phtr.elev.range  # reorder columns 
write.csv(phtr.elev.range, file = "phtr.elev.range.csv")
```

Still Greenish Warbler, but for Nepal: 
```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE  - FOR NEPAL 

phtr.np <- subset(phtr.final, subset = phtr.final$countryCode %in% c("NP"))

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=phtr.np, aes(x=month, y=final_elev, group=phtr.np$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="phtr")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
phtr.np.nona <- subset(phtr.np, select=oa) 
is.na(phtr.np.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
phtr.np.b <- phtr.np.nona[which(phtr.np.nona$month==6 | phtr.np.nona$month==7), ] # breeding May-mid Aug
phtr.np.nb <- phtr.np.nona[which(phtr.np.nona$month==12 | phtr.np.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phtr.np.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: phtr")
p <- p + theme_classic()
print(p)

boxplot(phtr.np.b$final_elev, range = 1, main="range = 1") # Breeding lumped; check outlier threshold 
# Making this more conservative becuase ~150 m point stands out from the rest as likely outlier

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phtr.np.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: phtr")
p <- p + theme_classic()
print(p)

boxplot(phtr.np.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
phtr.np.b.out <- FindOutliers(phtr.np.b, r=1.0); phtr.np.b.out # Detect outliers
phtr.np.b <- phtr.np.b[-phtr.np.b.out$rownum,] # remove the outliers 

phtr.np.nb.out <- FindOutliers(phtr.np.nb, r=1.5); phtr.np.nb.out # Detect outliers
phtr.np.nb <- phtr.np.nb[-phtr.np.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
phtr.np.b.elevs <- BreedingElevs(phtr.np.b)
phtr.np.nb.elevs <- NonbreedingElevs(phtr.np.nb)
phtr.np.elev.range <- cbind(phtr.np.nb.elevs, phtr.np.b.elevs); phtr.np.elev.range
phtr.np.elev.range["species"] <- "Phylloscopus_trochiloides_India"
phtr.np.elev.range <- phtr.np.elev.range[, c(5,1,2,3,4)]; phtr.np.elev.range  # reorder columns 
write.csv(phtr.np.elev.range, file = "phtr.np.elev.range.csv")
```



# TYTLER'S LEAF WARBLER
```{r}
# Import data
name_suggest(q="Phylloscopus tytleri", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(phty.dl <- occ_download("taxonKey=2493067", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(phty.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
phty <- occ_download_get("0021052-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

phty.cit <- occ_download_get("0021052-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
phty.cit$download # prints one-line output with DOI

write.csv(phty, file = "phty.csv")
phty <- read.csv("phty.csv", header= TRUE)
```

```{r}
# Clean data  
phty.sub <- subset(phty, select=sc) # subset data w/ criteria defined in sc
phty.sub <- phty.sub[which(phty.sub$species == "Phylloscopus tytleri"),] # verify only desired species
phty.sub <- phty.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
phty.sub <- phty.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
phty.sub <- phty.sub[which(!phty.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
phty.sub <- phty.sub[which(!phty.sub$decimalLongitude == "0"), ] # Drop lon values of 0
phty.sub <- phty.sub[which(!phty.sub$month == "NA"), ] # Drop NA months
phty.sub <- phty.sub[which(!phty.sub$countryCode == "NA"), ] # Drop NA countries
colnames(phty.sub)[colnames(phty.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
phty.sub <- phty.sub[order(-phty.sub$coord_uncert), ] # sort by coordinate uncertainty
phty.sub <- subset(phty.sub, phty.sub$coord_uncert < 3000 | is.na(phty.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(phty.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
phty.sub <- subset(phty.sub, subset = phty.sub$countryCode %in% c("IN"))

# Fetch elevations with elevation() from rgbif
phty.getelev <- elevation(phty.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
phty.qc <- phty.getelev
phty.qc$elev_diff <- (phty.qc$elevation-phty.qc$elevation_geonames) # Make elev_diff variable 
phty.qc <- phty.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
phty.qc <- phty.qc[order(-phty.qc$elev_diff), ] # sort by elev_diff
phty.qc <- subset(phty.qc, phty.qc$elev_diff < 300 | is.na(phty.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
phty.elevs <- phty.qc %>% filter(!is.na(elevation)) # existing elev
phty.noelev <- phty.qc %>% filter(is.na(elevation)) # no original elevs
phty.elevs$final_elev <- phty.elevs$elevation # add final_elev, assign elevation values to it 
phty.noelev$final_elev <- phty.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
phty.final <- rbind(phty.elevs, phty.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
phty.final <- phty.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
phty.final <- phty.final[order(-phty.final$month, -phty.final$final_elev), ] # sort by month
phty.final <- phty.final[which(!phty.final$final_elev == "-32768"), ] # drop ocean points
write.csv(phty.final, file = "phty.final.csv")
save(phty.final, file="phty.final.RData") # save as Rdata object so you don't have to do it every time
phty.final <- read.csv("phty.final.csv", header= TRUE)
# load("phty.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

phty.final <- phty.final[ , !(colnames(phty.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(phty.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
phty.final <- phty.final[!dup, ] # drop duplicate records
write.csv(phty.final, file = "phty.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(phty.final$lon, phty.final$lat, col='orange', pch=20, cex=0.75) # add points
points(phty.final$lon, phty.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=phty.final, aes(x=month, y=final_elev, group=phty.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="phty")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
phty.nona <- subset(phty.final, select=oa) 
is.na(phty.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
phty.b <- phty.nona[which(phty.nona$month==6 | phty.nona$month==7), ] # Breeding May-July
phty.nb <- phty.nona[which(phty.nona$month==12 | phty.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phty.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: phty")
p <- p + theme_classic()
print(p)

boxplot(phty.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=phty.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: phty")
p <- p + theme_classic()
print(p)

boxplot(phty.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
phty.b.out <- FindOutliers(phty.b, r=1.5); phty.b.out # Detect outliers
phty.b <- phty.b[-phty.b.out$rownum,] # remove the outliers 

phty.nb.out <- FindOutliers(phty.nb, r=1.5); phty.nb.out # Detect outliers
#phty.nb <- phty.nb[-phty.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
phty.b.elevs <- BreedingElevs(phty.b)
phty.nb.elevs <- NonbreedingElevs(phty.nb)
phty.elev.range <- cbind(phty.nb.elevs, phty.b.elevs); phty.elev.range
phty.elev.range["species"] <- "Phylloscopus_tytleri"
phty.elev.range <- phty.elev.range[, c(5,1,2,3,4)]; phty.elev.range  # reorder columns 
write.csv(phty.elev.range, file = "phty.elev.range.csv")
```



# HUME'S WHITETHROAT
```{r}
# Import data
name_suggest(q="Sylvia althaea", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(syal.dl <- occ_download("taxonKey=9612559", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(syal.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
syal <- occ_download_get("0021063-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

syal.cit <- occ_download_get("0021063-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
syal.cit$download # prints one-line output with DOI

write.csv(syal, file = "syal.csv")
syal <- read.csv("syal.csv", header= TRUE)
```

```{r}
# Clean data  
syal.sub <- subset(syal, select=sc) # subset data w/ criteria defined in sc
syal.sub <- syal.sub[which(syal.sub$species == "Sylvia althaea"),] # verify only desired species
syal.sub <- syal.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
syal.sub <- syal.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
syal.sub <- syal.sub[which(!syal.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
syal.sub <- syal.sub[which(!syal.sub$decimalLongitude == "0"), ] # Drop lon values of 0
syal.sub <- syal.sub[which(!syal.sub$month == "NA"), ] # Drop NA months
syal.sub <- syal.sub[which(!syal.sub$countryCode == "NA"), ] # Drop NA countries
colnames(syal.sub)[colnames(syal.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
syal.sub <- syal.sub[order(-syal.sub$coord_uncert), ] # sort by coordinate uncertainty
syal.sub <- subset(syal.sub, syal.sub$coord_uncert < 3000 | is.na(syal.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(syal.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
syal.sub <- subset(syal.sub, subset = syal.sub$countryCode %in% c("IN"))

# Fetch elevations with elevation() from rgbif
syal.getelev <- elevation(syal.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
syal.qc <- syal.getelev
syal.qc$elev_diff <- (syal.qc$elevation-syal.qc$elevation_geonames) # Make elev_diff variable 
syal.qc <- syal.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
syal.qc <- syal.qc[order(-syal.qc$elev_diff), ] # sort by elev_diff
syal.qc <- subset(syal.qc, syal.qc$elev_diff < 300 | is.na(syal.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
syal.elevs <- syal.qc %>% filter(!is.na(elevation)) # existing elev
syal.noelev <- syal.qc %>% filter(is.na(elevation)) # no original elevs
syal.elevs$final_elev <- syal.elevs$elevation # add final_elev, assign elevation values to it 
syal.noelev$final_elev <- syal.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
syal.final <- rbind(syal.elevs, syal.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
syal.final <- syal.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
syal.final <- syal.final[order(-syal.final$month, -syal.final$final_elev), ] # sort by month
syal.final <- syal.final[which(!syal.final$final_elev == "-32768"), ] # drop ocean points
write.csv(syal.final, file = "syal.final.csv")
save(syal.final, file="syal.final.RData") # save as Rdata object so you don't have to do it every time
syal.final <- read.csv("syal.final.csv", header= TRUE)
# load("syal.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

syal.final <- syal.final[ , !(colnames(syal.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(syal.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
syal.final <- syal.final[!dup, ] # drop duplicate records
write.csv(syal.final, file = "syal.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(syal.final$lon, syal.final$lat, col='orange', pch=20, cex=0.75) # add points
points(syal.final$lon, syal.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=syal.final, aes(x=month, y=final_elev, group=syal.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="syal")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
syal.nona <- subset(syal.final, select=oa) 
is.na(syal.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
syal.b <- syal.nona[which(syal.nona$month==6 | syal.nona$month==7), ] # Breeding end-April to August
syal.nb <- syal.nona[which(syal.nona$month==12 | syal.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=syal.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: syal")
p <- p + theme_classic()
print(p)

boxplot(syal.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=syal.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: syal")
p <- p + theme_classic()
print(p)

boxplot(syal.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
syal.b.out <- FindOutliers(syal.b, r=1.5); syal.b.out # Detect outliers
syal.b <- syal.b[-syal.b.out$rownum,] # remove the outliers 

syal.nb.out <- FindOutliers(syal.nb, r=1.5); syal.nb.out # Detect outliers
# no outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
syal.b.elevs <- BreedingElevs(syal.b)
syal.nb.elevs <- NonbreedingElevs(syal.nb)
syal.elev.range <- cbind(syal.nb.elevs, syal.b.elevs); syal.elev.range
syal.elev.range["species"] <- "Sylvia althaea"
syal.elev.range <- syal.elev.range[, c(5,1,2,3,4)]; syal.elev.range  # reorder columns 
write.csv(syal.elev.range, file = "syal.elev.range.csv")
```






# BLUETHROAT
```{r}
# Import data
name_suggest(q="Luscinia svecica", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(lusv.dl <- occ_download("taxonKey=4408732", "hasCoordinate=TRUE", "country=IN", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(lusv.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
lusv <- occ_download_get("0021074-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

lusv.cit <- occ_download_get("0021074-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
lusv.cit$download # prints one-line output with DOI

write.csv(lusv, file = "lusv.csv")
lusv <- read.csv("lusv.csv", header= TRUE)
```

```{r}
# Clean data  
lusv.sub <- subset(lusv, select=sc) # subset data w/ criteria defined in sc
lusv.sub <- lusv.sub[which(lusv.sub$species == "Luscinia svecica"),] # verify only desired species
lusv.sub <- lusv.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
lusv.sub <- lusv.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
lusv.sub <- lusv.sub[which(!lusv.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
lusv.sub <- lusv.sub[which(!lusv.sub$decimalLongitude == "0"), ] # Drop lon values of 0
lusv.sub <- lusv.sub[which(!lusv.sub$month == "NA"), ] # Drop NA months
lusv.sub <- lusv.sub[which(!lusv.sub$countryCode == "NA"), ] # Drop NA countries
colnames(lusv.sub)[colnames(lusv.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
lusv.sub <- lusv.sub[order(-lusv.sub$coord_uncert), ] # sort by coordinate uncertainty
lusv.sub <- subset(lusv.sub, lusv.sub$coord_uncert < 3000 | is.na(lusv.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(lusv.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
lusv.sub <- subset(lusv.sub, subset = lusv.sub$countryCode %in% c("IN"))

# Fetch elevations with elevation() from rgbif
lusv.getelev <- elevation(lusv.sub, elevation_model="srtm3", username="selina1")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
lusv.qc <- lusv.getelev
lusv.qc$elev_diff <- (lusv.qc$elevation-lusv.qc$elevation_geonames) # Make elev_diff variable 
lusv.qc <- lusv.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
lusv.qc <- lusv.qc[order(-lusv.qc$elev_diff), ] # sort by elev_diff
lusv.qc <- subset(lusv.qc, lusv.qc$elev_diff < 300 | is.na(lusv.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
lusv.elevs <- lusv.qc %>% filter(!is.na(elevation)) # existing elev
lusv.noelev <- lusv.qc %>% filter(is.na(elevation)) # no original elevs
lusv.elevs$final_elev <- lusv.elevs$elevation # add final_elev, assign elevation values to it 
lusv.noelev$final_elev <- lusv.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
lusv.final <- rbind(lusv.elevs, lusv.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
lusv.final <- lusv.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
lusv.final <- lusv.final[order(-lusv.final$month, -lusv.final$final_elev), ] # sort by month
lusv.final <- lusv.final[which(!lusv.final$final_elev == "-32768"), ] # drop ocean points
write.csv(lusv.final, file = "lusv.final.csv")
save(lusv.final, file="lusv.final.RData") # save as Rdata object so you don't have to do it every time
lusv.final <- read.csv("lusv.final.csv", header= TRUE)
# load("lusv.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

lusv.final <- lusv.final[ , !(colnames(lusv.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(lusv.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
lusv.final <- lusv.final[!dup, ] # drop duplicate records
write.csv(lusv.final, file = "lusv.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(lusv.final$lon, lusv.final$lat, col='orange', pch=20, cex=0.75) # add points
points(lusv.final$lon, lusv.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=lusv.final, aes(x=month, y=final_elev, group=lusv.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="lusv")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
lusv.nona <- subset(lusv.final, select=oa) 
is.na(lusv.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
lusv.b <- lusv.nona[which(lusv.nona$month==6 | lusv.nona$month==7), ] # Breeding May to August
lusv.nb <- lusv.nona[which(lusv.nona$month==12 | lusv.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=lusv.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: lusv")
p <- p + theme_classic()
print(p)

boxplot(lusv.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=lusv.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: lusv")
p <- p + theme_classic()
print(p)

boxplot(lusv.nb$final_elev, range=3, main="range=3") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
lusv.b.out <- FindOutliers(lusv.b, r=1.5); lusv.b.out # Detect outliers
lusv.b <- lusv.b[-lusv.b.out$rownum,] # remove the outliers 

lusv.nb.out <- FindOutliers(lusv.nb, r=3); lusv.nb.out # Detect outliers
lusv.nb <- lusv.nb[-lusv.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
lusv.b.elevs <- BreedingElevs(lusv.b)
lusv.nb.elevs <- NonbreedingElevs(lusv.nb)
lusv.elev.range <- cbind(lusv.nb.elevs, lusv.b.elevs); lusv.elev.range
lusv.elev.range["species"] <- "Luscinia_svecica"
lusv.elev.range <- lusv.elev.range[, c(5,1,2,3,4)]; lusv.elev.range  # reorder columns 
write.csv(lusv.elev.range, file = "lusv.elev.range.csv")
```




# DESERT WHEATEAR
```{r}
# Import data
name_suggest(q="Oenanthe deserti", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(oede.dl <- occ_download("taxonKey=5231244", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(oede.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
oede <- occ_download_get("0021089-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

oede.cit <- occ_download_get("0021089-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
oede.cit$download # prints one-line output with DOI

write.csv(oede, file = "oede.csv")
oede <- read.csv("oede.csv", header= TRUE)
```

```{r}
# Clean data  
oede.sub <- subset(oede, select=sc) # subset data w/ criteria defined in sc
oede.sub <- oede.sub[which(oede.sub$species == "Oenanthe deserti"),] # verify only desired species
oede.sub <- oede.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
oede.sub <- oede.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
oede.sub <- oede.sub[which(!oede.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
oede.sub <- oede.sub[which(!oede.sub$decimalLongitude == "0"), ] # Drop lon values of 0
oede.sub <- oede.sub[which(!oede.sub$month == "NA"), ] # Drop NA months
oede.sub <- oede.sub[which(!oede.sub$countryCode == "NA"), ] # Drop NA countries
colnames(oede.sub)[colnames(oede.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
oede.sub <- oede.sub[order(-oede.sub$coord_uncert), ] # sort by coordinate uncertainty
oede.sub <- subset(oede.sub, oede.sub$coord_uncert < 3000 | is.na(oede.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(oede.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
oede.sub <- subset(oede.sub, subset = oede.sub$countryCode %in% c("IN"))

# Fetch elevations with elevation() from rgbif
oede.getelev <- elevation(oede.sub, elevation_model="srtm3", username="jwilliamson0110")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
oede.qc <- oede.getelev
oede.qc$elev_diff <- (oede.qc$elevation-oede.qc$elevation_geonames) # Make elev_diff variable 
oede.qc <- oede.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
oede.qc <- oede.qc[order(-oede.qc$elev_diff), ] # sort by elev_diff
oede.qc <- subset(oede.qc, oede.qc$elev_diff < 300 | is.na(oede.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
oede.elevs <- oede.qc %>% filter(!is.na(elevation)) # existing elev
oede.noelev <- oede.qc %>% filter(is.na(elevation)) # no original elevs
oede.elevs$final_elev <- oede.elevs$elevation # add final_elev, assign elevation values to it 
oede.noelev$final_elev <- oede.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
oede.final <- rbind(oede.elevs, oede.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
oede.final <- oede.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
oede.final <- oede.final[order(-oede.final$month, -oede.final$final_elev), ] # sort by month
oede.final <- oede.final[which(!oede.final$final_elev == "-32768"), ] # drop ocean points
write.csv(oede.final, file = "oede.final.csv")
save(oede.final, file="oede.final.RData") # save as Rdata object so you don't have to do it every time
oede.final <- read.csv("oede.final.csv", header= TRUE)
# load("oede.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

oede.final <- oede.final[ , !(colnames(oede.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(oede.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
oede.final <- oede.final[!dup, ] # drop duplicate records
write.csv(oede.final, file = "oede.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(oede.final$lon, oede.final$lat, col='orange', pch=20, cex=0.75) # add points
points(oede.final$lon, oede.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=oede.final, aes(x=month, y=final_elev, group=oede.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="oede")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
oede.nona <- subset(oede.final, select=oa) 
is.na(oede.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
oede.b <- oede.nona[which(oede.nona$month==6 | oede.nona$month==7), ] # Breeding May-July
oede.nb <- oede.nona[which(oede.nona$month==12 | oede.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=oede.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: oede")
p <- p + theme_classic()
print(p)

boxplot(oede.b$final_elev, range = 3, main="range =3") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=oede.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: oede")
p <- p + theme_classic()
print(p)

boxplot(oede.nb$final_elev, range=3, main="range=3") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
oede.b.out <- FindOutliers(oede.b, r=3); oede.b.out # Detect outliers
oede.b <- oede.b[-oede.b.out$rownum,] # remove the outliers 

oede.nb.out <- FindOutliers(oede.nb, r=3); oede.nb.out # Detect outliers
#no outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
oede.b.elevs <- BreedingElevs(oede.b)
oede.nb.elevs <- NonbreedingElevs(oede.nb)
oede.elev.range <- cbind(oede.nb.elevs, oede.b.elevs); oede.elev.range
oede.elev.range["species"] <- "Oenanthe_deserti"
oede.elev.range <- oede.elev.range[, c(5,1,2,3,4)]; oede.elev.range  # reorder columns 
write.csv(oede.elev.range, file = "oede.elev.range.csv")
```


# VARIABLE WHEATEAR
```{r}
# Import data
name_suggest(q="Oenanthe picata", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(oepi.dl <- occ_download("taxonKey=5231238", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(oepi.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
oepi <- occ_download_get("0021091-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

oepi.cit <- occ_download_get("0021091-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
oepi.cit$download # prints one-line output with DOI

write.csv(oepi, file = "oepi.csv")
oepi <- read.csv("oepi.csv", header= TRUE)
```

```{r}
# Clean data  
oepi.sub <- subset(oepi, select=sc) # subset data w/ criteria defined in sc
oepi.sub <- oepi.sub[which(oepi.sub$species == "Oenanthe picata"),] # verify only desired species
oepi.sub <- oepi.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
oepi.sub <- oepi.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
oepi.sub <- oepi.sub[which(!oepi.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
oepi.sub <- oepi.sub[which(!oepi.sub$decimalLongitude == "0"), ] # Drop lon values of 0
oepi.sub <- oepi.sub[which(!oepi.sub$month == "NA"), ] # Drop NA months
oepi.sub <- oepi.sub[which(!oepi.sub$countryCode == "NA"), ] # Drop NA countries
colnames(oepi.sub)[colnames(oepi.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
oepi.sub <- oepi.sub[order(-oepi.sub$coord_uncert), ] # sort by coordinate uncertainty
oepi.sub <- subset(oepi.sub, oepi.sub$coord_uncert < 3000 | is.na(oepi.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(oepi.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
oepi.sub <- subset(oepi.sub, subset = oepi.sub$countryCode %in% c("IN"))

# Fetch elevations with elevation() from rgbif
oepi.getelev <- elevation(oepi.sub, elevation_model="srtm3", username="jwilliamson0110")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
oepi.qc <- oepi.getelev
oepi.qc$elev_diff <- (oepi.qc$elevation-oepi.qc$elevation_geonames) # Make elev_diff variable 
oepi.qc <- oepi.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
oepi.qc <- oepi.qc[order(-oepi.qc$elev_diff), ] # sort by elev_diff
oepi.qc <- subset(oepi.qc, oepi.qc$elev_diff < 300 | is.na(oepi.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
oepi.elevs <- oepi.qc %>% filter(!is.na(elevation)) # existing elev
oepi.noelev <- oepi.qc %>% filter(is.na(elevation)) # no original elevs
oepi.elevs$final_elev <- oepi.elevs$elevation # add final_elev, assign elevation values to it 
oepi.noelev$final_elev <- oepi.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
oepi.final <- rbind(oepi.elevs, oepi.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
oepi.final <- oepi.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
oepi.final <- oepi.final[order(-oepi.final$month, -oepi.final$final_elev), ] # sort by month
oepi.final <- oepi.final[which(!oepi.final$final_elev == "-32768"), ] # drop ocean points
write.csv(oepi.final, file = "oepi.final.csv")
save(oepi.final, file="oepi.final.RData") # save as Rdata object so you don't have to do it every time
oepi.final <- read.csv("oepi.final.csv", header= TRUE)
# load("oepi.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

oepi.final <- oepi.final[ , !(colnames(oepi.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(oepi.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
oepi.final <- oepi.final[!dup, ] # drop duplicate records
write.csv(oepi.final, file = "oepi.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(oepi.final$lon, oepi.final$lat, col='orange', pch=20, cex=0.75) # add points
points(oepi.final$lon, oepi.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=oepi.final, aes(x=month, y=final_elev, group=oepi.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="oepi")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
oepi.nona <- subset(oepi.final, select=oa) 
is.na(oepi.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
oepi.b <- oepi.nona[which(oepi.nona$month==5 | oepi.nona$month==6 | oepi.nona$month==7), ] # Breeding March-August
oepi.nb <- oepi.nona[which(oepi.nona$month==11 | oepi.nona$month==12 | oepi.nona$month==11), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=oepi.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: oepi")
p <- p + theme_classic()
print(p)

boxplot(oepi.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=oepi.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: oepi")
p <- p + theme_classic()
print(p)

boxplot(oepi.nb$final_elev, range=3, main="range=3") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
oepi.b.out <- FindOutliers(oepi.b, r=1.5); oepi.b.out # Detect outliers
oepi.b <- oepi.b[-oepi.b.out$rownum,] # remove the outliers 

oepi.nb.out <- FindOutliers(oepi.nb, r=3); oepi.nb.out # Detect outliers
oepi.nb <- oepi.nb[-oepi.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
oepi.b.elevs <- BreedingElevs(oepi.b)
oepi.nb.elevs <- NonbreedingElevs(oepi.nb)
oepi.elev.range <- cbind(oepi.nb.elevs, oepi.b.elevs); oepi.elev.range
oepi.elev.range["species"] <- "Oenanthe_picata"
oepi.elev.range <- oepi.elev.range[, c(5,1,2,3,4)]; oepi.elev.range  # reorder columns 
write.csv(oepi.elev.range, file = "oepi.elev.range.csv")
```



# BLUE ROCK THRUSH
```{r}
# Import data
name_suggest(q="Monticola solitarius", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(moso.dl <- occ_download("taxonKey=2490955", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(moso.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
moso <- occ_download_get("0021103-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") # if this stops working, add "fill=false, quote="" "

moso.cit <- occ_download_get("0021103-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
moso.cit$download # prints one-line output with DOI

write.csv(moso, file = "moso.csv")
moso <- read.csv("moso.csv", header= TRUE)
```

```{r}
# Clean data  
moso.sub <- subset(moso, select=sc) # subset data w/ criteria defined in sc
moso.sub <- moso.sub[which(moso.sub$species == "Monticola solitarius"),] # verify only desired species
moso.sub <- moso.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
moso.sub <- moso.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
moso.sub <- moso.sub[which(!moso.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
moso.sub <- moso.sub[which(!moso.sub$decimalLongitude == "0"), ] # Drop lon values of 0
moso.sub <- moso.sub[which(!moso.sub$month == "NA"), ] # Drop NA months
moso.sub <- moso.sub[which(!moso.sub$countryCode == "NA"), ] # Drop NA countries
colnames(moso.sub)[colnames(moso.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
moso.sub <- moso.sub[order(-moso.sub$coord_uncert), ] # sort by coordinate uncertainty
moso.sub <- subset(moso.sub, moso.sub$coord_uncert < 3000 | is.na(moso.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(moso.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
moso.sub <- subset(moso.sub, subset = moso.sub$countryCode %in% c("NP"))

# Fetch elevations with elevation() from rgbif
moso.getelev <- elevation(moso.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
moso.qc <- moso.getelev
moso.qc$elev_diff <- (moso.qc$elevation-moso.qc$elevation_geonames) # Make elev_diff variable 
moso.qc <- moso.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
moso.qc <- moso.qc[order(-moso.qc$elev_diff), ] # sort by elev_diff
moso.qc <- subset(moso.qc, moso.qc$elev_diff < 300 | is.na(moso.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
moso.elevs <- moso.qc %>% filter(!is.na(elevation)) # existing elev
moso.noelev <- moso.qc %>% filter(is.na(elevation)) # no original elevs
moso.elevs$final_elev <- moso.elevs$elevation # add final_elev, assign elevation values to it 
moso.noelev$final_elev <- moso.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
moso.final <- rbind(moso.elevs, moso.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
moso.final <- moso.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
moso.final <- moso.final[order(-moso.final$month, -moso.final$final_elev), ] # sort by month
moso.final <- moso.final[which(!moso.final$final_elev == "-32768"), ] # drop ocean points
write.csv(moso.final, file = "moso.final.csv")
save(moso.final, file="moso.final.RData") # save as Rdata object so you don't have to do it every time
moso.final <- read.csv("moso.final.csv", header= TRUE)
# load("moso.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

moso.final <- moso.final[ , !(colnames(moso.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(moso.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
moso.final <- moso.final[!dup, ] # drop duplicate records
write.csv(moso.final, file = "moso.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(moso.final$lon, moso.final$lat, col='orange', pch=20, cex=0.75) # add points
points(moso.final$lon, moso.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=moso.final, aes(x=month, y=final_elev, group=moso.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="moso")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
moso.nona <- subset(moso.final, select=oa) 
is.na(moso.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
moso.b <- moso.nona[which(moso.nona$month==5 | moso.nona$month==6), ] # Breeding April-July
moso.nb <- moso.nona[which(moso.nona$month==11 | moso.nona$month==12), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=moso.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: moso")
p <- p + theme_classic()
print(p)

boxplot(moso.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=moso.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: moso")
p <- p + theme_classic()
print(p)

boxplot(moso.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
moso.b.out <- FindOutliers(moso.b, r=1.5); moso.b.out # Detect outliers
# no outliers

moso.nb.out <- FindOutliers(moso.nb, r=1.5); moso.nb.out # Detect outliers
moso.nb <- moso.nb[-moso.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
moso.b.elevs <- BreedingElevs(moso.b)
moso.nb.elevs <- NonbreedingElevs(moso.nb)
moso.elev.range <- cbind(moso.nb.elevs, moso.b.elevs); moso.elev.range
moso.elev.range["species"] <- "Monticola_solitarius"
moso.elev.range <- moso.elev.range[, c(5,1,2,3,4)]; moso.elev.range  # reorder columns 
write.csv(moso.elev.range, file = "moso.elev.range.csv")
```


# CITRINE WAGTAIL
```{r}
# Import data
name_suggest(q="Motacilla citreola", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(moci.dl <- occ_download("taxonKey=2490307", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(moci.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
moci <- occ_download_get("0021163-191105090559680", overwrite=TRUE) %>% occ_download_import() 
# if this stops working, add "fill=false, quote="" "

moci.cit <- occ_download_get("0021163-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
moci.cit$download # prints one-line output with DOI

write.csv(moci, file = "moci.csv")
moci <- read.csv("moci.csv", header= TRUE)
```

```{r}
# Clean data  
moci.sub <- subset(moci, select=sc) # subset data w/ criteria defined in sc
moci.sub <- moci.sub[which(moci.sub$species == "Motacilla citreola"),] # verify only desired species
moci.sub <- moci.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
moci.sub <- moci.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
moci.sub <- moci.sub[which(!moci.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
moci.sub <- moci.sub[which(!moci.sub$decimalLongitude == "0"), ] # Drop lon values of 0
moci.sub <- moci.sub[which(!moci.sub$month == "NA"), ] # Drop NA months
moci.sub <- moci.sub[which(!moci.sub$countryCode == "NA"), ] # Drop NA countries
colnames(moci.sub)[colnames(moci.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
moci.sub <- moci.sub[order(-moci.sub$coord_uncert), ] # sort by coordinate uncertainty
moci.sub <- subset(moci.sub, moci.sub$coord_uncert < 3000 | is.na(moci.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(moci.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
moci.sub <- subset(moci.sub, subset = moci.sub$countryCode %in% c("IN"))

moci.split <- split(moci.sub, (seq(nrow(moci.sub))-1) %/% 6656) # splits data into chunks of 9000 (10k too big)
# moci.split.unlist <- do.call(rbind.data.frame, moci.split) # unsplits and makes a data frame 

moci0 <- as.data.frame(moci.split$"0")
moci1 <- as.data.frame(moci.split$"1")

# Fetch elevations with elevation() from rgbif
moci.e0 <- elevation(moci0, elevation_model="srtm3", username="selina1")
moci.e1 <- elevation(moci1, elevation_model="srtm3", username="willford1")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# rbind mini data frames together again
moci.all <- rbind(moci.e0, moci.e1) # good, same length as moci.sub

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
moci.qc <- moci.all
moci.qc$elev_diff <- (moci.qc$elevation-moci.qc$elevation_geonames) # Make elev_diff variable 
moci.qc <- moci.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
moci.qc <- moci.qc[order(-moci.qc$elev_diff), ] # sort by elev_diff
moci.qc <- subset(moci.qc, moci.qc$elev_diff < 300 | is.na(moci.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
moci.elevs <- moci.qc %>% filter(!is.na(elevation)) # existing elev
moci.noelev <- moci.qc %>% filter(is.na(elevation)) # no original elevs
moci.elevs$final_elev <- moci.elevs$elevation # add final_elev, assign elevation values to it 
moci.noelev$final_elev <- moci.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
moci.final <- rbind(moci.elevs, moci.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
moci.final <- moci.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
moci.final <- moci.final[order(-moci.final$month, -moci.final$final_elev), ] # sort by month
moci.final <- moci.final[which(!moci.final$final_elev == "-32768"), ] # drop ocean points
write.csv(moci.final, file = "moci.final.csv")
save(moci.final, file="moci.final.RData") # save as Rdata object so you don't have to do it every time
moci.final <- read.csv("moci.final.csv", header= TRUE)
# load("moci.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

moci.final <- moci.final[ , !(colnames(moci.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(moci.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
moci.final <- moci.final[!dup, ] # drop duplicate records
write.csv(moci.final, file = "moci.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
# plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(moci.final$lon, moci.final$lat, col='orange', pch=20, cex=0.75) # add points
points(moci.final$lon, moci.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=moci.final, aes(x=month, y=final_elev, group=moci.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="moci")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
moci.nona <- subset(moci.final, select=oa) 
is.na(moci.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
moci.b <- moci.nona[which(moci.nona$month==6 | moci.nona$month==7), ] # Breeding May-August
moci.nb <- moci.nona[which(moci.nona$month==12 | moci.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=moci.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: moci")
p <- p + theme_classic()
print(p)

boxplot(moci.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=moci.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: moci")
p <- p + theme_classic()
print(p)

boxplot(moci.nb$final_elev, range=3, main="range=3") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
moci.b.out <- FindOutliers(moci.b, r=1.5); moci.b.out # Detect outliers
moci.b <- moci.b[-moci.b.out$rownum,] # remove the outliers 

moci.nb.out <- FindOutliers(moci.nb, r=3); moci.nb.out # Detect outliers
moci.nb <- moci.nb[-moci.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
moci.b.elevs <- BreedingElevs(moci.b)
moci.nb.elevs <- NonbreedingElevs(moci.nb)
moci.elev.range <- cbind(moci.nb.elevs, moci.b.elevs); moci.elev.range
moci.elev.range["species"] <- "Motacilla_citreola"
moci.elev.range <- moci.elev.range[, c(5,1,2,3,4)]; moci.elev.range  # reorder columns 
write.csv(moci.elev.range, file = "moci.elev.range.csv")
```



# TREE PIPIT
```{r}
# Import data
name_suggest(q="Anthus trivialis", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(antr.dl <- occ_download("taxonKey=2490246", "hasCoordinate=TRUE", "country=IN", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(antr.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
antr <- occ_download_get("0021165-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") # if this stops working, add "fill=false, quote="" "

antr.cit <- occ_download_get("0021165-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
antr.cit$download # prints one-line output with DOI

write.csv(antr, file = "antr.csv")
antr <- read.csv("antr.csv", header= TRUE)
```

```{r}
# Clean data  
antr.sub <- subset(antr, select=sc) # subset data w/ criteria defined in sc
antr.sub <- antr.sub[which(antr.sub$species == "Anthus trivialis"),] # verify only desired species
antr.sub <- antr.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
antr.sub <- antr.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
antr.sub <- antr.sub[which(!antr.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
antr.sub <- antr.sub[which(!antr.sub$decimalLongitude == "0"), ] # Drop lon values of 0
antr.sub <- antr.sub[which(!antr.sub$month == "NA"), ] # Drop NA months
antr.sub <- antr.sub[which(!antr.sub$countryCode == "NA"), ] # Drop NA countries
colnames(antr.sub)[colnames(antr.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
antr.sub <- antr.sub[order(-antr.sub$coord_uncert), ] # sort by coordinate uncertainty
antr.sub <- subset(antr.sub, antr.sub$coord_uncert < 3000 | is.na(antr.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(antr.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
antr.sub <- subset(antr.sub, subset = antr.sub$countryCode %in% c("IN"))

# Fetch elevations with elevation() from rgbif
antr.getelev <- elevation(antr.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
antr.qc <- antr.getelev
antr.qc$elev_diff <- (antr.qc$elevation-antr.qc$elevation_geonames) # Make elev_diff variable 
antr.qc <- antr.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
antr.qc <- antr.qc[order(-antr.qc$elev_diff), ] # sort by elev_diff
antr.qc <- subset(antr.qc, antr.qc$elev_diff < 300 | is.na(antr.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
antr.elevs <- antr.qc %>% filter(!is.na(elevation)) # existing elev
antr.noelev <- antr.qc %>% filter(is.na(elevation)) # no original elevs
antr.elevs$final_elev <- antr.elevs$elevation # add final_elev, assign elevation values to it 
antr.noelev$final_elev <- antr.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
antr.final <- rbind(antr.elevs, antr.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
antr.final <- antr.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
antr.final <- antr.final[order(-antr.final$month, -antr.final$final_elev), ] # sort by month
antr.final <- antr.final[which(!antr.final$final_elev == "-32768"), ] # drop ocean points
write.csv(antr.final, file = "antr.final.csv")
save(antr.final, file="antr.final.RData") # save as Rdata object so you don't have to do it every time
antr.final <- read.csv("antr.final.csv", header= TRUE)
# load("antr.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

antr.final <- antr.final[ , !(colnames(antr.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(antr.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
antr.final <- antr.final[!dup, ] # drop duplicate records
write.csv(antr.final, file = "antr.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(antr.final$lon, antr.final$lat, col='orange', pch=20, cex=0.75) # add points
points(antr.final$lon, antr.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=antr.final, aes(x=month, y=final_elev, group=antr.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="antr")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
antr.nona <- subset(antr.final, select=oa) 
is.na(antr.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
antr.b <- antr.nona[which(antr.nona$month==6 | antr.nona$month==7), ] # Breeding May to July
antr.nb <- antr.nona[which(antr.nona$month==12 | antr.nona$month==1), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=antr.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: antr")
p <- p + theme_classic()
print(p)

boxplot(antr.b$final_elev, range = 1.0, main="range = 1.0") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=antr.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: antr")
p <- p + theme_classic()
print(p)

boxplot(antr.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
antr.b.out <- FindOutliers(antr.b, r=1.0); antr.b.out # Detect outliers
antr.b <- antr.b[-antr.b.out$rownum,] # remove the outliers 

antr.nb.out <- FindOutliers(antr.nb, r=1.5); antr.nb.out # Detect outliers
antr.nb <- antr.nb[-antr.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
antr.b.elevs <- BreedingElevs(antr.b)
antr.nb.elevs <- NonbreedingElevs(antr.nb)
antr.elev.range <- cbind(antr.nb.elevs, antr.b.elevs); antr.elev.range
antr.elev.range["species"] <- "Anthus trivialis"
antr.elev.range <- antr.elev.range[, c(5,1,2,3,4)]; antr.elev.range  # reorder columns 
write.csv(antr.elev.range, file = "antr.elev.range.csv")
```



# YELLOW-BREASTED GREENFINCH
```{r}
# Import data
name_suggest(q="Chloris spinoides", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(casp.dl <- occ_download("taxonKey=6101013", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(casp.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
casp <- occ_download_get("0021171-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") # if this stops working, add "fill=false, quote="" "

casp.cit <- occ_download_get("0021171-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
casp.cit$download # prints one-line output with DOI

write.csv(casp, file = "casp.csv")
casp <- read.csv("casp.csv", header= TRUE)
```

```{r}
# Clean data  
casp.sub <- subset(casp, select=sc) # subset data w/ criteria defined in sc
casp.sub <- casp.sub[which(casp.sub$species == "Chloris spinoides"),] # verify only desired species
casp.sub <- casp.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
casp.sub <- casp.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
casp.sub <- casp.sub[which(!casp.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
casp.sub <- casp.sub[which(!casp.sub$decimalLongitude == "0"), ] # Drop lon values of 0
casp.sub <- casp.sub[which(!casp.sub$month == "NA"), ] # Drop NA months
casp.sub <- casp.sub[which(!casp.sub$countryCode == "NA"), ] # Drop NA countries
colnames(casp.sub)[colnames(casp.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
casp.sub <- casp.sub[order(-casp.sub$coord_uncert), ] # sort by coordinate uncertainty
casp.sub <- subset(casp.sub, casp.sub$coord_uncert < 3000 | is.na(casp.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(casp.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
casp.sub <- subset(casp.sub, subset = casp.sub$countryCode %in% c("IN"))

# Fetch elevations with elevation() from rgbif
casp.getelev <- elevation(casp.sub, elevation_model="srtm3", username="jwilliamson0110")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
casp.qc <- casp.getelev
casp.qc$elev_diff <- (casp.qc$elevation-casp.qc$elevation_geonames) # Make elev_diff variable 
casp.qc <- casp.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
casp.qc <- casp.qc[order(-casp.qc$elev_diff), ] # sort by elev_diff
casp.qc <- subset(casp.qc, casp.qc$elev_diff < 300 | is.na(casp.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
casp.elevs <- casp.qc %>% filter(!is.na(elevation)) # existing elev
casp.noelev <- casp.qc %>% filter(is.na(elevation)) # no original elevs
casp.elevs$final_elev <- casp.elevs$elevation # add final_elev, assign elevation values to it 
casp.noelev$final_elev <- casp.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
casp.final <- rbind(casp.elevs, casp.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
casp.final <- casp.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
casp.final <- casp.final[order(-casp.final$month, -casp.final$final_elev), ] # sort by month
casp.final <- casp.final[which(!casp.final$final_elev == "-32768"), ] # drop ocean points
write.csv(casp.final, file = "casp.final.csv")
save(casp.final, file="casp.final.RData") # save as Rdata object so you don't have to do it every time
casp.final <- read.csv("casp.final.csv", header= TRUE)
# load("casp.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

casp.final <- casp.final[ , !(colnames(casp.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(casp.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
casp.final <- casp.final[!dup, ] # drop duplicate records
write.csv(casp.final, file = "casp.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(casp.final$lon, casp.final$lat, col='orange', pch=20, cex=0.75) # add points
points(casp.final$lon, casp.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=casp.final, aes(x=month, y=final_elev, group=casp.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="casp")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
casp.nona <- subset(casp.final, select=oa) 
is.na(casp.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season 
casp.b <- casp.nona[which(casp.nona$month==7 | casp.nona$month==8 | casp.nona$month==9), ] # Breeding June-October
casp.nb <- casp.nona[which(casp.nona$month==12 | casp.nona$month==1 | casp.nona$month==2), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=casp.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: casp")
p <- p + theme_classic()
print(p)

boxplot(casp.b$final_elev, range = 3, main="range = 3") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=casp.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: casp")
p <- p + theme_classic()
print(p)

boxplot(casp.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
casp.b.out <- FindOutliers(casp.b, r=3); casp.b.out # Detect outliers
casp.b <- casp.b[-casp.b.out$rownum,] # remove the outliers 

casp.nb.out <- FindOutliers(casp.nb, r=1.5); casp.nb.out # Detect outliers
casp.nb <- casp.nb[-casp.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
casp.b.elevs <- BreedingElevs(casp.b)
casp.nb.elevs <- NonbreedingElevs(casp.nb)
casp.elev.range <- cbind(casp.nb.elevs, casp.b.elevs); casp.elev.range
casp.elev.range["species"] <- "Chloris_spinoides"
casp.elev.range <- casp.elev.range[, c(5,1,2,3,4)]; casp.elev.range  # reorder columns 
write.csv(casp.elev.range, file = "casp.elev.range.csv")
```




# COMMON SANDPIPER - Pakistan
```{r}
# Import data
name_suggest(q="Actitis hypoleucos", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(acpk.dl <- occ_download("taxonKey=2481800", "hasCoordinate=TRUE", "country=PK", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(acpk.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
acpk <- occ_download_get("0021177-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") 
# if this stops working, add "fill=false, quote="" "

acpk.cit <- occ_download_get("0021177-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
acpk.cit$download # prints one-line output with DOI

write.csv(acpk, file = "acpk.csv")
acpk <- read.csv("acpk.csv", header= TRUE)
```

```{r}
# Clean data  
acpk.sub <- subset(acpk, select=sc) # subset data w/ criteria defined in sc
acpk.sub <- acpk.sub[which(acpk.sub$species == "Actitis hypoleucos"),] # verify only desired species
acpk.sub <- acpk.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
acpk.sub <- acpk.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
acpk.sub <- acpk.sub[which(!acpk.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
acpk.sub <- acpk.sub[which(!acpk.sub$decimalLongitude == "0"), ] # Drop lon values of 0
acpk.sub <- acpk.sub[which(!acpk.sub$month == "NA"), ] # Drop NA months
acpk.sub <- acpk.sub[which(!acpk.sub$countryCode == "NA"), ] # Drop NA countries
colnames(acpk.sub)[colnames(acpk.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
acpk.sub <- acpk.sub[order(-acpk.sub$coord_uncert), ] # sort by coordinate uncertainty
acpk.sub <- subset(acpk.sub, acpk.sub$coord_uncert < 3000 | is.na(acpk.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(acpk.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
acpk.sub <- subset(acpk.sub, subset = acpk.sub$countryCode %in% c("PK"))

# Fetch elevations with elevation() from rgbif
acpk.getelev <- elevation(acpk.sub, elevation_model="srtm3", username="jwilliamson0110")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
acpk.qc <- acpk.getelev
acpk.qc$elev_diff <- (acpk.qc$elevation-acpk.qc$elevation_geonames) # Make elev_diff variable 
acpk.qc <- acpk.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
acpk.qc <- acpk.qc[order(-acpk.qc$elev_diff), ] # sort by elev_diff
acpk.qc <- subset(acpk.qc, acpk.qc$elev_diff < 300 | is.na(acpk.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
acpk.elevs <- acpk.qc %>% filter(!is.na(elevation)) # existing elev
acpk.noelev <- acpk.qc %>% filter(is.na(elevation)) # no original elevs
acpk.elevs$final_elev <- acpk.elevs$elevation # add final_elev, assign elevation values to it 
acpk.noelev$final_elev <- acpk.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
acpk.final <- rbind(acpk.elevs, acpk.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
acpk.final <- acpk.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
acpk.final <- acpk.final[order(-acpk.final$month, -acpk.final$final_elev), ] # sort by month
acpk.final <- acpk.final[which(!acpk.final$final_elev == "-32768"), ] # drop ocean points
write.csv(acpk.final, file = "acpk.final.csv")
save(acpk.final, file="acpk.final.RData") # save as Rdata object so you don't have to do it every time
acpk.final <- read.csv("acpk.final.csv", header= TRUE)
#load("acpk.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

acpk.final <- acpk.final[ , !(colnames(acpk.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(acpk.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
acpk.final <- acpk.final[!dup, ] # drop duplicate records
write.csv(acpk.final, file = "acpk.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(60,100), ylim=c(5,45)) # Indian subcontinent
points(acpk.final$lon, acpk.final$lat, col='orange', pch=20, cex=0.75) # add points
points(acpk.final$lon, acpk.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=acpk.final, aes(x=month, y=final_elev, group=acpk.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="acpk")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
acpk.nona <- subset(acpk.final, select=oa) 
is.na(acpk.nona) # need no NAs to run outlier function 

# subset by breeding and non-breeding season  
acpk.b <- acpk.nona[which(acpk.nona$month==5 | acpk.nona$month==6), ]
  # HBW sayw late May to June, but check Grimmett (Grimmett also says May and June)
acpk.nb <- acpk.nona[which(acpk.nona$month==11 | acpk.nona$month==12), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=acpk.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: acpk")
p <- p + theme_classic()
print(p)

boxplot(acpk.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=acpk.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: acpk")
p <- p + theme_classic()
print(p)

boxplot(acpk.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
acpk.b.out <- FindOutliers(acpk.b, r=1.5); acpk.b.out # Detect outliers
#acpk.b <- acpk.b[-acpk.b.out$rownum,] # remove the outliers 

acpk.nb.out <- FindOutliers(acpk.nb, r=1.5); acpk.nb.out # Detect outliers
# no outliers

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
acpk.b.elevs <- BreedingElevs(acpk.b)
acpk.nb.elevs <- NonbreedingElevs(acpk.nb)
acpk.elev.range <- cbind(acpk.nb.elevs, acpk.b.elevs); acpk.elev.range
acpk.elev.range["species"] <- "Actitis_hypoleucos_Pakistan"
acpk.elev.range <- acpk.elev.range[, c(5,1,2,3,4)]; acpk.elev.range  # reorder columns 
write.csv(acpk.elev.range, file = "acpk.elev.range.csv")
```



# WHITE-BROWED GROUND-TYRANT
```{r}
# Import data
name_suggest(q="Muscisaxicola albilora", rank="species")$key[1] # get taxonKey

# kick off a download (taxonKey MUST be numeric form)
(mual.dl <- occ_download("taxonKey=2483719", "hasCoordinate=TRUE", user="jwilliamson", pwd = "YOURPASSWORD", email = "williamson@unm.edu"))
  # COMMENT THIS OUT SO YOU DON'T BEGIN NEW DOWNLOAD EACH TIME YOU RUN CODE 

occ_download_meta(mual.dl) # check download status 

# Once download is "succeeded", fetch data & pipe zip file into R as a data frame
mual <- occ_download_get("0021182-191105090559680", overwrite=TRUE) %>% occ_download_import(fill=FALSE, quote="") # if this stops working, add "fill=false, quote="" "

mual.cit <- occ_download_get("0021182-191105090559680", overwrite=TRUE) %>% gbif_citation() # get citation w/ DOI
mual.cit$download # prints one-line output with DOI

write.csv(mual, file = "mual.csv")
mual <- read.csv("mual.csv", header= TRUE)
```

```{r}
# Clean data  
mual.sub <- subset(mual, select=sc) # subset data w/ criteria defined in sc
mual.sub <- mual.sub[which(mual.sub$species == "Muscisaxicola albilora"),] # verify only desired species
mual.sub <- mual.sub %>% filter(!is.na(decimalLatitude)) # keep only records with lat (just in case)
mual.sub <- mual.sub %>% filter(!is.na(decimalLongitude)) # keep only records with lon (just in case)
    # You downloaded only records with coordinates, so this is no longer necessary
mual.sub <- mual.sub[which(!mual.sub$decimalLatitude == "0"), ] # Drop lat values of 0 
mual.sub <- mual.sub[which(!mual.sub$decimalLongitude == "0"), ] # Drop lon values of 0
mual.sub <- mual.sub[which(!mual.sub$month == "NA"), ] # Drop NA months
mual.sub <- mual.sub[which(!mual.sub$countryCode == "NA"), ] # Drop NA countries
colnames(mual.sub)[colnames(mual.sub)=="coordinateUncertaintyInMeters"] <- "coord_uncert" # rename col
mual.sub <- mual.sub[order(-mual.sub$coord_uncert), ] # sort by coordinate uncertainty
mual.sub <- subset(mual.sub, mual.sub$coord_uncert < 3000 | is.na(mual.sub$coord_uncert)) 
    # Drop coord_uncert values >3000 *and* keep NA values for coord_uncert
    # Another method to achieve the same thing: p <- p[!p$coord_uncert > 3000 | is.na(p$coord_uncert),]
count(mual.sub$countryCode) # Lists all countries & number of observations per country

# Species-specific region adjustments 
mual.sub <- subset(mual.sub, subset = mual.sub$countryCode %in% c("AR", "BO", "EC", "PE", "CL"))

# Fetch elevations with elevation() from rgbif
mual.getelev <- elevation(mual.sub, elevation_model="srtm3", username="jwilliamson")
  # elevations get added as column called "elevation_geonames"
  # decimalLatitude and decimalLongitude get renamed to latitude and longitude 

# Compare discrepancies in existing vs. rgbif elev records, remove bad records
mual.qc <- mual.getelev
mual.qc$elev_diff <- (mual.qc$elevation-mual.qc$elevation_geonames) # Make elev_diff variable 
mual.qc <- mual.qc[, c(1,2,3,4,5,6,7,13,14,8,9,10,11,12)] # reorder columns 
mual.qc <- mual.qc[order(-mual.qc$elev_diff), ] # sort by elev_diff
mual.qc <- subset(mual.qc, mual.qc$elev_diff < 300 | is.na(mual.qc$elev_diff)) 
      # Drop elev_diff values >300m *and* keep NA values for elev_diff
      # differences of >300 m are indicative of probably weird georeferencing
      # NA values mean there just weren't original elev values (aka, all taken from rgbif)

# Split into original elevs and rgbif elevs datasets, prepare to merge records 
mual.elevs <- mual.qc %>% filter(!is.na(elevation)) # existing elev
mual.noelev <- mual.qc %>% filter(is.na(elevation)) # no original elevs
mual.elevs$final_elev <- mual.elevs$elevation # add final_elev, assign elevation values to it 
mual.noelev$final_elev <- mual.noelev$elevation_geonames # add final_elev, assign elev_geonames values to it
    # Most straightforward way to do this would be to selectively merge data from two columns, and only keep 
    # elev_geonames data in instances where there is NOT elev data, but I'm not sure how to do that

# Merge, sort, finalize 
mual.final <- rbind(mual.elevs, mual.noelev) # merge 2 datasets: .elevs and .getelev
    # Note: column names MUST match! 
mual.final <- mual.final[, c(1,2,3,4,5,6,15,7,8,9,10,11,12,13,14)] # reorder columns 
mual.final <- mual.final[order(-mual.final$month, -mual.final$final_elev), ] # sort by month
mual.final <- mual.final[which(!mual.final$final_elev == "-32768"), ] # drop ocean points
write.csv(mual.final, file = "mual.final.csv")
save(mual.final, file="mual.final.RData") # save as Rdata object so you don't have to do it every time
mual.final <- read.csv("mual.final.csv", header= TRUE)
# load("mual.final.RData") # to load .RData file
```

```{r}
# OUTLIER ANALYSIS, REMOVAL, FINAL CALCULATION OF ELEV RANGE 

mual.final <- mual.final[ , !(colnames(mual.final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv

# identify duplicate records based on duplicates of the following columns:
dup <- duplicated(mual.final[, c("species", "longitude", "latitude", "month", "year", "locality", "final_elev")])
sum(dup) # number of duplicates
mual.final <- mual.final[!dup, ] # drop duplicate records
write.csv(mual.final, file = "mual.final.nodups.csv")

# Plot points to verify no oddities in the data
data(wrld_simpl)
#plot(wrld_simpl, axes=TRUE, col="white") # zoomed out
plot(wrld_simpl, axes=TRUE, col="white", xlim=c(-90,-60), ylim=c(-60,10)) # south America
points(mual.final$lon, mual.final$lat, col='orange', pch=20, cex=0.75) # add points
points(mual.final$lon, mual.final$lat, col='red', cex=0.75) # plot points again to add border for better visibility

# ------

# Wrangle breeding data 
mual.breed <- subset(mual.final, mual.final$latitude < -32) 
  # keep only breeding latitudes south of -30 

# Wrangle nonbreeding data 
mual.nonbreed <- subset(mual.final, mual.final$latitude > -32) 
  # keep only breeding latitudes north of -30

# Plot of all elevations by month to look at distribution 
library(ggplot2)
p <- ggplot()
p <- p + geom_boxplot(data=mual.final, aes(x=month, y=final_elev, group=mual.final$month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="mual")
p <- p + theme_classic()
print(p)

# subset for outlier analysis, check for NAs
mual.b.nona <- subset(mual.breed, select=oa) 
mual.nb.nona <- subset(mual.nonbreed, select=oa) 

# subset by breeding and non-breeding season 
mual.b <- mual.b.nona[which(mual.b.nona$month==10 | mual.b.nona$month==11), ] # Breeding October-Jan
mual.nb <- mual.nb.nona[which(mual.nb.nona$month==6 | mual.nb.nona$month==7), ]

# Breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=mual.b, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Breeding: mual")
p <- p + theme_classic()
print(p)

boxplot(mual.b$final_elev, range = 1.5, main="range = 1.5") # Breeding lumped; check outlier threshold 

# Non-breeding outlier ID
p <- ggplot()
p <- p + geom_boxplot(data=mual.nb, aes(x=month, y=final_elev, group=month)) 
p <- p + scale_x_continuous(limits=c(0.6,12.6), breaks = c(1,2,3,4,5,6,7,8,9,10,11,12))
p <- p + labs(x = "Month", y = "Elevation", title="Non-breeding: mual")
p <- p + theme_classic()
print(p)

boxplot(mual.nb$final_elev, range=1.5, main="range=1.5") # Non-breeding lumped; check outlier threshold 


# OUTLIER ANALYSIS AND REMOVAL 
mual.b.out <- FindOutliers(mual.b, r=1.5); mual.b.out # Detect outliers
mual.b <- mual.b[-mual.b.out$rownum,] # remove the outliers

mual.nb.out <- FindOutliers(mual.nb, r=1.5); mual.nb.out # Detect outliers
mual.nb <- mual.nb[-mual.nb.out$rownum,] # remove the outliers 

# Re-run box plots to confirm that outliers have been removed/data looks good 

# Use BreedingElevs() and NonbreedingElevs() functions to calculate elev range for ENSM table 
mual.b.elevs <- BreedingElevs(mual.nb) # reverse cause austral
mual.nb.elevs <- NonbreedingElevs(mual.b) # reverse cause austral
mual.elev.range <- cbind(mual.nb.elevs, mual.b.elevs); mual.elev.range
mual.elev.range["species"] <- "Muscisaxicola_albilora"
mual.elev.range <- mual.elev.range[, c(5,1,2,3,4)]; mual.elev.range  # reorder columns 
write.csv(mual.elev.range, file = "mual.elev.range.csv")
```

M. albilora range map
```{r}
library(maptools) ## Checking rgeos availability: TRUE
data(wrld_simpl)
plot(wrld_simpl, xlim=c(-80,-80), ylim=c(-55,3), axes=TRUE, col="whitesmoke") # plots snow2-colored world map
box() # restore the box around the map
title('M. albilora',cex.lab=1.0)

# these are good coords for all of the USA: plot(wrld_simpl, xlim=c(-130,-50), ylim=c(31,37.5)

# Plot breeding records (blue)
col1 <- c("midnightblue") #midnightblue, sienna2
points(jitter(mual.b$longitude), jitter(mual.b$latitude), col=alpha(col1, 0.8), pch=20, cex=1) # points 

# Plot non-breeding records (orange)
col1 <- c("sienna2") #midnightblue, sienna2
points(jitter(mual.nb$longitude), jitter(mual.nb$latitude), col=alpha(col1, 0.8), pch=20, cex=1) # points 
```






------

# all ENSM species taxa range
```{r}
# in order to see this full table need to read in all csvs for exported ranges 
all.sp.elev.range <- rbind(wcwr.elev.range, oreo.elev.range, phgr.elev.range, core.elev.range, dare.elev.range, blre.elev.range, smwa.elev.range, ibis.elev.range, labr.elev.range, cote.elev.range, anho.elev.range, zoda.elev.range, cema.elev.range, deda.elev.range, robu.elev.range, ulfl.elev.range, gane.elev.range, late.elev.range, bmfi.elev.range, loth.elev.range, muho.in.elev.range, muho.np.elev.range, phre.elev.range, rbac.elev.range, ptru.elev.range, angu.elev.range, ttdo.elev.range, psac.elev.range, wiph.elev.range, mufl.elev.range, muca.elev.range, cifu.elev.range, coru.elev.range, fasu.elev.range, stor.elev.range, anvi.elev.range, cusa.elev.range, jyto.elev.range, gfci.elev.range, caac.elev.range, phsi.elev.range, phch.elev.range, phtr.elev.range, phtr.np.elev.range, phty.elev.range, syal.elev.range, lusv.elev.range, oepi.elev.range, oede.elev.range, moso.elev.range, moci.elev.range, antr.elev.range, casp.elev.range, acpk.elev.range, mual.elev.range); all.sp.elev.range

write.csv(all.sp.elev.range, file = "all.sp.elev.range.csv")

# grwa.nb.elevs can't be included because you only finagled data based on non-breeding Nov-Dec records
# moci.elev.range, grye.elev.range, moqu.elev.range also wrong dimensions (only LLL and ULL)

#To eventually combine all xxxx.elev.range table outputs: 
# use rbind to combine other elev.range data frames
# If you want to drop records or subset, do this by calling $ species; e.g. $species==Tragopan_satyra
```



Attempt at a plot w/ all species
```{r}
chmo.b["season"] <- "breeding" # add column for season, fill w/ breeding
chmo.nb["season"] <- "nonbreeding" # add col for season, fill w/ nonbreeding
chmo.all.elevs <- rbind(chmo.b, chmo.nb) # combine datasets
chmo.all.elevs["family"] <- "Charadriidae" # add col for family

# the only problem with doing it this way is that it's going to plot all values that come out of your analysis
# which isn't necessarily what you want
# I think what you want is to read in your final TABLE and plot those values 

ggplot(data=chmo.all.elevs, aes(x=season, y=final_elev)) +
geom_bar(stat="identity", position=position_dodge())

# create test data frame in format I'd want for this plot
test <- data.frame("species" = "Charadrius mongolus", "season" = c("breeding", "breeding", "nonbreeding", "nonbreeding"), "elev" = c(3900, 5500, 0, 59))

test2 <- data.frame("species" = "Calidris bairdii", "season" = c("breeding", "breeding", "nonbreeding", "nonbreeding"), "elev" = c(2550, 5000, 0, 400))

test3 <- data.frame("species" = "Anthus roseatus", "season" = c("breeding", "breeding", "nonbreeding", "nonbreeding"), "elev" = c(4000, 5050, 760, 1500))

test4 <- data.frame("species" = "Chaimarrornis leucocephalus", "season" = c("breeding", "breeding", "nonbreeding", "nonbreeding"), "elev" = c(1830, 5000, 915, 1525))

test5 <- data.frame("species" = "Patagona gigas", "season" = c("breeding", "breeding", "nonbreeding", "nonbreeding"), "elev" = c(0, 2000, 1789, 4829))

test.big <- rbind(test, test2, test3, test4, test5)


#ggplot(data=test.big, aes(x=species, y=elev, fill=season)) +
# geom_bar(stat="identity", position=position_dodge())
# I don't think I want a barplot

# all species trial
p <- ggplot(test.big, aes(x=species, y=elev, fill=season)) +
  geom_boxplot(position=position_dodge(1), outlier.shape = NA, coef = 0, alpha = 1.0) + 
  scale_fill_manual(values=c("orangered3", "deepskyblue3")) +
  scale_y_continuous(breaks = c(0, 1000, 2000, 3000, 4000, 5000, 6000), limits=c(0, 6000)) +
  labs(title="Seasonal elevational range of ENSM species",x="Species", y = "Elevation (m)") +
  theme(axis.text.x = element_text(angle=45, hjust=1)) +
  theme_classic() + 
  theme(legend.position="bottom")
p


# IMPROVEMENTS
# Can you decreasing position_dodge spacing and increase spacing between species records instead?
# make species labels tilt sideways on axis
# Make legend go away? 
# Adjust legend text 
# Italicize species names 


# just one - Patagona
p <- ggplot(test5, aes(x=species, y=elev, fill=season)) +
  geom_boxplot(position=position_dodge(1), outlier.shape = NA, coef = 0) + 
  scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9")) +
  scale_y_continuous(breaks = c(0, 1000, 2000, 3000, 4000, 5000), limits=c(0, 5000)) +
  labs(title="P. gigas seasonal elev range",x="Species", y = "Elevation (m)") +
  theme(axis.text.x = element_text(angle=45, hjust=1)) +
  theme_classic() + 
  theme(legend.position="bottom")
p



# position_dodge = vertical spacing between data points
# coef = 0 = to make "error bars" disappear from boxplots

```


-----

#### END OF SCRIPT 

-----




### TUTORIALS, NOTES, OTHER INFO 


**Tutorials and info about some of the below code:** 

Good R spatial tutorial, including simple code for removing duplicates, mapping records, and mapping records while highlighting those that belong to the wrong countries regions: 
https://rspatial.org/raster/sdm/2_sdm_occdata.html#data-cleaning

For removing duplicates: 
http://www.datasciencemadesimple.com/remove-duplicate-rows-r-using-dplyr-distinct-function/

Select top or bottom rows by value: https://dplyr.tidyverse.org/reference/top_n.html

Using package elevatr to get elevation: https://cran.r-project.org/web/packages/elevatr/vignettes/introduction_to_elevatr.html (note: I've used rgbif)

Get elevation using elevation() in rgbif: https://rdrr.io/cran/rgbif/man/elevation.html

Helpful tutorial on using dyplyr to sort by min/max values of a group: 
https://stackoverflow.com/questions/24558328/how-to-select-the-row-with-the-maximum-value-in-each-group

rgbif package on CRAN has some good tutorials (see below for downloading, etc): https://cran.r-project.org/web/packages/rgbif/index.html

Good boxplot tutorial: http://www.sthda.com/english/wiki/ggplot2-box-plot-quick-start-guide-r-software-and-data-visualization

Another good boxplot tutorial: http://t-redactyl.io/blog/2016/04/creating-plots-in-r-using-ggplot2-part-10-boxplots.html

Another goog tutorial: 
https://www.datanovia.com/en/blog/ggplot-axis-ticks-set-and-rotate-text-labels/


Pull GBIF species occurrence records from the web 
Best tutorial for downloading: https://cran.r-project.org/web/packages/rgbif/vignettes/downloads.html
Although I haven't yet looked at this, here's another tutorial for looking at GBIF data issues and cleaning data: https://cran.r-project.org/web/packages/rgbif/vignettes/issues.html


---

# END 
